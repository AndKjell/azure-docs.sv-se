<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="zh-cn" original="foo.file" tool-id="763961e4-c071-4dba-a5d4-03d422043e5d" product-name="foo" product-version="1.0" build-num="1">
    <header>
      <tool tool-id="763961e4-c071-4dba-a5d4-03d422043e5d" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group id="0a938389-1441-4872-b342-dc4932deba0d">
        <trans-unit id="700e6346-b2b5-4c5e-b1b7-c7cc0f89aa03" xml:space="preserve">
          <source>Submit Hive Queries to Hadoop clusters in the Advanced Analytics Process and Technology | Microsoft Azure</source>
          <target state="new">Submit Hive Queries to Hadoop clusters in the Advanced Analytics Process and Technology | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="db52cb5b-a77e-4323-9e04-79e544e2b344" xml:space="preserve">
          <source>Process Data from Hive Tables with Hive queries.</source>
          <target state="new">Process Data from Hive Tables with Hive queries.</target>
        </trans-unit>
        <trans-unit id="cdb29a24-cc9c-4f8c-9f8d-fe80bae611c5" xml:space="preserve">
          <source>This document describes various ways of submitting Hive queries to Hadoop clusters that are managed by an HDInsight service in Azure.</source>
          <target state="new">This document describes various ways of submitting Hive queries to Hadoop clusters that are managed by an HDInsight service in Azure.</target>
        </trans-unit>
        <trans-unit id="20e30e1d-b91c-4859-ac0a-10350cef51a3" xml:space="preserve">
          <source>This task is part of the Advanced Analytics Process and Technology (ADAPT) provided by Azure Machine Learning.</source>
          <target state="new">This task is part of the Advanced Analytics Process and Technology (ADAPT) provided by Azure Machine Learning.</target>
        </trans-unit>
        <trans-unit id="71b95d87-0516-48ac-afaf-eee181ac7bcf" xml:space="preserve">
          <source>Several data wrangling tasks are discussed: data exploration and feature generation.</source>
          <target state="new">Several data wrangling tasks are discussed: data exploration and feature generation.</target>
        </trans-unit>
        <trans-unit id="3e4c770c-5b79-4f45-84a9-472f484f0e45" xml:space="preserve">
          <source>Generic Hive queries that show how to explore data or generate features using Hive in an Azure HDInsight Hadoop cluster.</source>
          <target state="new">Generic Hive queries that show how to explore data or generate features using Hive in an Azure HDInsight Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="e889d8d4-9cbb-4ac4-88a0-935e82fcc277" xml:space="preserve">
          <source>These Hive queries use embedded Hive User Defined Functions (UDFs) which are provided.</source>
          <target state="new">These Hive queries use embedded Hive User Defined Functions (UDFs) which are provided.</target>
        </trans-unit>
        <trans-unit id="11500147-55dc-46e9-8b26-47bb22421998" xml:space="preserve">
          <source>Examples of queries that are specific to [NYC Taxi Trip Data](http://chriswhong.com/open-data/foil<bpt id="46169098-8de4-4775-88ab-be3015bb7d4b">&lt;em&gt;</bpt>nyc<ept id="46169098-8de4-4775-88ab-be3015bb7d4b">&lt;/em&gt;</ept>taxi/) scenarios are also provided in <bpt id="8606fa10-9920-4be2-b366-76024e83963b">&lt;linkText&gt;</bpt>Github repository<ept id="8606fa10-9920-4be2-b366-76024e83963b">&lt;/linkText&gt;</ept><bpt id="8606fa10-9920-4be2-b366-76024e83963b">&lt;title&gt;</bpt><ept id="8606fa10-9920-4be2-b366-76024e83963b">&lt;/title&gt;</ept>.</source>
          <target state="new">Examples of queries that are specific to [NYC Taxi Trip Data](http://chriswhong.com/open-data/foil<bpt id="46169098-8de4-4775-88ab-be3015bb7d4b">&lt;em&gt;</bpt>nyc<ept id="46169098-8de4-4775-88ab-be3015bb7d4b">&lt;/em&gt;</ept>taxi/) scenarios are also provided in <bpt id="8606fa10-9920-4be2-b366-76024e83963b">&lt;linkText&gt;</bpt>Github repository<ept id="8606fa10-9920-4be2-b366-76024e83963b">&lt;/linkText&gt;</ept><bpt id="8606fa10-9920-4be2-b366-76024e83963b">&lt;title&gt;</bpt><ept id="8606fa10-9920-4be2-b366-76024e83963b">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="906399fc-df3a-4e02-91d6-90a22335a133" xml:space="preserve">
          <source>These queries already have data schema specified and are ready to be submitted to run.</source>
          <target state="new">These queries already have data schema specified and are ready to be submitted to run.</target>
        </trans-unit>
        <trans-unit id="8450bbe4-587b-48bc-a178-6d289da3dc26" xml:space="preserve">
          <source>In the final section, parameters that users can tune so that the performance of Hive queries can be improved are discussed.</source>
          <target state="new">In the final section, parameters that users can tune so that the performance of Hive queries can be improved are discussed.</target>
        </trans-unit>
        <trans-unit id="efc27462-adb9-49a6-b48f-8ae9dead831b" xml:space="preserve">
          <source>This article assumes that you have:</source>
          <target state="new">This article assumes that you have:</target>
        </trans-unit>
        <trans-unit id="0a48551c-fdf1-4e26-ae83-7fc3c08280c8" xml:space="preserve">
          <source>Created an Azure storage account.</source>
          <target state="new">Created an Azure storage account.</target>
        </trans-unit>
        <trans-unit id="e9772e06-35d9-4641-b628-e364c8c1fdc1" xml:space="preserve">
          <source>If you need instructions, see <bpt id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;linkText&gt;</bpt>Create an Azure Storage account<ept id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;/linkText&gt;</ept><bpt id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;title&gt;</bpt><ept id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;/title&gt;</ept></source>
          <target state="new">If you need instructions, see <bpt id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;linkText&gt;</bpt>Create an Azure Storage account<ept id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;/linkText&gt;</ept><bpt id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;title&gt;</bpt><ept id="457dba9f-8862-4dad-abd9-abde66d1f41e">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="b6b8fe72-9416-4a54-9c32-eba6a72e3029" xml:space="preserve">
          <source>Provisioned a customized Hadoop cluster with the HDInsight service.</source>
          <target state="new">Provisioned a customized Hadoop cluster with the HDInsight service.</target>
        </trans-unit>
        <trans-unit id="2a6509ea-6af8-44f6-aa80-be937ed067cf" xml:space="preserve">
          <source>If you need instructions, see <bpt id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;linkText&gt;</bpt>Customize Azure HDInsight Hadoop Clusters for Advanced Analytics<ept id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;/linkText&gt;</ept><bpt id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;title&gt;</bpt><ept id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;/title&gt;</ept>.</source>
          <target state="new">If you need instructions, see <bpt id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;linkText&gt;</bpt>Customize Azure HDInsight Hadoop Clusters for Advanced Analytics<ept id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;/linkText&gt;</ept><bpt id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;title&gt;</bpt><ept id="8a739345-4a4c-45f5-a60a-34919e18d1c6">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="60650375-40c7-4816-8c95-a56020f2bd1e" xml:space="preserve">
          <source>The data has been uploaded to Hive tables in Azure HDInsight Hadoop clusters.</source>
          <target state="new">The data has been uploaded to Hive tables in Azure HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="2be27adc-f5ee-4b3c-8053-0c04028b4302" xml:space="preserve">
          <source>If it has not, please follow <bpt id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;linkText&gt;</bpt>Create and load data to Hive tables<ept id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;/linkText&gt;</ept><bpt id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;title&gt;</bpt><ept id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;/title&gt;</ept> to upload data to Hive tables first.</source>
          <target state="new">If it has not, please follow <bpt id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;linkText&gt;</bpt>Create and load data to Hive tables<ept id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;/linkText&gt;</ept><bpt id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;title&gt;</bpt><ept id="ce863ec9-3968-4c43-91e7-d7266844eed1">&lt;/title&gt;</ept> to upload data to Hive tables first.</target>
        </trans-unit>
        <trans-unit id="7fb51741-482e-406c-a943-933c2abf592b" xml:space="preserve">
          <source>Enabled remote access to the cluster.</source>
          <target state="new">Enabled remote access to the cluster.</target>
        </trans-unit>
        <trans-unit id="d470ff1b-0b6e-4358-9e41-395d0dad88e9" xml:space="preserve">
          <source>If you need instructions, see <bpt id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;linkText&gt;</bpt>Access the Head Node of Hadoop Cluster<ept id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;/linkText&gt;</ept><bpt id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;title&gt;</bpt><ept id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;/title&gt;</ept>.</source>
          <target state="new">If you need instructions, see <bpt id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;linkText&gt;</bpt>Access the Head Node of Hadoop Cluster<ept id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;/linkText&gt;</ept><bpt id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;title&gt;</bpt><ept id="bfd8571d-4e5a-4d54-8c6d-89664e814c47">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="be9cb6a7-aa83-4912-b615-d09d5589eca2" xml:space="preserve">
          <source>Hive queries can be submitted by using:</source>
          <target state="new">Hive queries can be submitted by using:</target>
        </trans-unit>
        <trans-unit id="5612f467-801e-46ef-b48a-33d427528b0e" xml:space="preserve">
          <source>the Hadoop Command Line on the headnode of the cluster</source>
          <target state="new">the Hadoop Command Line on the headnode of the cluster</target>
        </trans-unit>
        <trans-unit id="b40204a0-8bbe-45ed-9a52-903a84729025" xml:space="preserve">
          <source>the IPython Notebook</source>
          <target state="new">the IPython Notebook</target>
        </trans-unit>
        <trans-unit id="483c4f8a-674e-41ea-842d-18498a33fdbe" xml:space="preserve">
          <source>the Hive Editor</source>
          <target state="new">the Hive Editor</target>
        </trans-unit>
        <trans-unit id="5505311d-6fd9-4e8d-99de-6806658caac1" xml:space="preserve">
          <source>Azure PowerShell scripts</source>
          <target state="new">Azure PowerShell scripts</target>
        </trans-unit>
        <trans-unit id="9bbb6ca6-cd97-42dd-ad57-1712804671c7" xml:space="preserve">
          <source>Hive queries are SQL-like.</source>
          <target state="new">Hive queries are SQL-like.</target>
        </trans-unit>
        <trans-unit id="0fe02dd7-d04f-4889-8d43-f08d7a8c381f" xml:space="preserve">
          <source>Users familiar with SQL may find the &lt;a href="http://hortonworks.com/wp-content/uploads/downloads/2013/08/Hortonworks.CheatSheet.SQLtoHive.pdf" target="_blank"&gt;SQL-to-Hive Cheat Sheet&lt;/a&gt; useful.</source>
          <target state="new">Users familiar with SQL may find the &lt;a href="http://hortonworks.com/wp-content/uploads/downloads/2013/08/Hortonworks.CheatSheet.SQLtoHive.pdf" target="_blank"&gt;SQL-to-Hive Cheat Sheet&lt;/a&gt; useful.</target>
        </trans-unit>
        <trans-unit id="1856bc93-39f2-4f85-be70-d225d69baa60" xml:space="preserve">
          <source>When submitting a Hive query, you can also control the destination of the output from Hive queries, whether it be on the screen or to a local file on the head node or to an Azure blob.</source>
          <target state="new">When submitting a Hive query, you can also control the destination of the output from Hive queries, whether it be on the screen or to a local file on the head node or to an Azure blob.</target>
        </trans-unit>
        <trans-unit id="d2f2754f-a89e-4ac1-8e32-4c922beac39d" xml:space="preserve">
          <source>If the query is complex, submitting Hive queries directly from the head node of the Hadoop cluster typically leads to faster turn around than submitting it with a Hive Editor or by using Azure PowerShell scripts.</source>
          <target state="new">If the query is complex, submitting Hive queries directly from the head node of the Hadoop cluster typically leads to faster turn around than submitting it with a Hive Editor or by using Azure PowerShell scripts.</target>
        </trans-unit>
        <trans-unit id="e64b3894-d399-4d55-84bc-5ba72a27c1ea" xml:space="preserve">
          <source>Log in to the head node of the Hadoop cluster, open the Hadoop Command Line on the desktop of the head node, and enter command</source>
          <target state="new">Log in to the head node of the Hadoop cluster, open the Hadoop Command Line on the desktop of the head node, and enter command</target>
        </trans-unit>
        <trans-unit id="1b4b30a5-da9d-4d10-ac17-2a7ae82bed48" xml:space="preserve">
          <source>Users have three ways to submit Hive queries in Hadoop Command Line console:</source>
          <target state="new">Users have three ways to submit Hive queries in Hadoop Command Line console:</target>
        </trans-unit>
        <trans-unit id="a0328413-becc-470b-953e-7921d90a95f2" xml:space="preserve">
          <source>directly from the Hadoop command line</source>
          <target state="new">directly from the Hadoop command line</target>
        </trans-unit>
        <trans-unit id="14157d5e-69ac-40ef-ad6a-74bc319cf178" xml:space="preserve">
          <source>using .hql files</source>
          <target state="new">using .hql files</target>
        </trans-unit>
        <trans-unit id="146fa7af-5821-430d-b6eb-9c92de9cd89f" xml:space="preserve">
          <source>from the Hive command console</source>
          <target state="new">from the Hive command console</target>
        </trans-unit>
        <trans-unit id="c4f85363-b87b-4b59-b702-e5bd666b50b5" xml:space="preserve">
          <source>Users can run command like</source>
          <target state="new">Users can run command like</target>
        </trans-unit>
        <trans-unit id="0dcf1c39-72cb-4717-b783-e1a590e703b3" xml:space="preserve">
          <source>to submit simple Hive queries directly in the Hadoop command line.</source>
          <target state="new">to submit simple Hive queries directly in the Hadoop command line.</target>
        </trans-unit>
        <trans-unit id="baed2ce7-f6d7-4f58-af12-3ed41a7d0534" xml:space="preserve">
          <source>Here is an example, where the red box outlines the command that submits the Hive query, and the green box outlines the output from the Hive query.</source>
          <target state="new">Here is an example, where the red box outlines the command that submits the Hive query, and the green box outlines the output from the Hive query.</target>
        </trans-unit>
        <trans-unit id="87f3105b-4402-43fd-a98a-d79d61cf598b" xml:space="preserve">
          <source><bpt id="0e456fd7-3871-4523-a9c0-b96211d451c3">&lt;linkText&gt;</bpt>Create workspace<ept id="0e456fd7-3871-4523-a9c0-b96211d451c3">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="0e456fd7-3871-4523-a9c0-b96211d451c3">&lt;linkText&gt;</bpt>Create workspace<ept id="0e456fd7-3871-4523-a9c0-b96211d451c3">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="8e142e47-e0c4-4e03-beca-1cd3ef683d07" xml:space="preserve">
          <source>When the Hive query is more complicated and has multiple lines, editing queries in Hadoop command line or Hive command console is not practical.</source>
          <target state="new">When the Hive query is more complicated and has multiple lines, editing queries in Hadoop command line or Hive command console is not practical.</target>
        </trans-unit>
        <trans-unit id="11c18934-2df7-4e16-8729-75f60b4c6606" xml:space="preserve">
          <source>An alternative is to use a text editor in the head node of the Hadoop cluster and to save the Hive queries in a .hql file in a local directory of the head node.</source>
          <target state="new">An alternative is to use a text editor in the head node of the Hadoop cluster and to save the Hive queries in a .hql file in a local directory of the head node.</target>
        </trans-unit>
        <trans-unit id="7c83f97f-6dca-4414-835d-1b051e820b87" xml:space="preserve">
          <source>Then the Hive query in the .hql file can be submitted by using the <bpt id="4a6d965a-3ebe-4a65-a806-01af76e1d719">&lt;code&gt;</bpt>-f<ept id="4a6d965a-3ebe-4a65-a806-01af76e1d719">&lt;/code&gt;</ept> argument in the <bpt id="1db2cdaa-d879-4b20-800b-180888192634">&lt;code&gt;</bpt>hive<ept id="1db2cdaa-d879-4b20-800b-180888192634">&lt;/code&gt;</ept> command as follows:</source>
          <target state="new">Then the Hive query in the .hql file can be submitted by using the <bpt id="4a6d965a-3ebe-4a65-a806-01af76e1d719">&lt;code&gt;</bpt>-f<ept id="4a6d965a-3ebe-4a65-a806-01af76e1d719">&lt;/code&gt;</ept> argument in the <bpt id="1db2cdaa-d879-4b20-800b-180888192634">&lt;code&gt;</bpt>hive<ept id="1db2cdaa-d879-4b20-800b-180888192634">&lt;/code&gt;</ept> command as follows:</target>
        </trans-unit>
        <trans-unit id="76b23224-0837-4c3e-bf5f-00130376ea97" xml:space="preserve">
          <source>By default, after Hive query is submitted in the Hadoop Command Line console, the progress of the Map/Reduce job will be printed out on screen.</source>
          <target state="new">By default, after Hive query is submitted in the Hadoop Command Line console, the progress of the Map/Reduce job will be printed out on screen.</target>
        </trans-unit>
        <trans-unit id="672717a2-07a4-4912-acda-f545528ea7a1" xml:space="preserve">
          <source>To suppress the screen print of the Map/Reduce job progress, you can use the argument <bpt id="398c71ef-e19d-4710-8bd3-b06269ca300d">&lt;code&gt;</bpt>-S<ept id="398c71ef-e19d-4710-8bd3-b06269ca300d">&lt;/code&gt;</ept> (case-sensitive) argument in the command line as follows:</source>
          <target state="new">To suppress the screen print of the Map/Reduce job progress, you can use the argument <bpt id="398c71ef-e19d-4710-8bd3-b06269ca300d">&lt;code&gt;</bpt>-S<ept id="398c71ef-e19d-4710-8bd3-b06269ca300d">&lt;/code&gt;</ept> (case-sensitive) argument in the command line as follows:</target>
        </trans-unit>
        <trans-unit id="6e966168-e0f6-4ead-b37d-cd1d093035cd" xml:space="preserve">
          <source>Users can also enter the Hive command console by running the  <bpt id="9f902abd-477b-4d4f-9318-192ab3abda06">&lt;code&gt;</bpt>hive<ept id="9f902abd-477b-4d4f-9318-192ab3abda06">&lt;/code&gt;</ept> command from the Hadoop command line, and then submit Hive queries from Hive command console at the <bpt id="1478f7d7-52e4-4b95-8c9d-b33b2a83f75a">&lt;strong&gt;</bpt>hive&gt;<ept id="1478f7d7-52e4-4b95-8c9d-b33b2a83f75a">&lt;/strong&gt;</ept> prompt.</source>
          <target state="new">Users can also enter the Hive command console by running the  <bpt id="9f902abd-477b-4d4f-9318-192ab3abda06">&lt;code&gt;</bpt>hive<ept id="9f902abd-477b-4d4f-9318-192ab3abda06">&lt;/code&gt;</ept> command from the Hadoop command line, and then submit Hive queries from Hive command console at the <bpt id="1478f7d7-52e4-4b95-8c9d-b33b2a83f75a">&lt;strong&gt;</bpt>hive&gt;<ept id="1478f7d7-52e4-4b95-8c9d-b33b2a83f75a">&lt;/strong&gt;</ept> prompt.</target>
        </trans-unit>
        <trans-unit id="7927ce17-8aad-4a37-a4d1-25d9090bcde9" xml:space="preserve">
          <source>Here is an example.</source>
          <target state="new">Here is an example.</target>
        </trans-unit>
        <trans-unit id="db2a881a-5560-41bf-9446-53e9dc6fbf25" xml:space="preserve">
          <source><bpt id="8ff6f6db-c6f7-4062-beef-49e1e24c9405">&lt;linkText&gt;</bpt>Create workspace<ept id="8ff6f6db-c6f7-4062-beef-49e1e24c9405">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="8ff6f6db-c6f7-4062-beef-49e1e24c9405">&lt;linkText&gt;</bpt>Create workspace<ept id="8ff6f6db-c6f7-4062-beef-49e1e24c9405">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="437e16d7-fc84-43fe-ac5e-3d1392af9a7b" xml:space="preserve">
          <source>In this example, the two red boxes highlight the commands used to enter the Hive command console, and the Hive query submitted in Hive command console, respectively.</source>
          <target state="new">In this example, the two red boxes highlight the commands used to enter the Hive command console, and the Hive query submitted in Hive command console, respectively.</target>
        </trans-unit>
        <trans-unit id="dde636a3-ef1f-4a7d-9b94-2433cf28afc2" xml:space="preserve">
          <source>The green box highlights the output from the Hive query.</source>
          <target state="new">The green box highlights the output from the Hive query.</target>
        </trans-unit>
        <trans-unit id="47ff9b6d-ff67-4d8d-bb9c-ef0ec064dbef" xml:space="preserve">
          <source>The previous examples directly output the Hive query results on screen.</source>
          <target state="new">The previous examples directly output the Hive query results on screen.</target>
        </trans-unit>
        <trans-unit id="a0b7575f-bf7b-42ab-a873-d39d13684a26" xml:space="preserve">
          <source>Users can also write the output to a local file on the head node, or to an Azure blob.</source>
          <target state="new">Users can also write the output to a local file on the head node, or to an Azure blob.</target>
        </trans-unit>
        <trans-unit id="4a0b2d9c-7854-4c31-9b21-5becf48dcc78" xml:space="preserve">
          <source>Then, users can use other tools to further analyze the output of from Hive queries.</source>
          <target state="new">Then, users can use other tools to further analyze the output of from Hive queries.</target>
        </trans-unit>
        <trans-unit id="900f298c-4dba-4521-93fb-74b5d1749bd5" xml:space="preserve">
          <source>To output Hive query results to a local directory on the head node, users have to submit the Hive query in the Hadoop Command Line as follows:</source>
          <target state="new">To output Hive query results to a local directory on the head node, users have to submit the Hive query in the Hadoop Command Line as follows:</target>
        </trans-unit>
        <trans-unit id="d2353f19-205e-4465-ba02-ae431bb853bb" xml:space="preserve">
          <source>Users can also output the Hive query results to an Azure blob, within the default container of the Hadoop cluster.</source>
          <target state="new">Users can also output the Hive query results to an Azure blob, within the default container of the Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="1400aa7e-d133-4c78-86ed-2cbe0135cc9e" xml:space="preserve">
          <source>The Hive query to do this looks like this:</source>
          <target state="new">The Hive query to do this looks like this:</target>
        </trans-unit>
        <trans-unit id="4958fff2-5ce0-44db-9959-0b5041fee93a" xml:space="preserve">
          <source>In the following example, the output of Hive query is written to a blob directory <bpt id="0b461d22-606f-4e33-8dba-3e8d6f6f22da">&lt;code&gt;</bpt>queryoutputdir<ept id="0b461d22-606f-4e33-8dba-3e8d6f6f22da">&lt;/code&gt;</ept> within the default container of the Hadoop cluster.</source>
          <target state="new">In the following example, the output of Hive query is written to a blob directory <bpt id="0b461d22-606f-4e33-8dba-3e8d6f6f22da">&lt;code&gt;</bpt>queryoutputdir<ept id="0b461d22-606f-4e33-8dba-3e8d6f6f22da">&lt;/code&gt;</ept> within the default container of the Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="831944b2-7f41-4f56-a1b1-49e8561a93b1" xml:space="preserve">
          <source>Here, you must only provide the directory name, without the blob name.</source>
          <target state="new">Here, you must only provide the directory name, without the blob name.</target>
        </trans-unit>
        <trans-unit id="740d7a2c-ade5-4b1e-b57c-69b3592e3347" xml:space="preserve">
          <source>An error will be thrown out if you provide both the directory and the blob name, such as <bpt id="283ac310-3f30-4f7a-8e4e-729c45f131d8">&lt;em&gt;</bpt>wasb:///queryoutputdir/queryoutput.txt<ept id="283ac310-3f30-4f7a-8e4e-729c45f131d8">&lt;/em&gt;</ept>.</source>
          <target state="new">An error will be thrown out if you provide both the directory and the blob name, such as <bpt id="283ac310-3f30-4f7a-8e4e-729c45f131d8">&lt;em&gt;</bpt>wasb:///queryoutputdir/queryoutput.txt<ept id="283ac310-3f30-4f7a-8e4e-729c45f131d8">&lt;/em&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="4335ad03-669e-4c45-9599-9fda137a4e6b" xml:space="preserve">
          <source><bpt id="247760eb-baf1-4bbd-95e9-79ca6c58f368">&lt;linkText&gt;</bpt>Create workspace<ept id="247760eb-baf1-4bbd-95e9-79ca6c58f368">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="247760eb-baf1-4bbd-95e9-79ca6c58f368">&lt;linkText&gt;</bpt>Create workspace<ept id="247760eb-baf1-4bbd-95e9-79ca6c58f368">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="bdcff872-726b-4c8f-bf4c-91084a1e76cb" xml:space="preserve">
          <source>The output of the Hive query can be seen in blob storage by opening the default container of the Hadoop cluster using the Azure Storage Explorer (or equivalent) tool.</source>
          <target state="new">The output of the Hive query can be seen in blob storage by opening the default container of the Hadoop cluster using the Azure Storage Explorer (or equivalent) tool.</target>
        </trans-unit>
        <trans-unit id="091b3cca-aaee-4f45-bd19-ef48ff270946" xml:space="preserve">
          <source>You can apply the filter (highlighted by red box) if you only want to retrieve a blob with specified letters in names.</source>
          <target state="new">You can apply the filter (highlighted by red box) if you only want to retrieve a blob with specified letters in names.</target>
        </trans-unit>
        <trans-unit id="e35f8960-cfdf-4aeb-8fa7-4bc9afbdbc80" xml:space="preserve">
          <source><bpt id="57214059-82bd-4ec6-991a-09287b90eb31">&lt;linkText&gt;</bpt>Create workspace<ept id="57214059-82bd-4ec6-991a-09287b90eb31">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="57214059-82bd-4ec6-991a-09287b90eb31">&lt;linkText&gt;</bpt>Create workspace<ept id="57214059-82bd-4ec6-991a-09287b90eb31">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="ccc022c9-47f3-4cac-ba4c-a98775f5050c" xml:space="preserve">
          <source>Users can also use the Query Console (Hive Editor) by entering the URL of the form</source>
          <target state="new">Users can also use the Query Console (Hive Editor) by entering the URL of the form</target>
        </trans-unit>
        <trans-unit id="270620db-52b5-4582-9fcb-8cf1b838ca5b" xml:space="preserve">
          <source><bpt id="ae586748-4690-4e2c-b95c-3a9aec479917">&lt;em&gt;</bpt>https://&amp;#60;Hadoop cluster name&gt;.azurehdinsight.net/Home/HiveEditor<ept id="ae586748-4690-4e2c-b95c-3a9aec479917">&lt;/em&gt;</ept>  </source>
          <target state="new"><bpt id="ae586748-4690-4e2c-b95c-3a9aec479917">&lt;em&gt;</bpt>https://&amp;#60;Hadoop cluster name&gt;.azurehdinsight.net/Home/HiveEditor<ept id="ae586748-4690-4e2c-b95c-3a9aec479917">&lt;/em&gt;</ept>  </target>
        </trans-unit>
        <trans-unit id="7c92a947-24be-4634-9126-543fdb4f2315" xml:space="preserve">
          <source>into a web browser.</source>
          <target state="new">into a web browser.</target>
        </trans-unit>
        <trans-unit id="ab9a75e2-2454-4e66-b446-3659c762e023" xml:space="preserve">
          <source>Note that you will be asked to input the Hadoop cluster credentials to log in.</source>
          <target state="new">Note that you will be asked to input the Hadoop cluster credentials to log in.</target>
        </trans-unit>
        <trans-unit id="ecfacf50-8827-46cd-a900-ce16a7cfc4ec" xml:space="preserve">
          <source>Alternatively, you can <bpt id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;linkText&gt;</bpt>Submit Hive jobs using PowerShell<ept id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;/linkText&gt;</ept><bpt id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;title&gt;</bpt><ept id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;/title&gt;</ept>.</source>
          <target state="new">Alternatively, you can <bpt id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;linkText&gt;</bpt>Submit Hive jobs using PowerShell<ept id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;/linkText&gt;</ept><bpt id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;title&gt;</bpt><ept id="ef59821e-1a3d-40a2-b8b0-36a18ffd6443">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="d80ff7f0-082a-4d74-a79d-a87277288bdb" xml:space="preserve">
          <source>Here are a few sample Hive scripts that can be used to explore data in Hive tables.</source>
          <target state="new">Here are a few sample Hive scripts that can be used to explore data in Hive tables.</target>
        </trans-unit>
        <trans-unit id="76f7facb-c1d2-4426-a16f-eecacb20827d" xml:space="preserve">
          <source>Get the count of observations per partition
<bpt id="f4c9600f-91de-4d5d-9116-11c8bfe7f468">&lt;code&gt;</bpt>SELECT &lt;partitionfieldname&gt;, count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by &lt;partitionfieldname&gt;;<ept id="f4c9600f-91de-4d5d-9116-11c8bfe7f468">&lt;/code&gt;</ept></source>
          <target state="new">Get the count of observations per partition
<bpt id="f4c9600f-91de-4d5d-9116-11c8bfe7f468">&lt;code&gt;</bpt>SELECT &lt;partitionfieldname&gt;, count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by &lt;partitionfieldname&gt;;<ept id="f4c9600f-91de-4d5d-9116-11c8bfe7f468">&lt;/code&gt;</ept></target>
        </trans-unit>
        <trans-unit id="94c3050f-404d-4508-b8f2-a3b722b1d54f" xml:space="preserve">
          <source>Get the count of observations per day
<bpt id="5b2b222d-69b3-4e19-80b4-b46f8b43af81">&lt;code&gt;</bpt>SELECT to_date(&lt;date_columnname&gt;), count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by to_date(&lt;date_columnname&gt;);<ept id="5b2b222d-69b3-4e19-80b4-b46f8b43af81">&lt;/code&gt;</ept></source>
          <target state="new">Get the count of observations per day
<bpt id="5b2b222d-69b3-4e19-80b4-b46f8b43af81">&lt;code&gt;</bpt>SELECT to_date(&lt;date_columnname&gt;), count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by to_date(&lt;date_columnname&gt;);<ept id="5b2b222d-69b3-4e19-80b4-b46f8b43af81">&lt;/code&gt;</ept></target>
        </trans-unit>
        <trans-unit id="dc6bdddb-8ba4-4c7b-9c24-eea4eb5cae7d" xml:space="preserve">
          <source>Get the levels in a categorical column  
<bpt id="f4297194-ae29-4548-a4c4-8ca3e2317dd7">&lt;code&gt;</bpt>SELECT  distinct &lt;column_name&gt; from &lt;databasename&gt;.&lt;tablename&gt;<ept id="f4297194-ae29-4548-a4c4-8ca3e2317dd7">&lt;/code&gt;</ept></source>
          <target state="new">Get the levels in a categorical column  
<bpt id="f4297194-ae29-4548-a4c4-8ca3e2317dd7">&lt;code&gt;</bpt>SELECT  distinct &lt;column_name&gt; from &lt;databasename&gt;.&lt;tablename&gt;<ept id="f4297194-ae29-4548-a4c4-8ca3e2317dd7">&lt;/code&gt;</ept></target>
        </trans-unit>
        <trans-unit id="d5214836-e377-4d85-b6ee-6b2421161e76" xml:space="preserve">
          <source>Get the number of levels in combination of two categorical columns
<bpt id="cdec4152-fa6e-405b-831f-df3d0a7fcace">&lt;code&gt;</bpt>SELECT &lt;column_a&gt;, &lt;column_b&gt;, count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by &lt;column_a&gt;, &lt;column_b&gt;<ept id="cdec4152-fa6e-405b-831f-df3d0a7fcace">&lt;/code&gt;</ept></source>
          <target state="new">Get the number of levels in combination of two categorical columns
<bpt id="cdec4152-fa6e-405b-831f-df3d0a7fcace">&lt;code&gt;</bpt>SELECT &lt;column_a&gt;, &lt;column_b&gt;, count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by &lt;column_a&gt;, &lt;column_b&gt;<ept id="cdec4152-fa6e-405b-831f-df3d0a7fcace">&lt;/code&gt;</ept></target>
        </trans-unit>
        <trans-unit id="eaefaceb-4175-4743-90fd-b6e9ec165888" xml:space="preserve">
          <source>Get the distribution for numerical columns  
<bpt id="c0f17bdb-029c-4ca7-a974-7ae0cc203c4c">&lt;code&gt;</bpt>SELECT &lt;column_name&gt;, count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by &lt;column_name&gt;<ept id="c0f17bdb-029c-4ca7-a974-7ae0cc203c4c">&lt;/code&gt;</ept></source>
          <target state="new">Get the distribution for numerical columns  
<bpt id="c0f17bdb-029c-4ca7-a974-7ae0cc203c4c">&lt;code&gt;</bpt>SELECT &lt;column_name&gt;, count(*) from &lt;databasename&gt;.&lt;tablename&gt; group by &lt;column_name&gt;<ept id="c0f17bdb-029c-4ca7-a974-7ae0cc203c4c">&lt;/code&gt;</ept></target>
        </trans-unit>
        <trans-unit id="fda3d5e4-8dc5-409b-9153-613489510572" xml:space="preserve">
          <source>Extract records from joining two tables</source>
          <target state="new">Extract records from joining two tables</target>
        </trans-unit>
        <trans-unit id="daf2be9b-4bae-4a53-a07d-3f6439110d83" xml:space="preserve">
          <source>In this section, we describe ways of generating features using Hive queries.</source>
          <target state="new">In this section, we describe ways of generating features using Hive queries.</target>
        </trans-unit>
        <trans-unit id="b8da186a-8692-40d7-9c1e-0a551b6e7509" xml:space="preserve">
          <source>The sample Hive queries in this section assumes that the data has been uploaded to Hive tables in Azure HDInsight Hadoop clusters.</source>
          <target state="new">The sample Hive queries in this section assumes that the data has been uploaded to Hive tables in Azure HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="f4424430-ea4c-473d-8049-3ea4d6729610" xml:space="preserve">
          <source>If it has not, please follow <bpt id="da29eb88-e135-4943-a777-8c576501e20d">&lt;linkText&gt;</bpt>Create and load data to Hive tables<ept id="da29eb88-e135-4943-a777-8c576501e20d">&lt;/linkText&gt;</ept><bpt id="da29eb88-e135-4943-a777-8c576501e20d">&lt;title&gt;</bpt><ept id="da29eb88-e135-4943-a777-8c576501e20d">&lt;/title&gt;</ept> to upload data to Hive tables first.</source>
          <target state="new">If it has not, please follow <bpt id="da29eb88-e135-4943-a777-8c576501e20d">&lt;linkText&gt;</bpt>Create and load data to Hive tables<ept id="da29eb88-e135-4943-a777-8c576501e20d">&lt;/linkText&gt;</ept><bpt id="da29eb88-e135-4943-a777-8c576501e20d">&lt;title&gt;</bpt><ept id="da29eb88-e135-4943-a777-8c576501e20d">&lt;/title&gt;</ept> to upload data to Hive tables first.</target>
        </trans-unit>
        <trans-unit id="efa325c0-713e-4828-b388-2a4917727c29" xml:space="preserve">
          <source>Once you have generated additional features, you can either add them as columns to the existing table or create a new table with the additional features and primary key, which can then be joined with the original table.</source>
          <target state="new">Once you have generated additional features, you can either add them as columns to the existing table or create a new table with the additional features and primary key, which can then be joined with the original table.</target>
        </trans-unit>
        <trans-unit id="b8f0eb97-4af2-42b3-96c3-2c242cc9580d" xml:space="preserve">
          <source><bpt id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;linkText&gt;</bpt>Frequency based Feature Generation<ept id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;/linkText&gt;</ept><bpt id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;title&gt;</bpt><ept id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;linkText&gt;</bpt>Frequency based Feature Generation<ept id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;/linkText&gt;</ept><bpt id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;title&gt;</bpt><ept id="e18a0b81-9f1d-4613-a685-e7c248af9051">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="a1638035-8622-4313-931c-a31c77e85b46" xml:space="preserve">
          <source><bpt id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;linkText&gt;</bpt>Risks of Categorical Variables in Binary Classification<ept id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;/linkText&gt;</ept><bpt id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;title&gt;</bpt><ept id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;linkText&gt;</bpt>Risks of Categorical Variables in Binary Classification<ept id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;/linkText&gt;</ept><bpt id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;title&gt;</bpt><ept id="7d897b29-2bfc-41f9-80d7-eb8020dff022">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="afa9c28e-c9fa-4113-b56c-969ee73c834b" xml:space="preserve">
          <source><bpt id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;linkText&gt;</bpt>Extract features from Datetime Field<ept id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;/linkText&gt;</ept><bpt id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;title&gt;</bpt><ept id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;linkText&gt;</bpt>Extract features from Datetime Field<ept id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;/linkText&gt;</ept><bpt id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;title&gt;</bpt><ept id="cecbdbdf-4805-4863-a877-5a9ce17ed4b6">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="583077ed-c1e8-4925-a649-c12850d5ef38" xml:space="preserve">
          <source><bpt id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;linkText&gt;</bpt>Extract features from Text Field<ept id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;/linkText&gt;</ept><bpt id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;title&gt;</bpt><ept id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;linkText&gt;</bpt>Extract features from Text Field<ept id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;/linkText&gt;</ept><bpt id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;title&gt;</bpt><ept id="f34404f1-800d-4615-bd6e-78e73684cfcd">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="7513e77b-fca8-4af7-8b6e-9f59e4647c55" xml:space="preserve">
          <source><bpt id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;linkText&gt;</bpt>Calculate distance between GPS coordinates<ept id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;/linkText&gt;</ept><bpt id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;title&gt;</bpt><ept id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;linkText&gt;</bpt>Calculate distance between GPS coordinates<ept id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;/linkText&gt;</ept><bpt id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;title&gt;</bpt><ept id="1c691e7f-3ea4-42e9-a61b-ecd7f3dcba2f">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="94190c24-4fbb-4062-b868-04b7d9552143" xml:space="preserve">
          <source>It is often useful to calculate the frequencies of the levels of a categorical variable, or the frequencies of certain combinations of levels from multiple categorical variables.</source>
          <target state="new">It is often useful to calculate the frequencies of the levels of a categorical variable, or the frequencies of certain combinations of levels from multiple categorical variables.</target>
        </trans-unit>
        <trans-unit id="8e646ab0-ddab-45f9-8949-affca613fb91" xml:space="preserve">
          <source>Users can use the following script to calculate these frequencies:</source>
          <target state="new">Users can use the following script to calculate these frequencies:</target>
        </trans-unit>
        <trans-unit id="a238e9af-ae50-4861-bae1-3329ae65d591" xml:space="preserve">
          <source>In binary classification, we need to convert non-numeric categorical variables into numeric features when the models being used only take numeric features.</source>
          <target state="new">In binary classification, we need to convert non-numeric categorical variables into numeric features when the models being used only take numeric features.</target>
        </trans-unit>
        <trans-unit id="d863cced-c78d-42f5-907f-3412c026e49a" xml:space="preserve">
          <source>This is done by replacing each non-numeric level with a numeric risk.</source>
          <target state="new">This is done by replacing each non-numeric level with a numeric risk.</target>
        </trans-unit>
        <trans-unit id="4017fcb4-fee1-43c7-88f1-d0a055cd67a6" xml:space="preserve">
          <source>In this section, we show some generic Hive queries that calculate the risk values (log odds) of a categorical variable.</source>
          <target state="new">In this section, we show some generic Hive queries that calculate the risk values (log odds) of a categorical variable.</target>
        </trans-unit>
        <trans-unit id="f64b3967-341c-492c-8e6c-2f1f5f0ab7a8" xml:space="preserve">
          <source>In this example, variables <bpt id="bc370847-61e3-4f1b-a093-4edd5a0ffaff">&lt;code&gt;</bpt>smooth_param1<ept id="bc370847-61e3-4f1b-a093-4edd5a0ffaff">&lt;/code&gt;</ept> and <bpt id="0644d507-7d0f-444d-a2b4-c3950eaca18c">&lt;code&gt;</bpt>smooth_param2<ept id="0644d507-7d0f-444d-a2b4-c3950eaca18c">&lt;/code&gt;</ept> are set to smooth the risk values calculated from the data.</source>
          <target state="new">In this example, variables <bpt id="bc370847-61e3-4f1b-a093-4edd5a0ffaff">&lt;code&gt;</bpt>smooth_param1<ept id="bc370847-61e3-4f1b-a093-4edd5a0ffaff">&lt;/code&gt;</ept> and <bpt id="0644d507-7d0f-444d-a2b4-c3950eaca18c">&lt;code&gt;</bpt>smooth_param2<ept id="0644d507-7d0f-444d-a2b4-c3950eaca18c">&lt;/code&gt;</ept> are set to smooth the risk values calculated from the data.</target>
        </trans-unit>
        <trans-unit id="bf6e4ed3-e5d7-48d4-a5fd-8ac350bc1c71" xml:space="preserve">
          <source>Risks have a range between -Inf and Inf.</source>
          <target state="new">Risks have a range between -Inf and Inf.</target>
        </trans-unit>
        <trans-unit id="fc9e4a13-12cb-4861-b0a4-00c8845e826c" xml:space="preserve">
          <source>A risks &gt; 0 indicates that the probability that the target is equal to 1 is greater than 0.5.</source>
          <target state="new">A risks &gt; 0 indicates that the probability that the target is equal to 1 is greater than 0.5.</target>
        </trans-unit>
        <trans-unit id="c01e685c-d3d1-40b9-b579-c0e5f8e100be" xml:space="preserve">
          <source>After the risk table is calculated, users can assign risk values to a table by joining it with the risk table.</source>
          <target state="new">After the risk table is calculated, users can assign risk values to a table by joining it with the risk table.</target>
        </trans-unit>
        <trans-unit id="9164b009-c314-49d3-8aba-09a088fe07bc" xml:space="preserve">
          <source>The Hive joining query was provided in previous section.</source>
          <target state="new">The Hive joining query was provided in previous section.</target>
        </trans-unit>
        <trans-unit id="a07c9862-7535-4a4a-9fcf-2510c9991825" xml:space="preserve">
          <source>Hive comes with a set of UDFs for processing datetime fields.</source>
          <target state="new">Hive comes with a set of UDFs for processing datetime fields.</target>
        </trans-unit>
        <trans-unit id="fc283ca9-14ee-4939-ab3c-b4e2b20a5298" xml:space="preserve">
          <source>In Hive, the default datetime format is 'yyyy-MM-dd 00:00:00' ('1970-01-01 12:21:32' for example).</source>
          <target state="new">In Hive, the default datetime format is 'yyyy-MM-dd 00:00:00' ('1970-01-01 12:21:32' for example).</target>
        </trans-unit>
        <trans-unit id="b47ca3a1-74b9-4a84-9504-13ad67c01396" xml:space="preserve">
          <source>In this section, we show examples that extract the day of a month, the month from a datetime field, and other examples that convert a datetime string in a format other than the default format to a datetime string in default format.</source>
          <target state="new">In this section, we show examples that extract the day of a month, the month from a datetime field, and other examples that convert a datetime string in a format other than the default format to a datetime string in default format.</target>
        </trans-unit>
        <trans-unit id="7057ba27-4def-4aa9-be48-5febdd768be9" xml:space="preserve">
          <source>This Hive query assumes that the <bpt id="3f9be871-f370-4e8c-abb1-b7eeaf6cf641">&lt;em&gt;</bpt>&amp;#60;datetime field&gt;<ept id="3f9be871-f370-4e8c-abb1-b7eeaf6cf641">&lt;/em&gt;</ept> is in the default datetime format.</source>
          <target state="new">This Hive query assumes that the <bpt id="3f9be871-f370-4e8c-abb1-b7eeaf6cf641">&lt;em&gt;</bpt>&amp;#60;datetime field&gt;<ept id="3f9be871-f370-4e8c-abb1-b7eeaf6cf641">&lt;/em&gt;</ept> is in the default datetime format.</target>
        </trans-unit>
        <trans-unit id="80a4773d-d43f-4818-bb3f-556232dc3d88" xml:space="preserve">
          <source>If a datetime field is not in the default format, you need to convert the datetime field into Unix time stamp first, and then convert the Unix time stamp to a datetime string that is in the default format.</source>
          <target state="new">If a datetime field is not in the default format, you need to convert the datetime field into Unix time stamp first, and then convert the Unix time stamp to a datetime string that is in the default format.</target>
        </trans-unit>
        <trans-unit id="2386cd04-5da9-4fbb-8a5e-c8516580cd55" xml:space="preserve">
          <source>When the datetime is in default format, users can apply the embedded datetime UDFs to extract features.</source>
          <target state="new">When the datetime is in default format, users can apply the embedded datetime UDFs to extract features.</target>
        </trans-unit>
        <trans-unit id="d58c85af-7081-4614-9485-7b6b4cf1e47a" xml:space="preserve">
          <source>In this query, if the <bpt id="f12d3bbc-4651-4fd3-86b4-296b834ccb1f">&lt;em&gt;</bpt>&amp;#60;datetime field&gt;<ept id="f12d3bbc-4651-4fd3-86b4-296b834ccb1f">&lt;/em&gt;</ept> has the pattern like <bpt id="92ce57a6-b2ef-4df1-aefb-6c6f0faa15ca">&lt;em&gt;</bpt>03/26/2015 12:04:39<ept id="92ce57a6-b2ef-4df1-aefb-6c6f0faa15ca">&lt;/em&gt;</ept>, the <bpt id="da0e88dc-db08-4b29-aeee-4ab6387b202e">&lt;em&gt;</bpt>'&amp;#60;pattern of the datetime field&gt;'<ept id="da0e88dc-db08-4b29-aeee-4ab6387b202e">&lt;/em&gt;</ept> should be <bpt id="0bc39d81-7d61-43df-b741-cf751f767330">&lt;code&gt;</bpt>'MM/dd/yyyy HH:mm:ss'<ept id="0bc39d81-7d61-43df-b741-cf751f767330">&lt;/code&gt;</ept>.</source>
          <target state="new">In this query, if the <bpt id="f12d3bbc-4651-4fd3-86b4-296b834ccb1f">&lt;em&gt;</bpt>&amp;#60;datetime field&gt;<ept id="f12d3bbc-4651-4fd3-86b4-296b834ccb1f">&lt;/em&gt;</ept> has the pattern like <bpt id="92ce57a6-b2ef-4df1-aefb-6c6f0faa15ca">&lt;em&gt;</bpt>03/26/2015 12:04:39<ept id="92ce57a6-b2ef-4df1-aefb-6c6f0faa15ca">&lt;/em&gt;</ept>, the <bpt id="da0e88dc-db08-4b29-aeee-4ab6387b202e">&lt;em&gt;</bpt>'&amp;#60;pattern of the datetime field&gt;'<ept id="da0e88dc-db08-4b29-aeee-4ab6387b202e">&lt;/em&gt;</ept> should be <bpt id="0bc39d81-7d61-43df-b741-cf751f767330">&lt;code&gt;</bpt>'MM/dd/yyyy HH:mm:ss'<ept id="0bc39d81-7d61-43df-b741-cf751f767330">&lt;/code&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="5be549d1-ed35-483d-95ec-0501e6f039dc" xml:space="preserve">
          <source>To test it, users can run</source>
          <target state="new">To test it, users can run</target>
        </trans-unit>
        <trans-unit id="0ca9ac3d-f950-4b0a-bc4d-8ef35c388ef1" xml:space="preserve">
          <source>The <bpt id="9a44f56f-f6ab-4801-9cce-4a6f0ae6e188">&lt;em&gt;</bpt>hivesampletable<ept id="9a44f56f-f6ab-4801-9cce-4a6f0ae6e188">&lt;/em&gt;</ept> in this query comes preinstalled on all Azure HDInsight Hadoop clusters by default when the clusters are provisioned.</source>
          <target state="new">The <bpt id="9a44f56f-f6ab-4801-9cce-4a6f0ae6e188">&lt;em&gt;</bpt>hivesampletable<ept id="9a44f56f-f6ab-4801-9cce-4a6f0ae6e188">&lt;/em&gt;</ept> in this query comes preinstalled on all Azure HDInsight Hadoop clusters by default when the clusters are provisioned.</target>
        </trans-unit>
        <trans-unit id="3f3cf295-8404-49c5-8dc7-d1f1fb4f1eed" xml:space="preserve">
          <source>When the Hive table has a text field that contains a string of words that are delimited by spaces, the following query extracts the length of the string, and the number of words in the string.</source>
          <target state="new">When the Hive table has a text field that contains a string of words that are delimited by spaces, the following query extracts the length of the string, and the number of words in the string.</target>
        </trans-unit>
        <trans-unit id="6e751d99-e8f1-411e-bbf2-2ee886b1a20e" xml:space="preserve">
          <source>The query given in this section can be directly applied to the NYC Taxi Trip Data.</source>
          <target state="new">The query given in this section can be directly applied to the NYC Taxi Trip Data.</target>
        </trans-unit>
        <trans-unit id="c64d6bb0-1ddd-4482-80e7-b5fe670352a6" xml:space="preserve">
          <source>The purpose of this query is to show how to apply an embedded mathematical functions in Hive to generate features.</source>
          <target state="new">The purpose of this query is to show how to apply an embedded mathematical functions in Hive to generate features.</target>
        </trans-unit>
        <trans-unit id="ef802887-5229-4acb-8487-5282c8c14b0d" xml:space="preserve">
          <source>The fields that are used in this query are the GPS coordinates of pickup and dropoff locations, named <bpt id="8832d38a-2ee3-405e-b2f8-5f3869bf14c9">&lt;em&gt;</bpt>pickup\_longitude<ept id="8832d38a-2ee3-405e-b2f8-5f3869bf14c9">&lt;/em&gt;</ept>, <bpt id="023ced6d-c75b-4de0-804b-64d82e26547c">&lt;em&gt;</bpt>pickup\_latitude<ept id="023ced6d-c75b-4de0-804b-64d82e26547c">&lt;/em&gt;</ept>, <bpt id="f5e4926b-2ad5-4eae-80f8-583e97a831b1">&lt;em&gt;</bpt>dropoff\_longitude<ept id="f5e4926b-2ad5-4eae-80f8-583e97a831b1">&lt;/em&gt;</ept>, and <bpt id="c0050bbe-5019-45fb-8406-1b9ba4ed467d">&lt;em&gt;</bpt>dropoff\_latitude<ept id="c0050bbe-5019-45fb-8406-1b9ba4ed467d">&lt;/em&gt;</ept>.</source>
          <target state="new">The fields that are used in this query are the GPS coordinates of pickup and dropoff locations, named <bpt id="8832d38a-2ee3-405e-b2f8-5f3869bf14c9">&lt;em&gt;</bpt>pickup\_longitude<ept id="8832d38a-2ee3-405e-b2f8-5f3869bf14c9">&lt;/em&gt;</ept>, <bpt id="023ced6d-c75b-4de0-804b-64d82e26547c">&lt;em&gt;</bpt>pickup\_latitude<ept id="023ced6d-c75b-4de0-804b-64d82e26547c">&lt;/em&gt;</ept>, <bpt id="f5e4926b-2ad5-4eae-80f8-583e97a831b1">&lt;em&gt;</bpt>dropoff\_longitude<ept id="f5e4926b-2ad5-4eae-80f8-583e97a831b1">&lt;/em&gt;</ept>, and <bpt id="c0050bbe-5019-45fb-8406-1b9ba4ed467d">&lt;em&gt;</bpt>dropoff\_latitude<ept id="c0050bbe-5019-45fb-8406-1b9ba4ed467d">&lt;/em&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="d6ff2729-0616-40d0-bf8d-6047ec0a8217" xml:space="preserve">
          <source>The queries that calculate the direct distance between the pickup and dropoff coordinates are:</source>
          <target state="new">The queries that calculate the direct distance between the pickup and dropoff coordinates are:</target>
        </trans-unit>
        <trans-unit id="3c47875f-2fd2-4768-bd83-a69601c68750" xml:space="preserve">
          <source>The mathematical equations that calculate the distance between two GPS coordinates can be found on the &lt;a href="http://www.movable-type.co.uk/scripts/latlong.html" target="_blank"&gt;Movable Type Scripts&lt;/a&gt; site, authored by Peter Lapisu.</source>
          <target state="new">The mathematical equations that calculate the distance between two GPS coordinates can be found on the &lt;a href="http://www.movable-type.co.uk/scripts/latlong.html" target="_blank"&gt;Movable Type Scripts&lt;/a&gt; site, authored by Peter Lapisu.</target>
        </trans-unit>
        <trans-unit id="aa9976ac-026a-41fa-a027-05756dfb1385" xml:space="preserve">
          <source>In his Javascript, the function <bpt id="c0abf2ed-99ab-4ec8-a7f8-517128b7c17d">&lt;code&gt;</bpt>toRad()<ept id="c0abf2ed-99ab-4ec8-a7f8-517128b7c17d">&lt;/code&gt;</ept> is just <bpt id="f4b50d04-74ad-41b8-af3b-b96ce97afe67">&lt;em&gt;</bpt>lat_or_lon<ept id="f4b50d04-74ad-41b8-af3b-b96ce97afe67">&lt;/em&gt;</ept>pi/180*, which converts degrees to radians.</source>
          <target state="new">In his Javascript, the function <bpt id="c0abf2ed-99ab-4ec8-a7f8-517128b7c17d">&lt;code&gt;</bpt>toRad()<ept id="c0abf2ed-99ab-4ec8-a7f8-517128b7c17d">&lt;/code&gt;</ept> is just <bpt id="f4b50d04-74ad-41b8-af3b-b96ce97afe67">&lt;em&gt;</bpt>lat_or_lon<ept id="f4b50d04-74ad-41b8-af3b-b96ce97afe67">&lt;/em&gt;</ept>pi/180*, which converts degrees to radians.</target>
        </trans-unit>
        <trans-unit id="8e1bee7d-0eea-4b72-9d31-5ea419dd6d07" xml:space="preserve">
          <source>Here, <bpt id="fc446dc4-9716-4b6b-afdc-1ba9e0d7913d">&lt;em&gt;</bpt>lat_or_lon<ept id="fc446dc4-9716-4b6b-afdc-1ba9e0d7913d">&lt;/em&gt;</ept> is the latitude or longitude.</source>
          <target state="new">Here, <bpt id="fc446dc4-9716-4b6b-afdc-1ba9e0d7913d">&lt;em&gt;</bpt>lat_or_lon<ept id="fc446dc4-9716-4b6b-afdc-1ba9e0d7913d">&lt;/em&gt;</ept> is the latitude or longitude.</target>
        </trans-unit>
        <trans-unit id="782195f3-9da0-4352-968c-d8001a575040" xml:space="preserve">
          <source>Since Hive does not provide the function <bpt id="ef97b232-ec58-4828-8824-11283d6ba1dc">&lt;code&gt;</bpt>atan2<ept id="ef97b232-ec58-4828-8824-11283d6ba1dc">&lt;/code&gt;</ept>, but provides the function <bpt id="bbc58840-6cbb-4976-a4c0-b3c9bf8b255b">&lt;code&gt;</bpt>atan<ept id="bbc58840-6cbb-4976-a4c0-b3c9bf8b255b">&lt;/code&gt;</ept>, the <bpt id="b4bcecf9-786a-4a2b-819a-f93a2b4c2775">&lt;code&gt;</bpt>atan2<ept id="b4bcecf9-786a-4a2b-819a-f93a2b4c2775">&lt;/code&gt;</ept> function is implemented by <bpt id="3f159e9b-601d-4d67-91f1-9d16e8b8f299">&lt;code&gt;</bpt>atan<ept id="3f159e9b-601d-4d67-91f1-9d16e8b8f299">&lt;/code&gt;</ept> function in the above Hive query using the definition provided in &lt;a href="http://en.wikipedia.org/wiki/Atan2" target="_blank"&gt;Wikipedia&lt;/a&gt;.</source>
          <target state="new">Since Hive does not provide the function <bpt id="ef97b232-ec58-4828-8824-11283d6ba1dc">&lt;code&gt;</bpt>atan2<ept id="ef97b232-ec58-4828-8824-11283d6ba1dc">&lt;/code&gt;</ept>, but provides the function <bpt id="bbc58840-6cbb-4976-a4c0-b3c9bf8b255b">&lt;code&gt;</bpt>atan<ept id="bbc58840-6cbb-4976-a4c0-b3c9bf8b255b">&lt;/code&gt;</ept>, the <bpt id="b4bcecf9-786a-4a2b-819a-f93a2b4c2775">&lt;code&gt;</bpt>atan2<ept id="b4bcecf9-786a-4a2b-819a-f93a2b4c2775">&lt;/code&gt;</ept> function is implemented by <bpt id="3f159e9b-601d-4d67-91f1-9d16e8b8f299">&lt;code&gt;</bpt>atan<ept id="3f159e9b-601d-4d67-91f1-9d16e8b8f299">&lt;/code&gt;</ept> function in the above Hive query using the definition provided in &lt;a href="http://en.wikipedia.org/wiki/Atan2" target="_blank"&gt;Wikipedia&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="b737b2a8-0eb5-431d-90b0-b950e72fb715" xml:space="preserve">
          <source><bpt id="fb13625e-2831-4b3a-931d-d0042a577da2">&lt;linkText&gt;</bpt>Create workspace<ept id="fb13625e-2831-4b3a-931d-d0042a577da2">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="fb13625e-2831-4b3a-931d-d0042a577da2">&lt;linkText&gt;</bpt>Create workspace<ept id="fb13625e-2831-4b3a-931d-d0042a577da2">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="ed40d9f7-1e8c-468f-a969-7987ac3aa67f" xml:space="preserve">
          <source>A full list of Hive embedded UDFs can be found in the <bpt id="2f70e0a8-ea85-4145-989e-85c54075f89e">&lt;strong&gt;</bpt>Built-in Functions<ept id="2f70e0a8-ea85-4145-989e-85c54075f89e">&lt;/strong&gt;</ept> section on the &lt;a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-MathematicalFunctions" target="_blank"&gt;Apache Hive wiki&lt;/a&gt;).</source>
          <target state="new">A full list of Hive embedded UDFs can be found in the <bpt id="2f70e0a8-ea85-4145-989e-85c54075f89e">&lt;strong&gt;</bpt>Built-in Functions<ept id="2f70e0a8-ea85-4145-989e-85c54075f89e">&lt;/strong&gt;</ept> section on the &lt;a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-MathematicalFunctions" target="_blank"&gt;Apache Hive wiki&lt;/a&gt;).</target>
        </trans-unit>
        <trans-unit id="5572b0fc-5719-4c1f-88aa-5e9a080381f7" xml:space="preserve">
          <source>The default parameter settings of Hive cluster might not be suitable for the Hive queries and the data that the queries are processing.</source>
          <target state="new">The default parameter settings of Hive cluster might not be suitable for the Hive queries and the data that the queries are processing.</target>
        </trans-unit>
        <trans-unit id="bd71fb64-b9e0-4694-807d-9f04e8ecbf4d" xml:space="preserve">
          <source>In this section, we discuss some parameters that users can tune that improve the performance of Hive queries.</source>
          <target state="new">In this section, we discuss some parameters that users can tune that improve the performance of Hive queries.</target>
        </trans-unit>
        <trans-unit id="d20a04d0-2a17-49d5-ad0b-7b8f71cd1a44" xml:space="preserve">
          <source>Users need to add the parameter tuning queries before the queries of processing data.</source>
          <target state="new">Users need to add the parameter tuning queries before the queries of processing data.</target>
        </trans-unit>
        <trans-unit id="bde92f1a-6833-4e0c-bf0c-3c0720e88b5e" xml:space="preserve">
          <source><bpt id="ea2a2b0b-7f10-4b11-8f53-9b8b2ef36573">&lt;strong&gt;</bpt>Java heap space<ept id="ea2a2b0b-7f10-4b11-8f53-9b8b2ef36573">&lt;/strong&gt;</ept>: For queries involving joining large datasets, or processing long records, <bpt id="49c52257-f016-4aa1-81f3-5c538cb19c24">&lt;strong&gt;</bpt>running out of heap space<ept id="49c52257-f016-4aa1-81f3-5c538cb19c24">&lt;/strong&gt;</ept> is one of the common error.</source>
          <target state="new"><bpt id="ea2a2b0b-7f10-4b11-8f53-9b8b2ef36573">&lt;strong&gt;</bpt>Java heap space<ept id="ea2a2b0b-7f10-4b11-8f53-9b8b2ef36573">&lt;/strong&gt;</ept>: For queries involving joining large datasets, or processing long records, <bpt id="49c52257-f016-4aa1-81f3-5c538cb19c24">&lt;strong&gt;</bpt>running out of heap space<ept id="49c52257-f016-4aa1-81f3-5c538cb19c24">&lt;/strong&gt;</ept> is one of the common error.</target>
        </trans-unit>
        <trans-unit id="ad21a970-6c1a-4424-8435-ab2d73ea0720" xml:space="preserve">
          <source>This can be tuned by setting parameters <bpt id="e3366b5e-7b6c-4773-96c5-eb4b0423bf62">&lt;em&gt;</bpt>mapreduce.map.java.opts<ept id="e3366b5e-7b6c-4773-96c5-eb4b0423bf62">&lt;/em&gt;</ept> and <bpt id="fadf47fd-5322-40a7-b1c2-fb573722545c">&lt;em&gt;</bpt>mapreduce.task.io.sort.mb<ept id="fadf47fd-5322-40a7-b1c2-fb573722545c">&lt;/em&gt;</ept> to desired values.</source>
          <target state="new">This can be tuned by setting parameters <bpt id="e3366b5e-7b6c-4773-96c5-eb4b0423bf62">&lt;em&gt;</bpt>mapreduce.map.java.opts<ept id="e3366b5e-7b6c-4773-96c5-eb4b0423bf62">&lt;/em&gt;</ept> and <bpt id="fadf47fd-5322-40a7-b1c2-fb573722545c">&lt;em&gt;</bpt>mapreduce.task.io.sort.mb<ept id="fadf47fd-5322-40a7-b1c2-fb573722545c">&lt;/em&gt;</ept> to desired values.</target>
        </trans-unit>
        <trans-unit id="98012bdc-0489-4932-98f1-6e342c55e805" xml:space="preserve">
          <source>Here is an example:</source>
          <target state="new">Here is an example:</target>
        </trans-unit>
        <trans-unit id="5976063a-a83f-4583-886e-57be92b1aa18" xml:space="preserve">
          <source>This parameter allocates 4GB memory to Java heap space and also makes sorting more efficient by allocating more memory for it.</source>
          <target state="new">This parameter allocates 4GB memory to Java heap space and also makes sorting more efficient by allocating more memory for it.</target>
        </trans-unit>
        <trans-unit id="c078f93f-bbfc-4eda-a676-a419e5701242" xml:space="preserve">
          <source>It is a good idea to play with these allocations if there are any job failure errors related to heap space.</source>
          <target state="new">It is a good idea to play with these allocations if there are any job failure errors related to heap space.</target>
        </trans-unit>
        <trans-unit id="1a35e9ee-3a75-41e5-bca9-573cbfe1c6f3" xml:space="preserve">
          <source><bpt id="cc537a4a-670a-4936-a5ea-3d3a5aa223ad">&lt;strong&gt;</bpt>DFS block size<ept id="cc537a4a-670a-4936-a5ea-3d3a5aa223ad">&lt;/strong&gt;</ept> : This parameter sets the smallest unit of data that the file system stores.</source>
          <target state="new"><bpt id="cc537a4a-670a-4936-a5ea-3d3a5aa223ad">&lt;strong&gt;</bpt>DFS block size<ept id="cc537a4a-670a-4936-a5ea-3d3a5aa223ad">&lt;/strong&gt;</ept> : This parameter sets the smallest unit of data that the file system stores.</target>
        </trans-unit>
        <trans-unit id="c1138531-8b43-4349-b94f-50d5c3c1481d" xml:space="preserve">
          <source>As an example, if the DFS block size is 128MB, then any data of size less than and up to 128MB is stored in a single block, while data that is larger than 128MB is allotted extra blocks.</source>
          <target state="new">As an example, if the DFS block size is 128MB, then any data of size less than and up to 128MB is stored in a single block, while data that is larger than 128MB is allotted extra blocks.</target>
        </trans-unit>
        <trans-unit id="66401e42-63a6-4b7c-a9c6-c4458e81112b" xml:space="preserve">
          <source>Choosing a very small block size causes large overheads in Hadoop since the name node has to process many more requests to find the relevant block pertaining to the file.</source>
          <target state="new">Choosing a very small block size causes large overheads in Hadoop since the name node has to process many more requests to find the relevant block pertaining to the file.</target>
        </trans-unit>
        <trans-unit id="5c7f7af0-e18b-48ff-b8d9-ba052bcbce01" xml:space="preserve">
          <source>A recommended setting when dealing with gigabytes (or larger) data is :</source>
          <target state="new">A recommended setting when dealing with gigabytes (or larger) data is :</target>
        </trans-unit>
        <trans-unit id="5b07fb52-bf90-45fc-a96b-06979bea9830" xml:space="preserve">
          <source><bpt id="cc3ee201-2932-47a3-983e-cb464e08853c">&lt;strong&gt;</bpt>Optimizing join operation in Hive<ept id="cc3ee201-2932-47a3-983e-cb464e08853c">&lt;/strong&gt;</ept> : While join operations in the map/reduce framework typically take place in the reduce phase, sometimes, enormous gains can be achieved by scheduling joins in the map phase (also called "mapjoins").</source>
          <target state="new"><bpt id="cc3ee201-2932-47a3-983e-cb464e08853c">&lt;strong&gt;</bpt>Optimizing join operation in Hive<ept id="cc3ee201-2932-47a3-983e-cb464e08853c">&lt;/strong&gt;</ept> : While join operations in the map/reduce framework typically take place in the reduce phase, sometimes, enormous gains can be achieved by scheduling joins in the map phase (also called "mapjoins").</target>
        </trans-unit>
        <trans-unit id="ffc1325b-8c10-4e51-8f74-e43047612b6c" xml:space="preserve">
          <source>To direct Hive to do this whenever possible, we can set :</source>
          <target state="new">To direct Hive to do this whenever possible, we can set :</target>
        </trans-unit>
        <trans-unit id="02312273-57e9-4a01-bbff-b037938bedcb" xml:space="preserve">
          <source><bpt id="d9a0b7d7-1c1d-482a-bc09-a3fae8a98ad9">&lt;strong&gt;</bpt>Specifying the number of mappers to Hive<ept id="d9a0b7d7-1c1d-482a-bc09-a3fae8a98ad9">&lt;/strong&gt;</ept> : While Hadoop allows the user to set the number of reducers, the number of mappers is typically not be set by the user.</source>
          <target state="new"><bpt id="d9a0b7d7-1c1d-482a-bc09-a3fae8a98ad9">&lt;strong&gt;</bpt>Specifying the number of mappers to Hive<ept id="d9a0b7d7-1c1d-482a-bc09-a3fae8a98ad9">&lt;/strong&gt;</ept> : While Hadoop allows the user to set the number of reducers, the number of mappers is typically not be set by the user.</target>
        </trans-unit>
        <trans-unit id="9f1da849-472f-4b00-8d83-75ca3c11a8dd" xml:space="preserve">
          <source>A trick that allows some degree of control on this number is to choose the Hadoop variables, <bpt id="6de64329-8c9e-4e94-96a7-8263816af69e">&lt;em&gt;</bpt>mapred.min.split.size<ept id="6de64329-8c9e-4e94-96a7-8263816af69e">&lt;/em&gt;</ept> and <bpt id="d9c576bf-15ce-424a-8e18-74cdef77f7da">&lt;em&gt;</bpt>mapred.max.split.size<ept id="d9c576bf-15ce-424a-8e18-74cdef77f7da">&lt;/em&gt;</ept> as the size of each map task is determined by :</source>
          <target state="new">A trick that allows some degree of control on this number is to choose the Hadoop variables, <bpt id="6de64329-8c9e-4e94-96a7-8263816af69e">&lt;em&gt;</bpt>mapred.min.split.size<ept id="6de64329-8c9e-4e94-96a7-8263816af69e">&lt;/em&gt;</ept> and <bpt id="d9c576bf-15ce-424a-8e18-74cdef77f7da">&lt;em&gt;</bpt>mapred.max.split.size<ept id="d9c576bf-15ce-424a-8e18-74cdef77f7da">&lt;/em&gt;</ept> as the size of each map task is determined by :</target>
        </trans-unit>
        <trans-unit id="cdf98c7d-babc-41ef-a0f6-ac286ec9f672" xml:space="preserve">
          <source>Typically, the default value of <bpt id="881d00e3-bf84-4fb3-b875-524f8b9fb975">&lt;em&gt;</bpt>mapred.min.split.size<ept id="881d00e3-bf84-4fb3-b875-524f8b9fb975">&lt;/em&gt;</ept> is 0, that of <bpt id="cd8496c2-881a-4ea3-9d55-2fa7931e1e32">&lt;em&gt;</bpt>mapred.max.split.size<ept id="cd8496c2-881a-4ea3-9d55-2fa7931e1e32">&lt;/em&gt;</ept> is <bpt id="db5b7189-77df-4d52-896b-f26db4d13db6">&lt;strong&gt;</bpt>Long.MAX<ept id="db5b7189-77df-4d52-896b-f26db4d13db6">&lt;/strong&gt;</ept> and that of <bpt id="10794e46-548b-4f8a-9656-7fbb41a8fa92">&lt;em&gt;</bpt>dfs.block.size<ept id="10794e46-548b-4f8a-9656-7fbb41a8fa92">&lt;/em&gt;</ept> is 64MB.</source>
          <target state="new">Typically, the default value of <bpt id="881d00e3-bf84-4fb3-b875-524f8b9fb975">&lt;em&gt;</bpt>mapred.min.split.size<ept id="881d00e3-bf84-4fb3-b875-524f8b9fb975">&lt;/em&gt;</ept> is 0, that of <bpt id="cd8496c2-881a-4ea3-9d55-2fa7931e1e32">&lt;em&gt;</bpt>mapred.max.split.size<ept id="cd8496c2-881a-4ea3-9d55-2fa7931e1e32">&lt;/em&gt;</ept> is <bpt id="db5b7189-77df-4d52-896b-f26db4d13db6">&lt;strong&gt;</bpt>Long.MAX<ept id="db5b7189-77df-4d52-896b-f26db4d13db6">&lt;/strong&gt;</ept> and that of <bpt id="10794e46-548b-4f8a-9656-7fbb41a8fa92">&lt;em&gt;</bpt>dfs.block.size<ept id="10794e46-548b-4f8a-9656-7fbb41a8fa92">&lt;/em&gt;</ept> is 64MB.</target>
        </trans-unit>
        <trans-unit id="6c9bc711-095f-4708-b6eb-ac8f38b007f6" xml:space="preserve">
          <source>As we can see, given the data size, tuning these parameters by "setting" them allows us to tune the number of mappers used.</source>
          <target state="new">As we can see, given the data size, tuning these parameters by "setting" them allows us to tune the number of mappers used.</target>
        </trans-unit>
        <trans-unit id="fc4c6432-832b-4ed9-bb5e-ca1c9a1142af" xml:space="preserve">
          <source>A few other more <bpt id="83697ffd-f76c-4c11-9ffd-642158ad6ee2">&lt;strong&gt;</bpt>advanced options<ept id="83697ffd-f76c-4c11-9ffd-642158ad6ee2">&lt;/strong&gt;</ept> for optimizing Hive performance are mentioned below.</source>
          <target state="new">A few other more <bpt id="83697ffd-f76c-4c11-9ffd-642158ad6ee2">&lt;strong&gt;</bpt>advanced options<ept id="83697ffd-f76c-4c11-9ffd-642158ad6ee2">&lt;/strong&gt;</ept> for optimizing Hive performance are mentioned below.</target>
        </trans-unit>
        <trans-unit id="ac797eaa-0dd7-428a-938a-d1147826f1fe" xml:space="preserve">
          <source>These allow you to set the memory allocated to map and reduce tasks, and can be useful in tweaking performance.</source>
          <target state="new">These allow you to set the memory allocated to map and reduce tasks, and can be useful in tweaking performance.</target>
        </trans-unit>
        <trans-unit id="eb7cd7ad-8516-4808-afac-84cc91c45c9a" xml:space="preserve">
          <source>Please keep in mind that the <bpt id="db518253-c2d1-4f9e-8f6a-1692ace58f07">&lt;em&gt;</bpt>mapreduce.reduce.memory.mb<ept id="db518253-c2d1-4f9e-8f6a-1692ace58f07">&lt;/em&gt;</ept> cannot be greater than the physical memory size of each worker node in the Hadoop cluster.</source>
          <target state="new">Please keep in mind that the <bpt id="db518253-c2d1-4f9e-8f6a-1692ace58f07">&lt;em&gt;</bpt>mapreduce.reduce.memory.mb<ept id="db518253-c2d1-4f9e-8f6a-1692ace58f07">&lt;/em&gt;</ept> cannot be greater than the physical memory size of each worker node in the Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="eb9c5820-b59e-4d82-bbbd-753cbbf5e53b" xml:space="preserve">
          <source>./media/machine-learning-data-science-process-hive-tables/atan2new.png</source>
          <target state="new">./media/machine-learning-data-science-process-hive-tables/atan2new.png</target>
        </trans-unit>
        <trans-unit id="8933c59d-faec-4596-b44f-b40d51e55ffb" xml:space="preserve">
          <source>./media/machine-learning-data-science-process-hive-tables/run-hive-queries-1.png</source>
          <target state="new">./media/machine-learning-data-science-process-hive-tables/run-hive-queries-1.png</target>
        </trans-unit>
        <trans-unit id="3549c34a-5811-46ce-a5e5-c66ac327d98f" xml:space="preserve">
          <source>./media/machine-learning-data-science-process-hive-tables/run-hive-queries-2.png</source>
          <target state="new">./media/machine-learning-data-science-process-hive-tables/run-hive-queries-2.png</target>
        </trans-unit>
        <trans-unit id="70a3053a-61b9-4668-af8f-3c1cd1c652a5" xml:space="preserve">
          <source>./media/machine-learning-data-science-process-hive-tables/output-hive-results-1.png</source>
          <target state="new">./media/machine-learning-data-science-process-hive-tables/output-hive-results-1.png</target>
        </trans-unit>
        <trans-unit id="9a0d2860-1390-4f0f-b407-2eb61e4d5643" xml:space="preserve">
          <source>./media/machine-learning-data-science-process-hive-tables/output-hive-results-2.png</source>
          <target state="new">./media/machine-learning-data-science-process-hive-tables/output-hive-results-2.png</target>
        </trans-unit>
        <trans-unit id="9021ba10-242d-46a5-84fd-d36024c2dc71" xml:space="preserve">
          <source>./media/machine-learning-data-science-process-hive-tables/output-hive-results-3.png</source>
          <target state="new">./media/machine-learning-data-science-process-hive-tables/output-hive-results-3.png</target>
        </trans-unit>
        <trans-unit id="aad5d6b2-9cf4-4d46-af83-5b4867db156e" xml:space="preserve">
          <source>./media/machine-learning-data-science-process-hive-tables/run-hive-queries-3.png</source>
          <target state="new">./media/machine-learning-data-science-process-hive-tables/run-hive-queries-3.png</target>
        </trans-unit>
      </group>
      <group id="5bff1c7a-46a4-4fe6-953b-f8d3f830fe4e" />
    </body>
  </file>
</xliff>