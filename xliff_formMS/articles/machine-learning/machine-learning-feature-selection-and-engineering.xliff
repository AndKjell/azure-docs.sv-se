<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="zh-cn" original="foo.file" tool-id="14bab268-dbaf-44f5-82f4-29effc6c501a" product-name="foo" product-version="1.0" build-num="1">
    <header>
      <tool tool-id="14bab268-dbaf-44f5-82f4-29effc6c501a" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group id="eb3be1bd-8168-4136-a6e3-1723b288d036">
        <trans-unit id="bb963118-65f7-4384-abe3-4a01c3a515b1" xml:space="preserve">
          <source>Feature Engineering and Selection in Azure Machine Learning | Microsoft Azure</source>
          <target state="new">Feature Engineering and Selection in Azure Machine Learning | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="6230b119-7667-46de-a07c-d6e6b6094b49" xml:space="preserve">
          <source>Explains the purposes of feature selection and feature engineering and provides examples of their role in the data enhancement process of machine learning.</source>
          <target state="new">Explains the purposes of feature selection and feature engineering and provides examples of their role in the data enhancement process of machine learning.</target>
        </trans-unit>
        <trans-unit id="b3190816-847d-40e2-9dfe-dcb250a6a98e" xml:space="preserve">
          <source>This topic explains the purposes of feature engineering and feature selection in the data enhancement process of machine learning.</source>
          <target state="new">This topic explains the purposes of feature engineering and feature selection in the data enhancement process of machine learning.</target>
        </trans-unit>
        <trans-unit id="ffc06e0f-3205-4714-88b3-33aeaa9779a9" xml:space="preserve">
          <source>It illustrates what these processes involve using examples provided by Azure Machine Learning Studio.</source>
          <target state="new">It illustrates what these processes involve using examples provided by Azure Machine Learning Studio.</target>
        </trans-unit>
        <trans-unit id="b774c496-d2bc-4cdb-b766-fb74acee5b5e" xml:space="preserve">
          <source><bpt id="6e837787-bd1c-42fa-9569-df44822d188e">&lt;token href="../../includes/machine-learning-free-trial.md"&gt;</bpt><ept id="6e837787-bd1c-42fa-9569-df44822d188e">&lt;/token&gt;</ept></source>
          <target state="new"><bpt id="6e837787-bd1c-42fa-9569-df44822d188e">&lt;token href="../../includes/machine-learning-free-trial.md"&gt;</bpt><ept id="6e837787-bd1c-42fa-9569-df44822d188e">&lt;/token&gt;</ept></target>
        </trans-unit>
        <trans-unit id="7005af81-64c1-4382-9969-5bec36c9e91c" xml:space="preserve">
          <source>The training data used in machine learning can often be enhanced by the selection or extraction of features from the raw data collected.</source>
          <target state="new">The training data used in machine learning can often be enhanced by the selection or extraction of features from the raw data collected.</target>
        </trans-unit>
        <trans-unit id="c61e769a-90c8-4206-b9f3-eddef0e11ee7" xml:space="preserve">
          <source>A  example of an engineered feature in the context of learning how to classify the images of handwritten characters is a bit density map constructed from the raw bit distribution data.</source>
          <target state="new">A  example of an engineered feature in the context of learning how to classify the images of handwritten characters is a bit density map constructed from the raw bit distribution data.</target>
        </trans-unit>
        <trans-unit id="ca1e4b32-9b78-4708-b427-a72ef8dca0f3" xml:space="preserve">
          <source>This map can help locate the edges of the characters more efficiently than the raw distribution.</source>
          <target state="new">This map can help locate the edges of the characters more efficiently than the raw distribution.</target>
        </trans-unit>
        <trans-unit id="7493300f-3982-4d51-b057-b9ecdaeddd82" xml:space="preserve">
          <source>Engineered and selected features increase the efficiency of the training process which attempts to extract the key information contained in the data.</source>
          <target state="new">Engineered and selected features increase the efficiency of the training process which attempts to extract the key information contained in the data.</target>
        </trans-unit>
        <trans-unit id="d55eb4c0-af03-467d-b42d-22d2220a54ac" xml:space="preserve">
          <source>They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</source>
          <target state="new">They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</target>
        </trans-unit>
        <trans-unit id="1c33e6b9-4612-4698-97f4-dac06358fc57" xml:space="preserve">
          <source>Feature engineering and selection can also combine to make the learning more computationally tractable.</source>
          <target state="new">Feature engineering and selection can also combine to make the learning more computationally tractable.</target>
        </trans-unit>
        <trans-unit id="4563710a-d957-46e1-9d5f-11204c37c6e4" xml:space="preserve">
          <source>It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</source>
          <target state="new">It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</target>
        </trans-unit>
        <trans-unit id="84f8c662-1a03-42ff-9902-5c425a8f3c57" xml:space="preserve">
          <source>Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</source>
          <target state="new">Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</target>
        </trans-unit>
        <trans-unit id="7c876ec8-a538-4080-be30-61c244e69151" xml:space="preserve">
          <source>The engineering and selection of features is one part of a larger process, which typically consists of four steps:</source>
          <target state="new">The engineering and selection of features is one part of a larger process, which typically consists of four steps:</target>
        </trans-unit>
        <trans-unit id="213debcd-71e1-4dc4-ab41-fc7561911220" xml:space="preserve">
          <source>data collection</source>
          <target state="new">data collection</target>
        </trans-unit>
        <trans-unit id="9a69c5a0-85f7-425b-8d08-f360ca609844" xml:space="preserve">
          <source>data enhancement</source>
          <target state="new">data enhancement</target>
        </trans-unit>
        <trans-unit id="c250ef51-fd17-44da-be5c-c1c030c6ed7a" xml:space="preserve">
          <source>model construction</source>
          <target state="new">model construction</target>
        </trans-unit>
        <trans-unit id="ae352d26-d9af-4723-aa94-b13d692b936b" xml:space="preserve">
          <source>post-processing</source>
          <target state="new">post-processing</target>
        </trans-unit>
        <trans-unit id="e3182f50-c510-47d3-a93a-ad7ec6c78286" xml:space="preserve">
          <source>Engineering and selection are the <bpt id="c9a266e3-76e7-4545-b90a-127d951f3e6b">&lt;strong&gt;</bpt>data enhancement<ept id="c9a266e3-76e7-4545-b90a-127d951f3e6b">&lt;/strong&gt;</ept> step of machine learning.</source>
          <target state="new">Engineering and selection are the <bpt id="c9a266e3-76e7-4545-b90a-127d951f3e6b">&lt;strong&gt;</bpt>data enhancement<ept id="c9a266e3-76e7-4545-b90a-127d951f3e6b">&lt;/strong&gt;</ept> step of machine learning.</target>
        </trans-unit>
        <trans-unit id="a5358e5c-437a-4d16-8de7-fa7e02bfa059" xml:space="preserve">
          <source>Three aspects of this process may be distinguished for our purposes:</source>
          <target state="new">Three aspects of this process may be distinguished for our purposes:</target>
        </trans-unit>
        <trans-unit id="d6a6bdb9-1c5e-414c-a230-11cc44ff3ed6" xml:space="preserve">
          <source><bpt id="10e72356-bf08-434a-871b-b25a4a3934a2">&lt;strong&gt;</bpt>data pre-processing<ept id="10e72356-bf08-434a-871b-b25a4a3934a2">&lt;/strong&gt;</ept>: This process tries to insure that the collected data is clean and consistent.</source>
          <target state="new"><bpt id="10e72356-bf08-434a-871b-b25a4a3934a2">&lt;strong&gt;</bpt>data pre-processing<ept id="10e72356-bf08-434a-871b-b25a4a3934a2">&lt;/strong&gt;</ept>: This process tries to insure that the collected data is clean and consistent.</target>
        </trans-unit>
        <trans-unit id="dd074882-9379-4380-9dcb-a321d2f09b78" xml:space="preserve">
          <source>It includes tasks such as integrating multiple datasets, handling missing data, handling inconsistent data, and converting data types.</source>
          <target state="new">It includes tasks such as integrating multiple datasets, handling missing data, handling inconsistent data, and converting data types.</target>
        </trans-unit>
        <trans-unit id="c94ebaab-f092-40df-9b42-ee9be03d1441" xml:space="preserve">
          <source><bpt id="eb72874c-2f7d-4942-9cb0-d91b4a59bf7b">&lt;strong&gt;</bpt>feature engineering<ept id="eb72874c-2f7d-4942-9cb0-d91b4a59bf7b">&lt;/strong&gt;</ept>: This process attempts to create additional relevant features from the existing raw features in the data, and to increase predictive power to the learning algorithm.</source>
          <target state="new"><bpt id="eb72874c-2f7d-4942-9cb0-d91b4a59bf7b">&lt;strong&gt;</bpt>feature engineering<ept id="eb72874c-2f7d-4942-9cb0-d91b4a59bf7b">&lt;/strong&gt;</ept>: This process attempts to create additional relevant features from the existing raw features in the data, and to increase predictive power to the learning algorithm.</target>
        </trans-unit>
        <trans-unit id="97c17416-65c9-4421-9e70-4b6a2a116491" xml:space="preserve">
          <source><bpt id="17a4a141-eca3-4fbe-860d-d6eded003bc1">&lt;strong&gt;</bpt>feature selection<ept id="17a4a141-eca3-4fbe-860d-d6eded003bc1">&lt;/strong&gt;</ept>: This process selects the key subset of original data features in an attempt to reduce the dimensionality of the training problem.</source>
          <target state="new"><bpt id="17a4a141-eca3-4fbe-860d-d6eded003bc1">&lt;strong&gt;</bpt>feature selection<ept id="17a4a141-eca3-4fbe-860d-d6eded003bc1">&lt;/strong&gt;</ept>: This process selects the key subset of original data features in an attempt to reduce the dimensionality of the training problem.</target>
        </trans-unit>
        <trans-unit id="5c1c076b-40f9-4db5-ada4-45dddebcaf68" xml:space="preserve">
          <source>This topic only covers the feature engineering and feature selection aspects of the data enhancement process.</source>
          <target state="new">This topic only covers the feature engineering and feature selection aspects of the data enhancement process.</target>
        </trans-unit>
        <trans-unit id="d641298c-73b8-41d9-a053-8f1fbf2749c1" xml:space="preserve">
          <source>For additional information on the data pre-processing step, see the <bpt id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;linkText&gt;</bpt>Pre-processing Data in Azure ML Studio<ept id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;/linkText&gt;</ept><bpt id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;title&gt;</bpt><ept id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;/title&gt;</ept> video.</source>
          <target state="new">For additional information on the data pre-processing step, see the <bpt id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;linkText&gt;</bpt>Pre-processing Data in Azure ML Studio<ept id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;/linkText&gt;</ept><bpt id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;title&gt;</bpt><ept id="36d865bb-a42c-48dc-a15b-8536f061eb8f">&lt;/title&gt;</ept> video.</target>
        </trans-unit>
        <trans-unit id="2fbee0e4-0f43-4357-8aaa-24fcc5fa1a03" xml:space="preserve">
          <source>The training data consists of a matrix composed of examples (records or observations stored in rows), each of which has a set of features (variables or fields stored in columns).</source>
          <target state="new">The training data consists of a matrix composed of examples (records or observations stored in rows), each of which has a set of features (variables or fields stored in columns).</target>
        </trans-unit>
        <trans-unit id="b06096e0-ef59-46c6-b7bc-64c1eef7ad91" xml:space="preserve">
          <source>The features specified in the experimental design are expected to characterize the patterns in the data.</source>
          <target state="new">The features specified in the experimental design are expected to characterize the patterns in the data.</target>
        </trans-unit>
        <trans-unit id="e313668b-4b87-4753-a43d-3558680b2fea" xml:space="preserve">
          <source>Although many of the raw data fields can be directly included in the selected feature set used to train a model, it is often the case that additional (engineered) features need to be constructed from the features in the raw data to generate an enhanced training dataset.</source>
          <target state="new">Although many of the raw data fields can be directly included in the selected feature set used to train a model, it is often the case that additional (engineered) features need to be constructed from the features in the raw data to generate an enhanced training dataset.</target>
        </trans-unit>
        <trans-unit id="57051d1d-499f-413e-bfdc-0c52abb11030" xml:space="preserve">
          <source>What kind of features should be created to enhance the dataset when training a model?</source>
          <target state="new">What kind of features should be created to enhance the dataset when training a model?</target>
        </trans-unit>
        <trans-unit id="b7aaf4b1-9e07-4fae-a211-651074baa6ac" xml:space="preserve">
          <source>Engineered features that enhance the training provide information that better differentiates the patterns in the data.</source>
          <target state="new">Engineered features that enhance the training provide information that better differentiates the patterns in the data.</target>
        </trans-unit>
        <trans-unit id="60e7fac8-6d3d-489e-aa34-c660ed22d7fa" xml:space="preserve">
          <source>We expect the new features to provide additional information that is not clearly captured or easily apparent in the original or existing feature set.</source>
          <target state="new">We expect the new features to provide additional information that is not clearly captured or easily apparent in the original or existing feature set.</target>
        </trans-unit>
        <trans-unit id="b2893c30-cb41-450d-95d9-7e52b8f5b368" xml:space="preserve">
          <source>But this process is something of an art.</source>
          <target state="new">But this process is something of an art.</target>
        </trans-unit>
        <trans-unit id="ae5813f9-759d-4c84-b717-1940d89e0401" xml:space="preserve">
          <source>Sound and productive decisions often require some domain expertise.</source>
          <target state="new">Sound and productive decisions often require some domain expertise.</target>
        </trans-unit>
        <trans-unit id="4a3b1c9a-249d-4cc8-a422-078c103669c4" xml:space="preserve">
          <source>When starting with Azure Machine Learning, it is easiest to grasp this process concretely using samples provided in the Studio.</source>
          <target state="new">When starting with Azure Machine Learning, it is easiest to grasp this process concretely using samples provided in the Studio.</target>
        </trans-unit>
        <trans-unit id="3c69e00c-6ed5-4082-ab6b-345ba474adf9" xml:space="preserve">
          <source>Two examples are presented here:</source>
          <target state="new">Two examples are presented here:</target>
        </trans-unit>
        <trans-unit id="38807185-d8b5-45a3-8467-72283901a374" xml:space="preserve">
          <source>A regression example <bpt id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;linkText&gt;</bpt>Prediction of the number of bike rentals<ept id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;/linkText&gt;</ept><bpt id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;title&gt;</bpt><ept id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;/title&gt;</ept> in a supervised experiment where the target values are known</source>
          <target state="new">A regression example <bpt id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;linkText&gt;</bpt>Prediction of the number of bike rentals<ept id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;/linkText&gt;</ept><bpt id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;title&gt;</bpt><ept id="3ce1d488-aa35-4422-81c1-f70217f45c73">&lt;/title&gt;</ept> in a supervised experiment where the target values are known</target>
        </trans-unit>
        <trans-unit id="a4bf8f4e-1efe-4b41-a88e-b71bfb25c470" xml:space="preserve">
          <source>A text mining classification example using <bpt id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;/linkText&gt;</ept><bpt id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;title&gt;</bpt><ept id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;/title&gt;</ept></source>
          <target state="new">A text mining classification example using <bpt id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;/linkText&gt;</ept><bpt id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;title&gt;</bpt><ept id="3f340cd7-3319-4f6b-915b-baaaaad9ba02">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="d0226c56-6860-473f-810a-2e08865a0531" xml:space="preserve">
          <source>Let's use the experiment "Demand forecasting of bikes" in Azure Machine Learning Studio to demonstrate how to engineer features for a regression task.</source>
          <target state="new">Let's use the experiment "Demand forecasting of bikes" in Azure Machine Learning Studio to demonstrate how to engineer features for a regression task.</target>
        </trans-unit>
        <trans-unit id="f53b54bd-70d5-4642-9c0a-47e443b9c370" xml:space="preserve">
          <source>The objective of this experiment is to predict the demand for the bikes, that is, the number of bike rentals within a specific month/day/hour.</source>
          <target state="new">The objective of this experiment is to predict the demand for the bikes, that is, the number of bike rentals within a specific month/day/hour.</target>
        </trans-unit>
        <trans-unit id="5f79404b-1d4b-4b58-a235-959082ffde50" xml:space="preserve">
          <source>The dataset "Bike Rental UCI dataset" is used as the raw input data.</source>
          <target state="new">The dataset "Bike Rental UCI dataset" is used as the raw input data.</target>
        </trans-unit>
        <trans-unit id="da5cef99-12fa-406f-be3e-365f76d691fb" xml:space="preserve">
          <source>This dataset is based on real data from the Capital Bikeshare company that maintains a bike rental network in Washington DC in the United States.</source>
          <target state="new">This dataset is based on real data from the Capital Bikeshare company that maintains a bike rental network in Washington DC in the United States.</target>
        </trans-unit>
        <trans-unit id="668486c4-a26f-44fa-b9f0-80a515806aaf" xml:space="preserve">
          <source>The dataset represents the number of bike rentals within a specific hour of a day in the years 2011 and year 2012 and contains 17379 rows and 17 columns.</source>
          <target state="new">The dataset represents the number of bike rentals within a specific hour of a day in the years 2011 and year 2012 and contains 17379 rows and 17 columns.</target>
        </trans-unit>
        <trans-unit id="81a837e0-dcee-4c13-8c59-93d2facff13a" xml:space="preserve">
          <source>The raw feature set contains weather conditions (temperature/humidity/wind speed) and the type of the day (holiday/weekday).</source>
          <target state="new">The raw feature set contains weather conditions (temperature/humidity/wind speed) and the type of the day (holiday/weekday).</target>
        </trans-unit>
        <trans-unit id="6032a08e-f536-473f-a22e-8a1ceb39411f" xml:space="preserve">
          <source>The field to predict is "cnt", a count which represents the bike rentals within a specific hour and which ranges ranges from 1 to 977.</source>
          <target state="new">The field to predict is "cnt", a count which represents the bike rentals within a specific hour and which ranges ranges from 1 to 977.</target>
        </trans-unit>
        <trans-unit id="c6da7819-22e4-4862-b71d-51fb0fb9e81e" xml:space="preserve">
          <source>With the goal of constructing effective features in the training data, four regression models are built using the same algorithm but with four different training datasets.</source>
          <target state="new">With the goal of constructing effective features in the training data, four regression models are built using the same algorithm but with four different training datasets.</target>
        </trans-unit>
        <trans-unit id="f122a7a8-4b11-4e87-9b8d-b59022dbb780" xml:space="preserve">
          <source>The four datasets represent the same raw input data, but with an increasing number of features set.</source>
          <target state="new">The four datasets represent the same raw input data, but with an increasing number of features set.</target>
        </trans-unit>
        <trans-unit id="a7dc96e4-3f4d-4443-aa05-78d3c0f36a6c" xml:space="preserve">
          <source>These features are grouped into four categories:</source>
          <target state="new">These features are grouped into four categories:</target>
        </trans-unit>
        <trans-unit id="b642541a-f8e9-4b83-a6cc-7b968b854401" xml:space="preserve">
          <source>A = weather + holiday + weekday + weekend features for the predicted day</source>
          <target state="new">A = weather + holiday + weekday + weekend features for the predicted day</target>
        </trans-unit>
        <trans-unit id="83fc23d7-66f8-44e9-bc50-5d2244ea21e3" xml:space="preserve">
          <source>B = number of bikes that were rented in each of the previous 12 hours</source>
          <target state="new">B = number of bikes that were rented in each of the previous 12 hours</target>
        </trans-unit>
        <trans-unit id="41a3f578-487c-4539-82e3-fd4d9bf45fb2" xml:space="preserve">
          <source>C = number of bikes that were rented in each of the previous 12 days at the same hour</source>
          <target state="new">C = number of bikes that were rented in each of the previous 12 days at the same hour</target>
        </trans-unit>
        <trans-unit id="5f8cd6ef-a32d-4fcf-8c6e-929b3c4e5d54" xml:space="preserve">
          <source>D = number of bikes that were rented in each of the previous 12 weeks at the same hour and the same day</source>
          <target state="new">D = number of bikes that were rented in each of the previous 12 weeks at the same hour and the same day</target>
        </trans-unit>
        <trans-unit id="029a9224-bc7d-4bb7-8c2d-a0e8b0262047" xml:space="preserve">
          <source>Besides feature set A, which already exist in the original raw data, the other three sets of features are created through the feature engineering process.</source>
          <target state="new">Besides feature set A, which already exist in the original raw data, the other three sets of features are created through the feature engineering process.</target>
        </trans-unit>
        <trans-unit id="8e288e59-8379-46e1-a045-9024f6e6ad97" xml:space="preserve">
          <source>Feature set B captures very recent demand for the bikes.</source>
          <target state="new">Feature set B captures very recent demand for the bikes.</target>
        </trans-unit>
        <trans-unit id="2af47388-0081-4c1c-a760-acfb2a5aa8c0" xml:space="preserve">
          <source>Feature set C captures the demand for bikes at a particular hour.</source>
          <target state="new">Feature set C captures the demand for bikes at a particular hour.</target>
        </trans-unit>
        <trans-unit id="169bb0ff-bcfd-42cd-8c23-049395c3b78a" xml:space="preserve">
          <source>Feature set D captures demand for bikes at particular hour and particular day of the week.</source>
          <target state="new">Feature set D captures demand for bikes at particular hour and particular day of the week.</target>
        </trans-unit>
        <trans-unit id="07efcbff-7b6f-40a4-b769-2c044a01205e" xml:space="preserve">
          <source>The four training datasets each includes feature set A, A+B, A+B+C, and A+B+C+D, respectively.</source>
          <target state="new">The four training datasets each includes feature set A, A+B, A+B+C, and A+B+C+D, respectively.</target>
        </trans-unit>
        <trans-unit id="229fe31c-9550-469f-bd7c-23f548bb7a00" xml:space="preserve">
          <source>In the Azure Machine Learning experiment, these four training datasets are formed via four branches from the pre-processed input dataset.</source>
          <target state="new">In the Azure Machine Learning experiment, these four training datasets are formed via four branches from the pre-processed input dataset.</target>
        </trans-unit>
        <trans-unit id="64b6e1c2-cf4b-4b45-a8e5-90057419f803" xml:space="preserve">
          <source>Except the left most branch, each of these branches contains an <bpt id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;linkText&gt;</bpt>Execute R Script[execute-r-script]<ept id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;/linkText&gt;</ept><bpt id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;title&gt;</bpt><ept id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;/title&gt;</ept> module, in which a set of derived features (feature set B, C, and D) are respectively constructed and appended to the imported dataset.</source>
          <target state="new">Except the left most branch, each of these branches contains an <bpt id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;linkText&gt;</bpt>Execute R Script[execute-r-script]<ept id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;/linkText&gt;</ept><bpt id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;title&gt;</bpt><ept id="61664b46-5b29-4fbc-b4a6-57ac33e651e0">&lt;/title&gt;</ept> module, in which a set of derived features (feature set B, C, and D) are respectively constructed and appended to the imported dataset.</target>
        </trans-unit>
        <trans-unit id="e6276ac4-289f-4126-b5b5-9afa6d05288d" xml:space="preserve">
          <source>The following figure demonstrates the R script used to create feature set B in the second left branch.</source>
          <target state="new">The following figure demonstrates the R script used to create feature set B in the second left branch.</target>
        </trans-unit>
        <trans-unit id="68303919-8e11-4d2b-b2fd-f56a424f5ea8" xml:space="preserve">
          <source><bpt id="28199cea-7033-4765-9458-a7c126211716">&lt;linkText&gt;</bpt>create features<ept id="28199cea-7033-4765-9458-a7c126211716">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="28199cea-7033-4765-9458-a7c126211716">&lt;linkText&gt;</bpt>create features<ept id="28199cea-7033-4765-9458-a7c126211716">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="7a26e793-d49b-434d-b48c-a170dcfb41dd" xml:space="preserve">
          <source>The comparison of the performance results of the four models are summarized in the following table.</source>
          <target state="new">The comparison of the performance results of the four models are summarized in the following table.</target>
        </trans-unit>
        <trans-unit id="9db69527-8b89-4d45-99c0-1cfe24600137" xml:space="preserve">
          <source>The best results are shown by features A+B+C.</source>
          <target state="new">The best results are shown by features A+B+C.</target>
        </trans-unit>
        <trans-unit id="dbd60ab7-b811-415a-8329-89a984886232" xml:space="preserve">
          <source>Note that the error rate decreases when additional feature set are included in the training data.</source>
          <target state="new">Note that the error rate decreases when additional feature set are included in the training data.</target>
        </trans-unit>
        <trans-unit id="32743876-8128-4f84-8a15-fa71e8ea00c3" xml:space="preserve">
          <source>It verifies our presumption that the feature set B, C provide additional relevant information for the regression task.</source>
          <target state="new">It verifies our presumption that the feature set B, C provide additional relevant information for the regression task.</target>
        </trans-unit>
        <trans-unit id="63ee34aa-e4ca-4d42-ae62-3a2be103b8f7" xml:space="preserve">
          <source>But adding the D feature does not seem to provide any additional reduction in the error rate.</source>
          <target state="new">But adding the D feature does not seem to provide any additional reduction in the error rate.</target>
        </trans-unit>
        <trans-unit id="e9eeac31-8a93-45d8-9210-8fbbee6aec2a" xml:space="preserve">
          <source><bpt id="dbf883f3-0a2a-4ea4-b476-f5727528c424">&lt;linkText&gt;</bpt>result comparison<ept id="dbf883f3-0a2a-4ea4-b476-f5727528c424">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="dbf883f3-0a2a-4ea4-b476-f5727528c424">&lt;linkText&gt;</bpt>result comparison<ept id="dbf883f3-0a2a-4ea4-b476-f5727528c424">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="cf37689a-bf57-411d-b6f5-20a23254b4f2" xml:space="preserve">
          <source>Feature engineering is widely applied in tasks related to text mining, such as document classification and sentiment analysis.</source>
          <target state="new">Feature engineering is widely applied in tasks related to text mining, such as document classification and sentiment analysis.</target>
        </trans-unit>
        <trans-unit id="66b46dd4-ea79-4ffe-ac11-a18db6f7bbf6" xml:space="preserve">
          <source>For example, when we want to classify documents into several categories, a typical assumption is that the word/phrases included in one doc category are less likely to occur in another doc category.</source>
          <target state="new">For example, when we want to classify documents into several categories, a typical assumption is that the word/phrases included in one doc category are less likely to occur in another doc category.</target>
        </trans-unit>
        <trans-unit id="ffe26075-b831-4185-a640-6c0d9fb0485e" xml:space="preserve">
          <source>In another words, the frequency of the words/phrases distribution is able to characterize different document categories.</source>
          <target state="new">In another words, the frequency of the words/phrases distribution is able to characterize different document categories.</target>
        </trans-unit>
        <trans-unit id="30938f8d-70c0-4498-9497-753381bc6aad" xml:space="preserve">
          <source>In text mining applications, because individual pieces of text-contents usually serve as the input data, the feature engineering process is needed to create the features involving word/phrase frequencies.</source>
          <target state="new">In text mining applications, because individual pieces of text-contents usually serve as the input data, the feature engineering process is needed to create the features involving word/phrase frequencies.</target>
        </trans-unit>
        <trans-unit id="7019ba0c-b080-4c52-a2ed-ae435467c0c1" xml:space="preserve">
          <source>To achieve this task, a technique called <bpt id="9e4eec56-4013-4c4f-8563-880a96545450">&lt;strong&gt;</bpt>feature hashing<ept id="9e4eec56-4013-4c4f-8563-880a96545450">&lt;/strong&gt;</ept> is applied to efficiently turn arbitrary text features into indices.</source>
          <target state="new">To achieve this task, a technique called <bpt id="9e4eec56-4013-4c4f-8563-880a96545450">&lt;strong&gt;</bpt>feature hashing<ept id="9e4eec56-4013-4c4f-8563-880a96545450">&lt;/strong&gt;</ept> is applied to efficiently turn arbitrary text features into indices.</target>
        </trans-unit>
        <trans-unit id="3b6808e8-1080-4e22-9aac-0f28c47e91de" xml:space="preserve">
          <source>Instead of associating each text feature (words/phrases) to a particular index, this method functions by applying a hash function to the features and using their hash values as indices directly.</source>
          <target state="new">Instead of associating each text feature (words/phrases) to a particular index, this method functions by applying a hash function to the features and using their hash values as indices directly.</target>
        </trans-unit>
        <trans-unit id="991363ba-c6f5-4c10-81d2-0d02336fdbcb" xml:space="preserve">
          <source>In Azure Machine Learning, there is a <bpt id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;/linkText&gt;</ept><bpt id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;title&gt;</bpt><ept id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;/title&gt;</ept> module that creates these word/phrase features conveniently.</source>
          <target state="new">In Azure Machine Learning, there is a <bpt id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;/linkText&gt;</ept><bpt id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;title&gt;</bpt><ept id="040edd2f-caea-4d1b-91a3-a4c6056b6e9b">&lt;/title&gt;</ept> module that creates these word/phrase features conveniently.</target>
        </trans-unit>
        <trans-unit id="4d8c25a5-271f-4749-9a1f-869741dfa145" xml:space="preserve">
          <source>Following figure shows an example of using this module.</source>
          <target state="new">Following figure shows an example of using this module.</target>
        </trans-unit>
        <trans-unit id="9029ada8-0dc7-4c5d-ad80-b978aa651527" xml:space="preserve">
          <source>The input dataset contains two columns: the book rating ranging from 1 to 5, and the actual review content.</source>
          <target state="new">The input dataset contains two columns: the book rating ranging from 1 to 5, and the actual review content.</target>
        </trans-unit>
        <trans-unit id="2abbc68d-5ef1-4be0-8be4-0b5c247c9711" xml:space="preserve">
          <source>The goal of this <bpt id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;/linkText&gt;</ept><bpt id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;title&gt;</bpt><ept id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;/title&gt;</ept> module is to retrieve a bunch of new features that show the occurrence frequency of the corresponding word(s)/phrase(s) within the particular book review.</source>
          <target state="new">The goal of this <bpt id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;/linkText&gt;</ept><bpt id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;title&gt;</bpt><ept id="b0739da3-21ae-47a9-988a-c2304a76133c">&lt;/title&gt;</ept> module is to retrieve a bunch of new features that show the occurrence frequency of the corresponding word(s)/phrase(s) within the particular book review.</target>
        </trans-unit>
        <trans-unit id="fb81b3c8-410e-42f1-a3ad-83c247a2dae0" xml:space="preserve">
          <source>To use this module, we need to complete the following steps:</source>
          <target state="new">To use this module, we need to complete the following steps:</target>
        </trans-unit>
        <trans-unit id="f7cd0c27-5e86-4ce2-95b2-db31ce6508f3" xml:space="preserve">
          <source>First, select the column that contains the input text ("Col2" in this example).</source>
          <target state="new">First, select the column that contains the input text ("Col2" in this example).</target>
        </trans-unit>
        <trans-unit id="97aef406-ba43-488d-bbed-2cbbfbae25f4" xml:space="preserve">
          <source>Second, set the "Hashing bitsize" to 8, which means 2^8=256 features will be created.</source>
          <target state="new">Second, set the "Hashing bitsize" to 8, which means 2^8=256 features will be created.</target>
        </trans-unit>
        <trans-unit id="ffabe582-fc5d-4c9d-927a-7c678f5033a7" xml:space="preserve">
          <source>The word/phase in all the text will be hashed to 256 indices.</source>
          <target state="new">The word/phase in all the text will be hashed to 256 indices.</target>
        </trans-unit>
        <trans-unit id="b5203a7a-0aee-481c-a744-d424a6148699" xml:space="preserve">
          <source>The parameter "Hashing bitsize" ranges from 1 to 31.</source>
          <target state="new">The parameter "Hashing bitsize" ranges from 1 to 31.</target>
        </trans-unit>
        <trans-unit id="78d3753e-b70b-487c-9671-2078f26e2c1f" xml:space="preserve">
          <source>The word(s)/phrase(s) are less likely to be hashed into the same index if setting it to be a larger number.</source>
          <target state="new">The word(s)/phrase(s) are less likely to be hashed into the same index if setting it to be a larger number.</target>
        </trans-unit>
        <trans-unit id="35e287da-5273-48e7-b69b-24755a099a78" xml:space="preserve">
          <source>Third, set the parameter "N-grams" to 2.</source>
          <target state="new">Third, set the parameter "N-grams" to 2.</target>
        </trans-unit>
        <trans-unit id="0cca0d5c-206d-4353-8036-dc2b20fd52df" xml:space="preserve">
          <source>This gets the occurrence frequency of unigrams (a feature for every single word) and bigrams (a feature for every pair of adjacent words) from the input text.</source>
          <target state="new">This gets the occurrence frequency of unigrams (a feature for every single word) and bigrams (a feature for every pair of adjacent words) from the input text.</target>
        </trans-unit>
        <trans-unit id="f1a95278-1fb5-4f79-93b6-6a48d922827c" xml:space="preserve">
          <source>The parameter "N-grams" ranges from 0 to 10, which indicates the maximum number of sequential words to be included in a feature.</source>
          <target state="new">The parameter "N-grams" ranges from 0 to 10, which indicates the maximum number of sequential words to be included in a feature.</target>
        </trans-unit>
        <trans-unit id="b43fe0a6-d7a8-4f3b-9dbd-03428138291d" xml:space="preserve">
          <source><bpt id="bda12989-0d86-432d-a9b6-0d76af137351">&lt;linkText&gt;</bpt>"Feature Hashing" module<ept id="bda12989-0d86-432d-a9b6-0d76af137351">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="bda12989-0d86-432d-a9b6-0d76af137351">&lt;linkText&gt;</bpt>"Feature Hashing" module<ept id="bda12989-0d86-432d-a9b6-0d76af137351">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="73c18c41-8ed7-4580-af50-2e671d556fb9" xml:space="preserve">
          <source>The following figure shows what the these new feature look like.</source>
          <target state="new">The following figure shows what the these new feature look like.</target>
        </trans-unit>
        <trans-unit id="fbb50282-1816-4be2-abc8-6e33ed1c4c01" xml:space="preserve">
          <source><bpt id="70ed0e41-eebf-4318-b7fc-a09cded8d5d3">&lt;linkText&gt;</bpt>"Feature Hashing" example<ept id="70ed0e41-eebf-4318-b7fc-a09cded8d5d3">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="70ed0e41-eebf-4318-b7fc-a09cded8d5d3">&lt;linkText&gt;</bpt>"Feature Hashing" example<ept id="70ed0e41-eebf-4318-b7fc-a09cded8d5d3">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="1a28e8a4-bc97-4f4f-9dce-9c2226c455ca" xml:space="preserve">
          <source>Feature selection is a process that is commonly applied for the construction of training datasets for predictive modeling tasks such as classification or regression tasks.</source>
          <target state="new">Feature selection is a process that is commonly applied for the construction of training datasets for predictive modeling tasks such as classification or regression tasks.</target>
        </trans-unit>
        <trans-unit id="20a8124a-39f6-4723-ae6c-34e6cfa1c112" xml:space="preserve">
          <source>The goal is to select a subset of the features from the original dataset that reduce its dimensions by using a minimal set of features to represent the maximum amount of variance in the data.</source>
          <target state="new">The goal is to select a subset of the features from the original dataset that reduce its dimensions by using a minimal set of features to represent the maximum amount of variance in the data.</target>
        </trans-unit>
        <trans-unit id="a35c73bb-bd9f-43b4-9102-88bc4c5b3858" xml:space="preserve">
          <source>This subset of features are, then, the only features to be included to train the model.</source>
          <target state="new">This subset of features are, then, the only features to be included to train the model.</target>
        </trans-unit>
        <trans-unit id="e954409d-640d-452e-99a0-fdf1ed258bd0" xml:space="preserve">
          <source>Feature selection serves two main purposes.</source>
          <target state="new">Feature selection serves two main purposes.</target>
        </trans-unit>
        <trans-unit id="26715f33-082c-45b4-8518-f91784c0f7ec" xml:space="preserve">
          <source>First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</source>
          <target state="new">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</target>
        </trans-unit>
        <trans-unit id="f91a47a4-70d2-4c72-9cc4-773c1ed8e122" xml:space="preserve">
          <source>Second, it decreases the number of features which makes model training process more efficient.</source>
          <target state="new">Second, it decreases the number of features which makes model training process more efficient.</target>
        </trans-unit>
        <trans-unit id="b4dafa50-fbfa-469f-b79e-96e356ef3e0f" xml:space="preserve">
          <source>This is particularly important for learners that are expensive to train such as support vector machines.</source>
          <target state="new">This is particularly important for learners that are expensive to train such as support vector machines.</target>
        </trans-unit>
        <trans-unit id="14b1b0f9-fedb-44ec-aeaa-c8a84b176de4" xml:space="preserve">
          <source>Although feature selection does seek to reduce the number of features in the dataset used to train the model, it is not usually referred to by the term "dimensionality reduction".</source>
          <target state="new">Although feature selection does seek to reduce the number of features in the dataset used to train the model, it is not usually referred to by the term "dimensionality reduction".</target>
        </trans-unit>
        <trans-unit id="33735b6e-6e10-4499-8433-ed91d2e9099e" xml:space="preserve">
          <source>Feature selection methods extract a subset of original features in the data without changing them.</source>
          <target state="new">Feature selection methods extract a subset of original features in the data without changing them.</target>
        </trans-unit>
        <trans-unit id="b4842989-57f5-4b82-a075-0cc893818107" xml:space="preserve">
          <source>Dimensionality reduction methods employ engineered features that can transform the original features and thus modify them.</source>
          <target state="new">Dimensionality reduction methods employ engineered features that can transform the original features and thus modify them.</target>
        </trans-unit>
        <trans-unit id="be2d02c2-ce92-4908-ad24-8791304b2b00" xml:space="preserve">
          <source>Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</source>
          <target state="new">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</target>
        </trans-unit>
        <trans-unit id="3a22c1a8-42d4-40d9-84ba-966db3b87ee4" xml:space="preserve">
          <source>Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</source>
          <target state="new">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</target>
        </trans-unit>
        <trans-unit id="d4d8f3da-3402-4698-b902-045ac5eb9cef" xml:space="preserve">
          <source>By evaluating the correlation between each feature and the target attribute, these methods apply a statistical measure to assign a score to each feature.</source>
          <target state="new">By evaluating the correlation between each feature and the target attribute, these methods apply a statistical measure to assign a score to each feature.</target>
        </trans-unit>
        <trans-unit id="02b1b2eb-c477-490e-97f3-2bc78a8589e7" xml:space="preserve">
          <source>The features are then ranked by the score, which may be used to help set the threshold for keeping or eliminating a specific feature.</source>
          <target state="new">The features are then ranked by the score, which may be used to help set the threshold for keeping or eliminating a specific feature.</target>
        </trans-unit>
        <trans-unit id="46d05e33-3d4e-4423-aa4e-93279e954977" xml:space="preserve">
          <source>Examples of the statistical measures used in these methods include Person correlation, mutual information, and the Chi squared test.</source>
          <target state="new">Examples of the statistical measures used in these methods include Person correlation, mutual information, and the Chi squared test.</target>
        </trans-unit>
        <trans-unit id="87ec1fe6-fece-4819-b62e-d62cb33d0463" xml:space="preserve">
          <source>In Azure Machine Learning Studio, there are modules provided for feature selection.</source>
          <target state="new">In Azure Machine Learning Studio, there are modules provided for feature selection.</target>
        </trans-unit>
        <trans-unit id="2e0154ba-34c8-40e2-86f0-39fac7fbff7d" xml:space="preserve">
          <source>As shown in the following figure, these modules include <bpt id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;/linkText&gt;</ept><bpt id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;title&gt;</bpt><ept id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;/title&gt;</ept> and <bpt id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;linkText&gt;</bpt>Fisher Linear Discriminant Analysis[fisher-linear-discriminant-analysis]<ept id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;/linkText&gt;</ept><bpt id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;title&gt;</bpt><ept id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;/title&gt;</ept>.</source>
          <target state="new">As shown in the following figure, these modules include <bpt id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;/linkText&gt;</ept><bpt id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;title&gt;</bpt><ept id="27303691-32a1-4be8-8ab6-659bf1b811fd">&lt;/title&gt;</ept> and <bpt id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;linkText&gt;</bpt>Fisher Linear Discriminant Analysis[fisher-linear-discriminant-analysis]<ept id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;/linkText&gt;</ept><bpt id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;title&gt;</bpt><ept id="81b77cc3-2f5b-4020-8be9-558f88236e39">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="a8dc7e5b-5d81-4589-8dc7-2939a60bd150" xml:space="preserve">
          <source><bpt id="3bab6166-c828-4c8a-ab52-7c62fd996f28">&lt;linkText&gt;</bpt>Feature selection example<ept id="3bab6166-c828-4c8a-ab52-7c62fd996f28">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="3bab6166-c828-4c8a-ab52-7c62fd996f28">&lt;linkText&gt;</bpt>Feature selection example<ept id="3bab6166-c828-4c8a-ab52-7c62fd996f28">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="8a4fcea7-ba95-411f-b74e-551c6521ca5c" xml:space="preserve">
          <source>Consider, for example, the use of the <bpt id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;/linkText&gt;</ept><bpt id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;title&gt;</bpt><ept id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;/title&gt;</ept> module.</source>
          <target state="new">Consider, for example, the use of the <bpt id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;/linkText&gt;</ept><bpt id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;title&gt;</bpt><ept id="ea2699c0-4009-494b-85f2-836b10bbb18f">&lt;/title&gt;</ept> module.</target>
        </trans-unit>
        <trans-unit id="a16b4535-a408-49e5-bfe2-d419088371bb" xml:space="preserve">
          <source>For the purpose of convenience, we continue to use the text mining example outlined above.</source>
          <target state="new">For the purpose of convenience, we continue to use the text mining example outlined above.</target>
        </trans-unit>
        <trans-unit id="43f12d90-426e-4675-969f-ebed4da707fa" xml:space="preserve">
          <source>Assume that we want to build a regression model after a set of 256 features are created through the <bpt id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;/linkText&gt;</ept><bpt id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;title&gt;</bpt><ept id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;/title&gt;</ept> module, and that the response variable is the "Col1" and represents a book review ratings ranging from 1 to 5.</source>
          <target state="new">Assume that we want to build a regression model after a set of 256 features are created through the <bpt id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;linkText&gt;</bpt>Feature Hashing[feature-hashing]<ept id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;/linkText&gt;</ept><bpt id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;title&gt;</bpt><ept id="6369ace0-c99e-40e1-941d-e96aa81fddea">&lt;/title&gt;</ept> module, and that the response variable is the "Col1" and represents a book review ratings ranging from 1 to 5.</target>
        </trans-unit>
        <trans-unit id="8ad5cba8-d21a-47cc-8ab7-04e04083326b" xml:space="preserve">
          <source>By setting "Feature scoring method" to be "Pearson Correlation", the "Target column" to be "Col1", and the "Number of desired features" to 50.</source>
          <target state="new">By setting "Feature scoring method" to be "Pearson Correlation", the "Target column" to be "Col1", and the "Number of desired features" to 50.</target>
        </trans-unit>
        <trans-unit id="c0d8be49-c34b-40fb-b364-ceb0bfa629a5" xml:space="preserve">
          <source>Then the module <bpt id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;/linkText&gt;</ept><bpt id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;title&gt;</bpt><ept id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;/title&gt;</ept> will produce a dataset containing 50 features together with the target attribute "Col1".</source>
          <target state="new">Then the module <bpt id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;/linkText&gt;</ept><bpt id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;title&gt;</bpt><ept id="de9d8ec3-d46d-4e57-8421-120ffea55295">&lt;/title&gt;</ept> will produce a dataset containing 50 features together with the target attribute "Col1".</target>
        </trans-unit>
        <trans-unit id="6dfd8301-7904-45cb-9a55-200117ee82ac" xml:space="preserve">
          <source>The following figure shows the flow of this experiment and the input parameters we just described.</source>
          <target state="new">The following figure shows the flow of this experiment and the input parameters we just described.</target>
        </trans-unit>
        <trans-unit id="3b7ab426-0dfd-46a9-8ede-953bf8ac4aee" xml:space="preserve">
          <source><bpt id="6e326430-289a-4e8d-8280-e4e4053ca92a">&lt;linkText&gt;</bpt>Feature selection example<ept id="6e326430-289a-4e8d-8280-e4e4053ca92a">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="6e326430-289a-4e8d-8280-e4e4053ca92a">&lt;linkText&gt;</bpt>Feature selection example<ept id="6e326430-289a-4e8d-8280-e4e4053ca92a">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="688d9dd1-c8fb-4d7d-b6ff-482f883c04f5" xml:space="preserve">
          <source>The following figure shows the resulting datasets.</source>
          <target state="new">The following figure shows the resulting datasets.</target>
        </trans-unit>
        <trans-unit id="ff0f5993-5f1d-44e6-a40e-5f9c7c248f4d" xml:space="preserve">
          <source>Each feature is scored based on the Pearson Correlation between itself and the target attribute "Col1".</source>
          <target state="new">Each feature is scored based on the Pearson Correlation between itself and the target attribute "Col1".</target>
        </trans-unit>
        <trans-unit id="5ac209ec-56c2-40ad-92d4-9708ae691adb" xml:space="preserve">
          <source>The features with top scores are kept.</source>
          <target state="new">The features with top scores are kept.</target>
        </trans-unit>
        <trans-unit id="51c5515f-9c69-4c59-9157-78e5c4629dd3" xml:space="preserve">
          <source><bpt id="a8789ae0-582c-48b1-899d-8c9f1e5b837a">&lt;linkText&gt;</bpt>Feature selection example<ept id="a8789ae0-582c-48b1-899d-8c9f1e5b837a">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="a8789ae0-582c-48b1-899d-8c9f1e5b837a">&lt;linkText&gt;</bpt>Feature selection example<ept id="a8789ae0-582c-48b1-899d-8c9f1e5b837a">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="0927cd86-fc72-48fd-bbda-2bcdb6bd4e31" xml:space="preserve">
          <source>The corresponding scores of the selected features are shown in the following figure.</source>
          <target state="new">The corresponding scores of the selected features are shown in the following figure.</target>
        </trans-unit>
        <trans-unit id="98557aef-ef1b-4a62-a9d6-40d2623b454b" xml:space="preserve">
          <source><bpt id="20124701-7a66-4b8a-9187-ae95fe1a6f15">&lt;linkText&gt;</bpt>Feature selection example<ept id="20124701-7a66-4b8a-9187-ae95fe1a6f15">&lt;/linkText&gt;</ept></source>
          <target state="new"><bpt id="20124701-7a66-4b8a-9187-ae95fe1a6f15">&lt;linkText&gt;</bpt>Feature selection example<ept id="20124701-7a66-4b8a-9187-ae95fe1a6f15">&lt;/linkText&gt;</ept></target>
        </trans-unit>
        <trans-unit id="ac576ce4-454a-44b7-a10b-652805c6dfe0" xml:space="preserve">
          <source>By applying this <bpt id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;/linkText&gt;</ept><bpt id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;title&gt;</bpt><ept id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;/title&gt;</ept> module, 50 out of 256 features are selected because they have the most correlated features with the target variable "Col1", based on the scoring method "Pearson Correlation".</source>
          <target state="new">By applying this <bpt id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;linkText&gt;</bpt>Filter-Based Feature Selection[filter-based-feature-selection]<ept id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;/linkText&gt;</ept><bpt id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;title&gt;</bpt><ept id="23fc9c0e-37ed-4e61-86b7-1c9748468b29">&lt;/title&gt;</ept> module, 50 out of 256 features are selected because they have the most correlated features with the target variable "Col1", based on the scoring method "Pearson Correlation".</target>
        </trans-unit>
        <trans-unit id="e4f82665-ad58-4106-b37f-3cf6b4314c65" xml:space="preserve">
          <source>Feature engineering and feature selection are two commonly performed steps to prepare the training data when building a machine learning model.</source>
          <target state="new">Feature engineering and feature selection are two commonly performed steps to prepare the training data when building a machine learning model.</target>
        </trans-unit>
        <trans-unit id="358613fe-e28a-4252-b0a3-c63aaac510ab" xml:space="preserve">
          <source>Normally feature engineering is applied first to generate additional features, and then the feature selection step is performed to eliminate irrelevant, redundant, or highly correlated features.</source>
          <target state="new">Normally feature engineering is applied first to generate additional features, and then the feature selection step is performed to eliminate irrelevant, redundant, or highly correlated features.</target>
        </trans-unit>
        <trans-unit id="5f6b8b9c-b231-4b51-9e06-97fae7ae4c10" xml:space="preserve">
          <source>Note that it is not always necessarily to perform feature engineering or feature selection.</source>
          <target state="new">Note that it is not always necessarily to perform feature engineering or feature selection.</target>
        </trans-unit>
        <trans-unit id="01c90f7a-a2d0-419a-bbfa-ae3fee5514bf" xml:space="preserve">
          <source>Whether it is needed or not depends on the data we have or collect, the algorithm we pick, and the objective of the experiment.</source>
          <target state="new">Whether it is needed or not depends on the data we have or collect, the algorithm we pick, and the objective of the experiment.</target>
        </trans-unit>
        <trans-unit id="a6382846-4487-4766-af24-5154d2526a56" xml:space="preserve">
          <source>https://msdn.microsoft.com/library/azure/30806023-392b-42e0-94d6-6b775a6e0fd5/</source>
          <target state="new">https://msdn.microsoft.com/library/azure/30806023-392b-42e0-94d6-6b775a6e0fd5/</target>
        </trans-unit>
        <trans-unit id="a858e34a-5567-4727-9efe-ef05a45964cf" xml:space="preserve">
          <source>https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/</source>
          <target state="new">https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/</target>
        </trans-unit>
        <trans-unit id="c6f7e7d6-81f3-468a-b7da-dac6423ad9e3" xml:space="preserve">
          <source>https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/</source>
          <target state="new">https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/</target>
        </trans-unit>
        <trans-unit id="5224ce7c-18d4-410a-91b2-4fa7e38e073f" xml:space="preserve">
          <source>https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/</source>
          <target state="new">https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/</target>
        </trans-unit>
      </group>
      <group id="3a0af61a-c3de-4626-9eda-1a14ce8c723b" />
    </body>
  </file>
</xliff>