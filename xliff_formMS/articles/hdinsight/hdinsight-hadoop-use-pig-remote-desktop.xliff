<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="zh-cn" original="foo.file" tool-id="5388d403-2200-46e5-aba0-4a215e252e5f" product-name="foo" product-version="1.0" build-num="1">
    <header>
      <tool tool-id="5388d403-2200-46e5-aba0-4a215e252e5f" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group id="3e5f4843-f6be-4eb8-9875-cd8aecbed9ca">
        <trans-unit id="ec0af2e3-9310-44d7-b806-ca88f1fb74ef" xml:space="preserve">
          <source>Use Hadoop Pig with Remote Desktop in HDInsight | Microsoft Azure</source>
          <target state="new">Use Hadoop Pig with Remote Desktop in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="94f64c3d-8e6f-4c8b-a33d-df0756e61a18" xml:space="preserve">
          <source>Learn how to use the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based Hadoop cluster in HDInsight.</source>
          <target state="new">Learn how to use the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based Hadoop cluster in HDInsight.</target>
        </trans-unit>
        <trans-unit id="28f1688f-a71b-4cdd-a957-89aa6c944fc5" xml:space="preserve">
          <source><bpt id="e98d3123-c01d-4312-89b2-cf72c63e4947">&lt;token href="../../includes/hdinsight-selector-use-pig.md"&gt;</bpt><ept id="e98d3123-c01d-4312-89b2-cf72c63e4947">&lt;/token&gt;</ept></source>
          <target state="new"><bpt id="e98d3123-c01d-4312-89b2-cf72c63e4947">&lt;token href="../../includes/hdinsight-selector-use-pig.md"&gt;</bpt><ept id="e98d3123-c01d-4312-89b2-cf72c63e4947">&lt;/token&gt;</ept></target>
        </trans-unit>
        <trans-unit id="7a2b1457-ea06-4928-b76e-53d4ed70cbf9" xml:space="preserve">
          <source>This document provides a walkthrough for using the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based HDInsight cluster.</source>
          <target state="new">This document provides a walkthrough for using the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="2c4a59a6-43ed-44c1-b0dd-610c2742c67f" xml:space="preserve">
          <source>Pig Latin allows you to create MapReduce applications by describing data transformations, rather than map and reduce functions.</source>
          <target state="new">Pig Latin allows you to create MapReduce applications by describing data transformations, rather than map and reduce functions.</target>
        </trans-unit>
        <trans-unit id="96b5d5d7-601f-4bc6-9764-d5186a0baa08" xml:space="preserve">
          <source>In this document, learn how to</source>
          <target state="new">In this document, learn how to</target>
        </trans-unit>
        <trans-unit id="35f1799b-394b-48ff-b377-7deb4b337247" xml:space="preserve">
          <source>To complete the steps in this article, you will need the following.</source>
          <target state="new">To complete the steps in this article, you will need the following.</target>
        </trans-unit>
        <trans-unit id="942b61eb-c75f-48b9-92df-33b891a3ad79" xml:space="preserve">
          <source>A Windows-based HDInsight (Hadoop on HDInsight) cluster</source>
          <target state="new">A Windows-based HDInsight (Hadoop on HDInsight) cluster</target>
        </trans-unit>
        <trans-unit id="4202e3ad-fae7-4a23-912a-ae5069350c96" xml:space="preserve">
          <source>A client computer running Windows 10, Windows 8, or Windows 7</source>
          <target state="new">A client computer running Windows 10, Windows 8, or Windows 7</target>
        </trans-unit>
        <trans-unit id="bd62a0ef-856c-4685-8243-44c9694a5ad8" xml:space="preserve">
          <source>Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;linkText&gt;</bpt>Connect to HDInsight clusters using RDP<ept id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;/linkText&gt;</ept><bpt id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;title&gt;</bpt><ept id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;/title&gt;</ept>.</source>
          <target state="new">Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;linkText&gt;</bpt>Connect to HDInsight clusters using RDP<ept id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;/linkText&gt;</ept><bpt id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;title&gt;</bpt><ept id="47de2db6-2a31-49d2-8eac-da5f6031eab0">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="b0550896-542b-44d8-bea0-6378908722ad" xml:space="preserve">
          <source>After you have a Remote Desktop connection, start the <bpt id="1b3e9b78-6310-4251-b6b1-ce71a39c3576">&lt;strong&gt;</bpt>Hadoop Command Line<ept id="1b3e9b78-6310-4251-b6b1-ce71a39c3576">&lt;/strong&gt;</ept> by using the icon on the desktop.</source>
          <target state="new">After you have a Remote Desktop connection, start the <bpt id="1b3e9b78-6310-4251-b6b1-ce71a39c3576">&lt;strong&gt;</bpt>Hadoop Command Line<ept id="1b3e9b78-6310-4251-b6b1-ce71a39c3576">&lt;/strong&gt;</ept> by using the icon on the desktop.</target>
        </trans-unit>
        <trans-unit id="b15ade61-d005-4519-ac2a-e25f454e43b5" xml:space="preserve">
          <source>Use the following to start the Pig command:</source>
          <target state="new">Use the following to start the Pig command:</target>
        </trans-unit>
        <trans-unit id="f7d36c82-4a4d-42ff-9acd-3cb1f140e257" xml:space="preserve">
          <source>You will be presented with a <bpt id="831c642b-f518-4aad-864d-c19bd731b61d">&lt;code&gt;</bpt>grunt&gt;<ept id="831c642b-f518-4aad-864d-c19bd731b61d">&lt;/code&gt;</ept> prompt.</source>
          <target state="new">You will be presented with a <bpt id="831c642b-f518-4aad-864d-c19bd731b61d">&lt;code&gt;</bpt>grunt&gt;<ept id="831c642b-f518-4aad-864d-c19bd731b61d">&lt;/code&gt;</ept> prompt.</target>
        </trans-unit>
        <trans-unit id="6b82498f-faad-42e6-ab0b-2979caf96911" xml:space="preserve">
          <source>Enter the following statement:</source>
          <target state="new">Enter the following statement:</target>
        </trans-unit>
        <trans-unit id="1dd4619f-6e81-4dc6-997e-63fbbf2ece2e" xml:space="preserve">
          <source>This command loads the contents of the sample.log file into the LOGS file.</source>
          <target state="new">This command loads the contents of the sample.log file into the LOGS file.</target>
        </trans-unit>
        <trans-unit id="c95b9970-c5a4-4013-9d10-ae9b738b5d5d" xml:space="preserve">
          <source>You can view the contents of the file by using the following command:</source>
          <target state="new">You can view the contents of the file by using the following command:</target>
        </trans-unit>
        <trans-unit id="800a97ef-95a8-4c66-ad09-aa59ccabe218" xml:space="preserve">
          <source>Transform the data by applying a regular expression to extract only the logging level from each record:</source>
          <target state="new">Transform the data by applying a regular expression to extract only the logging level from each record:</target>
        </trans-unit>
        <trans-unit id="eb146d70-6369-4c76-aacf-9b8b66c96cec" xml:space="preserve">
          <source>You can use <bpt id="5abaeda2-57a6-4850-9e2d-25971a2b1517">&lt;strong&gt;</bpt>DUMP<ept id="5abaeda2-57a6-4850-9e2d-25971a2b1517">&lt;/strong&gt;</ept> to view the data after the transformation.</source>
          <target state="new">You can use <bpt id="5abaeda2-57a6-4850-9e2d-25971a2b1517">&lt;strong&gt;</bpt>DUMP<ept id="5abaeda2-57a6-4850-9e2d-25971a2b1517">&lt;/strong&gt;</ept> to view the data after the transformation.</target>
        </trans-unit>
        <trans-unit id="d853bc22-d7b0-48a4-9307-8b200344cb4d" xml:space="preserve">
          <source>In this case, <bpt id="c3a2ef6a-2ee3-4819-900e-0e9c3d069b96">&lt;code&gt;</bpt>DUMP LEVELS;<ept id="c3a2ef6a-2ee3-4819-900e-0e9c3d069b96">&lt;/code&gt;</ept>.</source>
          <target state="new">In this case, <bpt id="c3a2ef6a-2ee3-4819-900e-0e9c3d069b96">&lt;code&gt;</bpt>DUMP LEVELS;<ept id="c3a2ef6a-2ee3-4819-900e-0e9c3d069b96">&lt;/code&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="745df75d-6d47-4469-955b-a0c2e4aed04a" xml:space="preserve">
          <source>Continue applying transformations by using the following statements.</source>
          <target state="new">Continue applying transformations by using the following statements.</target>
        </trans-unit>
        <trans-unit id="de03cc89-b8a5-4eb5-904d-6298e437b7d6" xml:space="preserve">
          <source>Use <bpt id="4ccb8dd1-9b68-4fa8-8e76-be7bb7b05ecb">&lt;code&gt;</bpt>DUMP<ept id="4ccb8dd1-9b68-4fa8-8e76-be7bb7b05ecb">&lt;/code&gt;</ept> to view the result of the transformation after each step.</source>
          <target state="new">Use <bpt id="4ccb8dd1-9b68-4fa8-8e76-be7bb7b05ecb">&lt;code&gt;</bpt>DUMP<ept id="4ccb8dd1-9b68-4fa8-8e76-be7bb7b05ecb">&lt;/code&gt;</ept> to view the result of the transformation after each step.</target>
        </trans-unit>
        <trans-unit id="54a88651-c9df-4d6f-ab8c-2a0316c432cb" xml:space="preserve">
          <source>Statement</source>
          <target state="new">Statement</target>
        </trans-unit>
        <trans-unit id="fc3da1d0-331f-44ac-8814-bf0137ff3961" xml:space="preserve">
          <source>What it does</source>
          <target state="new">What it does</target>
        </trans-unit>
        <trans-unit id="416148b4-f1bd-4c55-b146-b3f137bb02d9" xml:space="preserve">
          <source>FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;</source>
          <target state="new">FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;</target>
        </trans-unit>
        <trans-unit id="5e6387d0-d045-40bc-b067-dcf81e0c356c" xml:space="preserve">
          <source>Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.</source>
          <target state="new">Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.</target>
        </trans-unit>
        <trans-unit id="16362fb5-8981-4b52-9f7b-befb186f5546" xml:space="preserve">
          <source>GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;</source>
          <target state="new">GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;</target>
        </trans-unit>
        <trans-unit id="570cbfdb-6a32-46ae-97be-1c591e915a68" xml:space="preserve">
          <source>Groups the rows by log level and stores the results into GROUPEDLEVELS.</source>
          <target state="new">Groups the rows by log level and stores the results into GROUPEDLEVELS.</target>
        </trans-unit>
        <trans-unit id="1622a4d0-1e8e-41d4-a7e2-6f239c7d3ae4" xml:space="preserve">
          <source>FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;</source>
          <target state="new">FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;</target>
        </trans-unit>
        <trans-unit id="b0c8d337-44f4-48d8-bd5b-0da96518fe7c" xml:space="preserve">
          <source>Creates a new set of data that contains each unique log level value and how many times it occurs. This is stored into FREQUENCIES</source>
          <target state="new">Creates a new set of data that contains each unique log level value and how many times it occurs. This is stored into FREQUENCIES</target>
        </trans-unit>
        <trans-unit id="412eed95-c534-4bba-bccc-54c9d365eff3" xml:space="preserve">
          <source>RESULT = order FREQUENCIES by COUNT desc;</source>
          <target state="new">RESULT = order FREQUENCIES by COUNT desc;</target>
        </trans-unit>
        <trans-unit id="e8745f37-602f-4a2e-98cb-a2f45ae287d7" xml:space="preserve">
          <source>Orders the log levels by count (descending,) and stores into RESULT</source>
          <target state="new">Orders the log levels by count (descending,) and stores into RESULT</target>
        </trans-unit>
        <trans-unit id="2f7ce36e-d98b-4322-8fff-f08e7c81b4d3" xml:space="preserve">
          <source>You can also save the results of a transformation by using the <bpt id="47742ccb-3358-4ae2-8651-1ba127f97547">&lt;code&gt;</bpt>STORE<ept id="47742ccb-3358-4ae2-8651-1ba127f97547">&lt;/code&gt;</ept> statement.</source>
          <target state="new">You can also save the results of a transformation by using the <bpt id="47742ccb-3358-4ae2-8651-1ba127f97547">&lt;code&gt;</bpt>STORE<ept id="47742ccb-3358-4ae2-8651-1ba127f97547">&lt;/code&gt;</ept> statement.</target>
        </trans-unit>
        <trans-unit id="1840aaf7-05b8-4843-bfdc-68fbc9d3b248" xml:space="preserve">
          <source>For example, the following command saves the <bpt id="f0136c96-1a00-4259-a927-f39dd18f3187">&lt;code&gt;</bpt>RESULT<ept id="f0136c96-1a00-4259-a927-f39dd18f3187">&lt;/code&gt;</ept> to the <bpt id="21933a26-8420-48ca-8826-d8802057162f">&lt;strong&gt;</bpt>/example/data/pigout<ept id="21933a26-8420-48ca-8826-d8802057162f">&lt;/strong&gt;</ept> directory in the default storage container for your cluster:</source>
          <target state="new">For example, the following command saves the <bpt id="f0136c96-1a00-4259-a927-f39dd18f3187">&lt;code&gt;</bpt>RESULT<ept id="f0136c96-1a00-4259-a927-f39dd18f3187">&lt;/code&gt;</ept> to the <bpt id="21933a26-8420-48ca-8826-d8802057162f">&lt;strong&gt;</bpt>/example/data/pigout<ept id="21933a26-8420-48ca-8826-d8802057162f">&lt;/strong&gt;</ept> directory in the default storage container for your cluster:</target>
        </trans-unit>
        <trans-unit id="2df05ffb-0227-4819-9184-1ee9628a0473" xml:space="preserve">
          <source>The data is stored in the specified directory in files named <bpt id="d60e1ac8-76ab-4a8c-9928-0b5d2637227c">&lt;strong&gt;</bpt>part-nnnnn<ept id="d60e1ac8-76ab-4a8c-9928-0b5d2637227c">&lt;/strong&gt;</ept>.</source>
          <target state="new">The data is stored in the specified directory in files named <bpt id="d60e1ac8-76ab-4a8c-9928-0b5d2637227c">&lt;strong&gt;</bpt>part-nnnnn<ept id="d60e1ac8-76ab-4a8c-9928-0b5d2637227c">&lt;/strong&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="6b4c4369-44d3-4240-b383-f1474e93ca15" xml:space="preserve">
          <source>If the directory already exists, you will receive an error message.</source>
          <target state="new">If the directory already exists, you will receive an error message.</target>
        </trans-unit>
        <trans-unit id="442e1628-25d6-40e7-89c4-8451944348fb" xml:space="preserve">
          <source>To exit the grunt prompt, enter the following statement.</source>
          <target state="new">To exit the grunt prompt, enter the following statement.</target>
        </trans-unit>
        <trans-unit id="cb0daf22-84a6-4a0e-a36e-29c5a1b28c0d" xml:space="preserve">
          <source>You can also use the Pig command to run Pig Latin that is contained in a file.</source>
          <target state="new">You can also use the Pig command to run Pig Latin that is contained in a file.</target>
        </trans-unit>
        <trans-unit id="d62d7e2b-d4ca-40c8-ac37-2a8a683b37b8" xml:space="preserve">
          <source>After exiting the grunt prompt, open <bpt id="7a15ca0d-7b88-4657-9b98-089331d1eff3">&lt;strong&gt;</bpt>Notepad<ept id="7a15ca0d-7b88-4657-9b98-089331d1eff3">&lt;/strong&gt;</ept> and create a new file named <bpt id="a11395e0-aacd-4ea7-802c-f853538a6f7e">&lt;strong&gt;</bpt>pigbatch.pig<ept id="a11395e0-aacd-4ea7-802c-f853538a6f7e">&lt;/strong&gt;</ept> in the <bpt id="9b22b04b-61c3-490f-8ef5-9de0695cf1bf">&lt;strong&gt;</bpt>%PIG_HOME%<ept id="9b22b04b-61c3-490f-8ef5-9de0695cf1bf">&lt;/strong&gt;</ept> directory.</source>
          <target state="new">After exiting the grunt prompt, open <bpt id="7a15ca0d-7b88-4657-9b98-089331d1eff3">&lt;strong&gt;</bpt>Notepad<ept id="7a15ca0d-7b88-4657-9b98-089331d1eff3">&lt;/strong&gt;</ept> and create a new file named <bpt id="a11395e0-aacd-4ea7-802c-f853538a6f7e">&lt;strong&gt;</bpt>pigbatch.pig<ept id="a11395e0-aacd-4ea7-802c-f853538a6f7e">&lt;/strong&gt;</ept> in the <bpt id="9b22b04b-61c3-490f-8ef5-9de0695cf1bf">&lt;strong&gt;</bpt>%PIG_HOME%<ept id="9b22b04b-61c3-490f-8ef5-9de0695cf1bf">&lt;/strong&gt;</ept> directory.</target>
        </trans-unit>
        <trans-unit id="15284836-9a7c-4fa7-8bdd-db05db91c24e" xml:space="preserve">
          <source>Type or paste the following lines into the <bpt id="cb0bb7b2-799f-4103-b4e6-b1e1ef141ee4">&lt;strong&gt;</bpt>pigbatch.pig<ept id="cb0bb7b2-799f-4103-b4e6-b1e1ef141ee4">&lt;/strong&gt;</ept> file, and then save it:</source>
          <target state="new">Type or paste the following lines into the <bpt id="cb0bb7b2-799f-4103-b4e6-b1e1ef141ee4">&lt;strong&gt;</bpt>pigbatch.pig<ept id="cb0bb7b2-799f-4103-b4e6-b1e1ef141ee4">&lt;/strong&gt;</ept> file, and then save it:</target>
        </trans-unit>
        <trans-unit id="de437eaf-0935-45f5-8749-c4b24b793b9c" xml:space="preserve">
          <source>Use the following to run the <bpt id="371f3dd1-1fed-4dc6-a79a-5045a0d68847">&lt;strong&gt;</bpt>pigbatch.pig<ept id="371f3dd1-1fed-4dc6-a79a-5045a0d68847">&lt;/strong&gt;</ept> file using the pig command.</source>
          <target state="new">Use the following to run the <bpt id="371f3dd1-1fed-4dc6-a79a-5045a0d68847">&lt;strong&gt;</bpt>pigbatch.pig<ept id="371f3dd1-1fed-4dc6-a79a-5045a0d68847">&lt;/strong&gt;</ept> file using the pig command.</target>
        </trans-unit>
        <trans-unit id="59b6b67f-5ba9-4861-a98f-785db6f83ec5" xml:space="preserve">
          <source>When the batch job completes, you should see the following output, which should be the same as when you used <bpt id="83efb5e0-44ed-4730-b1cf-44f66070a364">&lt;code&gt;</bpt>DUMP RESULT;<ept id="83efb5e0-44ed-4730-b1cf-44f66070a364">&lt;/code&gt;</ept> in the previous steps:</source>
          <target state="new">When the batch job completes, you should see the following output, which should be the same as when you used <bpt id="83efb5e0-44ed-4730-b1cf-44f66070a364">&lt;code&gt;</bpt>DUMP RESULT;<ept id="83efb5e0-44ed-4730-b1cf-44f66070a364">&lt;/code&gt;</ept> in the previous steps:</target>
        </trans-unit>
        <trans-unit id="2f13c8af-e94e-4fb3-aca7-76e9bf42a180" xml:space="preserve">
          <source>As you can see, the Pig command allows you to interactively run MapReduce operations, or run Pig Latin jobs that are stored in a batch file.</source>
          <target state="new">As you can see, the Pig command allows you to interactively run MapReduce operations, or run Pig Latin jobs that are stored in a batch file.</target>
        </trans-unit>
        <trans-unit id="d550642a-4297-40d5-9461-cb21d6c41278" xml:space="preserve">
          <source>For general information about Pig in HDInsight:</source>
          <target state="new">For general information about Pig in HDInsight:</target>
        </trans-unit>
        <trans-unit id="3d40f790-fd80-4210-80c3-b80e57d0bb64" xml:space="preserve">
          <source><bpt id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;/linkText&gt;</ept><bpt id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;title&gt;</bpt><ept id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;/linkText&gt;</ept><bpt id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;title&gt;</bpt><ept id="25b7fd7f-00cc-4ea6-82ae-dd9f9dee7e7a">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="89bcc196-cd95-4ae4-990b-51142ecbdc15" xml:space="preserve">
          <source>For information about other ways you can work with Hadoop on HDInsight:</source>
          <target state="new">For information about other ways you can work with Hadoop on HDInsight:</target>
        </trans-unit>
        <trans-unit id="c0d36d7a-3505-41bd-bd12-bc6cee0f6835" xml:space="preserve">
          <source><bpt id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;/linkText&gt;</ept><bpt id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;title&gt;</bpt><ept id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;/linkText&gt;</ept><bpt id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;title&gt;</bpt><ept id="1471d98b-410b-4f44-bae9-4097681ddc3f">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="6e65662b-dcd2-45b9-8abd-0d944a087d7d" xml:space="preserve">
          <source><bpt id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;linkText&gt;</bpt>Use MapReduce with Hadoop on HDInsight<ept id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;/linkText&gt;</ept><bpt id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;title&gt;</bpt><ept id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;linkText&gt;</bpt>Use MapReduce with Hadoop on HDInsight<ept id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;/linkText&gt;</ept><bpt id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;title&gt;</bpt><ept id="43b1d3ef-3b53-42ed-ab1f-0b9d14137593">&lt;/title&gt;</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>