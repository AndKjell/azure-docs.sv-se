<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="zh-cn" original="foo.file" tool-id="db223df9-8745-4571-adaf-7a40aa18e36a" product-name="foo" product-version="1.0" build-num="1">
    <header>
      <tool tool-id="db223df9-8745-4571-adaf-7a40aa18e36a" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group id="5d2a4df5-76c0-47b6-a728-5b6aa87802ac">
        <trans-unit id="571acca1-b5e9-4e95-83ca-23d9ff5ed990" xml:space="preserve">
          <source>Use Script Action to install Spark on Hadoop cluster | Microsoft Azure</source>
          <target state="new">Use Script Action to install Spark on Hadoop cluster | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="f1ec1cbc-ab72-4693-ac40-e1f54ac2c4f7" xml:space="preserve">
          <source>Learn how to customize an HDInsight cluster with Spark. You'll use a Script Action configuration option to use a script to install Spark.</source>
          <target state="new">Learn how to customize an HDInsight cluster with Spark. You'll use a Script Action configuration option to use a script to install Spark.</target>
        </trans-unit>
        <trans-unit id="1a144cb6-46ac-469f-a9e5-7fcae2b71c12" xml:space="preserve">
          <source>In this document, you will learn how to install Spark by using Script Action.</source>
          <target state="new">In this document, you will learn how to install Spark by using Script Action.</target>
        </trans-unit>
        <trans-unit id="406d875b-febb-4a5f-9dc3-729e0138a51f" xml:space="preserve">
          <source>Script Action lets you run scripts to customize a cluster, only when the cluster is being created.</source>
          <target state="new">Script Action lets you run scripts to customize a cluster, only when the cluster is being created.</target>
        </trans-unit>
        <trans-unit id="6d9999d9-1737-4f28-a7cc-c9964cd87d18" xml:space="preserve">
          <source>For more information, see <bpt id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;linkText&gt;</bpt>Customize HDInsight cluster using Script Action[hdinsight-cluster-customize]<ept id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;/linkText&gt;</ept><bpt id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;title&gt;</bpt><ept id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;/title&gt;</ept>.</source>
          <target state="new">For more information, see <bpt id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;linkText&gt;</bpt>Customize HDInsight cluster using Script Action[hdinsight-cluster-customize]<ept id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;/linkText&gt;</ept><bpt id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;title&gt;</bpt><ept id="12c04e3c-a8bc-4222-8f66-9e3a563c58b6">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="b1acb2ef-6102-4203-af43-7423eb0c12a9" xml:space="preserve">
          <source>Once you have installed Spark, you'll also learn how to run a Spark query on HDInsight clusters.</source>
          <target state="new">Once you have installed Spark, you'll also learn how to run a Spark query on HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="8354aa35-37a4-45d8-a621-98370fff8e3b" xml:space="preserve">
          <source>HDInsight also provides Spark as a cluster type, which means you can now directly provision a Spark cluster without modifying a Hadoop cluster.</source>
          <target state="new">HDInsight also provides Spark as a cluster type, which means you can now directly provision a Spark cluster without modifying a Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="1d86eed2-395a-4f58-887d-5a1941261874" xml:space="preserve">
          <source>However, this is limited to Windows-based clusters currently.</source>
          <target state="new">However, this is limited to Windows-based clusters currently.</target>
        </trans-unit>
        <trans-unit id="ad7d476f-0dbd-48be-b1eb-243549531f5c" xml:space="preserve">
          <source>Using the Spark cluster type, you get a Windows-based HDInsight version 3.2 cluster with Spark version 1.3.1.</source>
          <target state="new">Using the Spark cluster type, you get a Windows-based HDInsight version 3.2 cluster with Spark version 1.3.1.</target>
        </trans-unit>
        <trans-unit id="7bf58ef5-7dfb-4efa-a681-e1efdc15d7c5" xml:space="preserve">
          <source>For more information, see <bpt id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;linkText&gt;</bpt>Get Started with Apache Spark on HDInsight<ept id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;/linkText&gt;</ept><bpt id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;title&gt;</bpt><ept id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;/title&gt;</ept>.</source>
          <target state="new">For more information, see <bpt id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;linkText&gt;</bpt>Get Started with Apache Spark on HDInsight<ept id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;/linkText&gt;</ept><bpt id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;title&gt;</bpt><ept id="151652cf-177a-4b1e-8d86-54a46c5fd1d3">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="abeaf21a-5595-481a-a153-6cf44e98fa50" xml:space="preserve">
          <source>&lt;a href="http://spark.apache.org/docs/latest/index.html" target="_blank"&gt;Apache Spark&lt;/a&gt; is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</source>
          <target state="new">&lt;a href="http://spark.apache.org/docs/latest/index.html" target="_blank"&gt;Apache Spark&lt;/a&gt; is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</target>
        </trans-unit>
        <trans-unit id="3d33f886-8209-4e2b-b983-493f130142a8" xml:space="preserve">
          <source>Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</source>
          <target state="new">Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</target>
        </trans-unit>
        <trans-unit id="2453853c-c581-4165-b7e5-db9cda7874e1" xml:space="preserve">
          <source>Spark can also be used to perform conventional disk-based data processing.</source>
          <target state="new">Spark can also be used to perform conventional disk-based data processing.</target>
        </trans-unit>
        <trans-unit id="4b6825da-c313-4cef-9793-07c158a80c91" xml:space="preserve">
          <source>Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages.</source>
          <target state="new">Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages.</target>
        </trans-unit>
        <trans-unit id="cab90240-6a42-4af7-960b-91342249ae8e" xml:space="preserve">
          <source>Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.</source>
          <target state="new">Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.</target>
        </trans-unit>
        <trans-unit id="3aff6463-c71d-4d32-a57d-bd3ab79f04ad" xml:space="preserve">
          <source>This topic provides instructions on how to customize an HDInsight cluster to install Spark.</source>
          <target state="new">This topic provides instructions on how to customize an HDInsight cluster to install Spark.</target>
        </trans-unit>
        <trans-unit id="e733c05e-fb37-4fb9-ab2e-a8e41ca52256" xml:space="preserve">
          <source>In this topic, we use a Script Action custom script to install Spark on an HDInsight cluster.</source>
          <target state="new">In this topic, we use a Script Action custom script to install Spark on an HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="6b388178-c8f8-499a-983c-45431a3be897" xml:space="preserve">
          <source>This script installs Spark 1.3.1.</source>
          <target state="new">This script installs Spark 1.3.1.</target>
        </trans-unit>
        <trans-unit id="94558aaa-cdea-42fc-ad96-7beca7d97750" xml:space="preserve">
          <source>You can modify this script or create your own script to install other versions of Spark.</source>
          <target state="new">You can modify this script or create your own script to install other versions of Spark.</target>
        </trans-unit>
        <trans-unit id="57049ca0-d783-47dc-b8c0-13e3d79c1fb0" xml:space="preserve">
          <source>This script installs Spark version 1.3.1 into <bpt id="aaae56ff-faa4-46e8-994f-cd28979a7c46">&lt;code&gt;</bpt>/usr/hdp/current/spark<ept id="aaae56ff-faa4-46e8-994f-cd28979a7c46">&lt;/code&gt;</ept>.</source>
          <target state="new">This script installs Spark version 1.3.1 into <bpt id="aaae56ff-faa4-46e8-994f-cd28979a7c46">&lt;code&gt;</bpt>/usr/hdp/current/spark<ept id="aaae56ff-faa4-46e8-994f-cd28979a7c46">&lt;/code&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="0948381c-04d7-4aea-bbea-bafd1437dc86" xml:space="preserve">
          <source>A sample script to install Spark on an HDInsight cluster is available from a read-only Azure storage blob at <bpt id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;linkText&gt;</bpt>https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh<ept id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;/linkText&gt;</ept><bpt id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;title&gt;</bpt><ept id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;/title&gt;</ept>.</source>
          <target state="new">A sample script to install Spark on an HDInsight cluster is available from a read-only Azure storage blob at <bpt id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;linkText&gt;</bpt>https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh<ept id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;/linkText&gt;</ept><bpt id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;title&gt;</bpt><ept id="a40b976d-5d45-4512-8c29-435d5d43cc0f">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="96422193-d629-4b3f-b4e6-6b6878d67345" xml:space="preserve">
          <source>This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal.</source>
          <target state="new">This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal.</target>
        </trans-unit>
        <trans-unit id="6557eeb8-7ad2-49a1-9290-e73efbe837db" xml:space="preserve">
          <source>You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script.</source>
          <target state="new">You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script.</target>
        </trans-unit>
        <trans-unit id="14915732-d48b-4e93-8b0a-d2a1402af6e4" xml:space="preserve">
          <source>For more information on using these methods, see <bpt id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;linkText&gt;</bpt>Customize HDInsight clusters with Script Actions<ept id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;/linkText&gt;</ept><bpt id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;title&gt;</bpt><ept id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;/title&gt;</ept>.</source>
          <target state="new">For more information on using these methods, see <bpt id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;linkText&gt;</bpt>Customize HDInsight clusters with Script Actions<ept id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;/linkText&gt;</ept><bpt id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;title&gt;</bpt><ept id="b4edb436-344f-41f6-89ba-fb7b5f878756">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="0df3c058-eba0-475f-81b1-be758f434c55" xml:space="preserve">
          <source>Start provisioning a cluster by using the steps in <bpt id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;/linkText&gt;</ept><bpt id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;title&gt;</bpt><ept id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;/title&gt;</ept>, but do not complete provisioning.</source>
          <target state="new">Start provisioning a cluster by using the steps in <bpt id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;/linkText&gt;</ept><bpt id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;title&gt;</bpt><ept id="c8df509a-b0e5-4b65-a607-3e52b2f470fa">&lt;/title&gt;</ept>, but do not complete provisioning.</target>
        </trans-unit>
        <trans-unit id="0e1e2fcd-f102-4642-a042-da746d55fffc" xml:space="preserve">
          <source>On the <bpt id="541a633c-3230-47e5-99af-19b41407ceba">&lt;strong&gt;</bpt>Optional Configuration<ept id="541a633c-3230-47e5-99af-19b41407ceba">&lt;/strong&gt;</ept> blade, select <bpt id="d0fb1025-1d4a-4f2a-973a-ebd411ecb788">&lt;strong&gt;</bpt>Script Actions<ept id="d0fb1025-1d4a-4f2a-973a-ebd411ecb788">&lt;/strong&gt;</ept>, and provide the information below:</source>
          <target state="new">On the <bpt id="541a633c-3230-47e5-99af-19b41407ceba">&lt;strong&gt;</bpt>Optional Configuration<ept id="541a633c-3230-47e5-99af-19b41407ceba">&lt;/strong&gt;</ept> blade, select <bpt id="d0fb1025-1d4a-4f2a-973a-ebd411ecb788">&lt;strong&gt;</bpt>Script Actions<ept id="d0fb1025-1d4a-4f2a-973a-ebd411ecb788">&lt;/strong&gt;</ept>, and provide the information below:</target>
        </trans-unit>
        <trans-unit id="3de94495-35a5-4b0a-a3f4-c34a9ea72da4" xml:space="preserve">
          <source><bpt id="6b108250-a74b-40ed-b5a8-20c7d981a410">&lt;strong&gt;</bpt>NAME<ept id="6b108250-a74b-40ed-b5a8-20c7d981a410">&lt;/strong&gt;</ept>: Enter a friendly name for the script action.</source>
          <target state="new"><bpt id="6b108250-a74b-40ed-b5a8-20c7d981a410">&lt;strong&gt;</bpt>NAME<ept id="6b108250-a74b-40ed-b5a8-20c7d981a410">&lt;/strong&gt;</ept>: Enter a friendly name for the script action.</target>
        </trans-unit>
        <trans-unit id="56f71c12-6e92-447f-a996-1ed68a9a8a65" xml:space="preserve">
          <source><bpt id="b7d5f3e8-25b7-41e0-98d2-90ec73e0ea55">&lt;strong&gt;</bpt>SCRIPT URI<ept id="b7d5f3e8-25b7-41e0-98d2-90ec73e0ea55">&lt;/strong&gt;</ept>: https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh</source>
          <target state="new"><bpt id="b7d5f3e8-25b7-41e0-98d2-90ec73e0ea55">&lt;strong&gt;</bpt>SCRIPT URI<ept id="b7d5f3e8-25b7-41e0-98d2-90ec73e0ea55">&lt;/strong&gt;</ept>: https://hdiconfigactions.blob.core.windows.net/linuxsparkconfigactionv01/spark-installer-v01.sh</target>
        </trans-unit>
        <trans-unit id="a6130cf6-73ed-4090-bed0-790ac30839be" xml:space="preserve">
          <source><bpt id="988c5e46-6d52-4e31-b64b-cb666eb9e70a">&lt;strong&gt;</bpt>HEAD<ept id="988c5e46-6d52-4e31-b64b-cb666eb9e70a">&lt;/strong&gt;</ept>: Check this option</source>
          <target state="new"><bpt id="988c5e46-6d52-4e31-b64b-cb666eb9e70a">&lt;strong&gt;</bpt>HEAD<ept id="988c5e46-6d52-4e31-b64b-cb666eb9e70a">&lt;/strong&gt;</ept>: Check this option</target>
        </trans-unit>
        <trans-unit id="7a29f449-f0b8-43aa-b45f-c07aa1492f12" xml:space="preserve">
          <source><bpt id="fc900441-8d62-4a43-886c-2b44a0e9d15f">&lt;strong&gt;</bpt>WORKER<ept id="fc900441-8d62-4a43-886c-2b44a0e9d15f">&lt;/strong&gt;</ept>: Check this option</source>
          <target state="new"><bpt id="fc900441-8d62-4a43-886c-2b44a0e9d15f">&lt;strong&gt;</bpt>WORKER<ept id="fc900441-8d62-4a43-886c-2b44a0e9d15f">&lt;/strong&gt;</ept>: Check this option</target>
        </trans-unit>
        <trans-unit id="0fd0ef19-e72e-4649-b7f3-3279059ac55b" xml:space="preserve">
          <source><bpt id="e4392182-04aa-4491-b09a-e4fd66daceb3">&lt;strong&gt;</bpt>ZOOKEEPER<ept id="e4392182-04aa-4491-b09a-e4fd66daceb3">&lt;/strong&gt;</ept>: Check this option to install on the Zookeeper node.</source>
          <target state="new"><bpt id="e4392182-04aa-4491-b09a-e4fd66daceb3">&lt;strong&gt;</bpt>ZOOKEEPER<ept id="e4392182-04aa-4491-b09a-e4fd66daceb3">&lt;/strong&gt;</ept>: Check this option to install on the Zookeeper node.</target>
        </trans-unit>
        <trans-unit id="60c20fe2-6f6f-46b7-ae8a-26610b9601ba" xml:space="preserve">
          <source><bpt id="45c6bb57-45d0-40b0-b6eb-1094086d8873">&lt;strong&gt;</bpt>PARAMETERS<ept id="45c6bb57-45d0-40b0-b6eb-1094086d8873">&lt;/strong&gt;</ept>: Leave this field blank</source>
          <target state="new"><bpt id="45c6bb57-45d0-40b0-b6eb-1094086d8873">&lt;strong&gt;</bpt>PARAMETERS<ept id="45c6bb57-45d0-40b0-b6eb-1094086d8873">&lt;/strong&gt;</ept>: Leave this field blank</target>
        </trans-unit>
        <trans-unit id="f7e8ea62-ecde-4bd7-9055-f1a983119e93" xml:space="preserve">
          <source>At the bottom of the <bpt id="76522bbd-e18f-40d7-ab22-b0dae4d0215a">&lt;strong&gt;</bpt>Script Actions<ept id="76522bbd-e18f-40d7-ab22-b0dae4d0215a">&lt;/strong&gt;</ept>, use the <bpt id="18259f3a-4d02-4029-a1e1-33fb7d7c59bc">&lt;strong&gt;</bpt>Select<ept id="18259f3a-4d02-4029-a1e1-33fb7d7c59bc">&lt;/strong&gt;</ept> button to save the configuration.</source>
          <target state="new">At the bottom of the <bpt id="76522bbd-e18f-40d7-ab22-b0dae4d0215a">&lt;strong&gt;</bpt>Script Actions<ept id="76522bbd-e18f-40d7-ab22-b0dae4d0215a">&lt;/strong&gt;</ept>, use the <bpt id="18259f3a-4d02-4029-a1e1-33fb7d7c59bc">&lt;strong&gt;</bpt>Select<ept id="18259f3a-4d02-4029-a1e1-33fb7d7c59bc">&lt;/strong&gt;</ept> button to save the configuration.</target>
        </trans-unit>
        <trans-unit id="33a130fe-3e1a-4ecf-bf9b-17bb59ac21f6" xml:space="preserve">
          <source>Finally, use the <bpt id="6c624bab-693a-45e9-be3c-9628a069b307">&lt;strong&gt;</bpt>Select<ept id="6c624bab-693a-45e9-be3c-9628a069b307">&lt;/strong&gt;</ept> button at the bottom of the <bpt id="44c2e7c3-3c26-4fe5-ba17-70fb498b3440">&lt;strong&gt;</bpt>Optional Configuration<ept id="44c2e7c3-3c26-4fe5-ba17-70fb498b3440">&lt;/strong&gt;</ept> blade to save the optional configuration information.</source>
          <target state="new">Finally, use the <bpt id="6c624bab-693a-45e9-be3c-9628a069b307">&lt;strong&gt;</bpt>Select<ept id="6c624bab-693a-45e9-be3c-9628a069b307">&lt;/strong&gt;</ept> button at the bottom of the <bpt id="44c2e7c3-3c26-4fe5-ba17-70fb498b3440">&lt;strong&gt;</bpt>Optional Configuration<ept id="44c2e7c3-3c26-4fe5-ba17-70fb498b3440">&lt;/strong&gt;</ept> blade to save the optional configuration information.</target>
        </trans-unit>
        <trans-unit id="67f53965-0635-4bcc-895d-4a1160049994" xml:space="preserve">
          <source>Continue provisining the cluster as described in <bpt id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;/linkText&gt;</ept><bpt id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;title&gt;</bpt><ept id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;/title&gt;</ept>.</source>
          <target state="new">Continue provisining the cluster as described in <bpt id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;linkText&gt;</bpt>Provision Linux-based HDInsight clusters<ept id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;/linkText&gt;</ept><bpt id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;title&gt;</bpt><ept id="2822164e-1878-4c78-9bfb-7628c5c09e23">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="77955fe1-237f-448b-affd-4748080b3128" xml:space="preserve">
          <source>Spark provides APIs in Scala, Python, and Java.</source>
          <target state="new">Spark provides APIs in Scala, Python, and Java.</target>
        </trans-unit>
        <trans-unit id="d62d42f8-f1c2-4bfc-9587-c47fa5aa9cda" xml:space="preserve">
          <source>You can also use the interactive Spark shell to run Spark queries.</source>
          <target state="new">You can also use the interactive Spark shell to run Spark queries.</target>
        </trans-unit>
        <trans-unit id="52d80323-1c3a-4cc7-8d6e-624b2e86f0f4" xml:space="preserve">
          <source>Once your cluster has finished provisioning, use the following to connect to your HDInsight cluster:</source>
          <target state="new">Once your cluster has finished provisioning, use the following to connect to your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="b3431bc3-9aed-4667-a166-25c2c82ed175" xml:space="preserve">
          <source>For more information on using SSH with HDInsight, see the following:</source>
          <target state="new">For more information on using SSH with HDInsight, see the following:</target>
        </trans-unit>
        <trans-unit id="9ae85a3f-db25-4867-876e-1267285a6a76" xml:space="preserve">
          <source><bpt id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;/linkText&gt;</ept><bpt id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;title&gt;</bpt><ept id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;/linkText&gt;</ept><bpt id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;title&gt;</bpt><ept id="994950ec-23c6-41b4-b918-ef53735c81e6">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="fc31a1ca-d24d-4725-a8b6-e04cf623d084" xml:space="preserve">
          <source><bpt id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;/linkText&gt;</ept><bpt id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;title&gt;</bpt><ept id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;/linkText&gt;</ept><bpt id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;title&gt;</bpt><ept id="a82653b6-98b8-4ebb-87ef-e79fd0b16b49">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="797a20a7-3972-400b-a4ea-1222c74ce72a" xml:space="preserve">
          <source>Once connected, use the following sections for specific steps on using Spark:</source>
          <target state="new">Once connected, use the following sections for specific steps on using Spark:</target>
        </trans-unit>
        <trans-unit id="43f1077c-fda9-47ad-b413-431e6ee7520f" xml:space="preserve">
          <source><bpt id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;linkText&gt;</bpt>Using the Spark shell to run interactive queries<ept id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;/linkText&gt;</ept><bpt id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;title&gt;</bpt><ept id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;linkText&gt;</bpt>Using the Spark shell to run interactive queries<ept id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;/linkText&gt;</ept><bpt id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;title&gt;</bpt><ept id="66124bb1-9a76-405d-98cf-5756cede075e">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="7887652a-d16d-4f14-badb-8ea1bcab2897" xml:space="preserve">
          <source><bpt id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;linkText&gt;</bpt>Using the Spark shell to run Spark SQL queries<ept id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;/linkText&gt;</ept><bpt id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;title&gt;</bpt><ept id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;/title&gt;</ept> </source>
          <target state="new"><bpt id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;linkText&gt;</bpt>Using the Spark shell to run Spark SQL queries<ept id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;/linkText&gt;</ept><bpt id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;title&gt;</bpt><ept id="ccf77887-920c-4bc6-be34-e218ef9d4d02">&lt;/title&gt;</ept> </target>
        </trans-unit>
        <trans-unit id="e8bc98a2-2f1e-487a-9a4b-2f5332c5cd5e" xml:space="preserve">
          <source><bpt id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;linkText&gt;</bpt>Using a standalone Scala program<ept id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;/linkText&gt;</ept><bpt id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;title&gt;</bpt><ept id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;linkText&gt;</bpt>Using a standalone Scala program<ept id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;/linkText&gt;</ept><bpt id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;title&gt;</bpt><ept id="ad59170a-5454-4a9e-b20c-afb9d222c15a">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="a7e008d2-9e8c-4340-8604-a9678a3117c6" xml:space="preserve">
          <source>Run the following command to start the Spark shell:</source>
          <target state="new">Run the following command to start the Spark shell:</target>
        </trans-unit>
        <trans-unit id="80036838-eca2-4d56-9fe9-a4902be30499" xml:space="preserve">
          <source>After the command finishes running, you should get a Scala prompt:</source>
          <target state="new">After the command finishes running, you should get a Scala prompt:</target>
        </trans-unit>
        <trans-unit id="036f6b03-1621-42d0-9fde-874cf3137ae9" xml:space="preserve">
          <source>On the Scala prompt, enter the Spark query shown below.</source>
          <target state="new">On the Scala prompt, enter the Spark query shown below.</target>
        </trans-unit>
        <trans-unit id="77010947-12e7-4715-a593-33fbabaa1735" xml:space="preserve">
          <source>This query counts the occurrence of each word in the davinci.txt file that is available at the /example/data/gutenberg/ location on the Azure Blob storage associated with the cluster.</source>
          <target state="new">This query counts the occurrence of each word in the davinci.txt file that is available at the /example/data/gutenberg/ location on the Azure Blob storage associated with the cluster.</target>
        </trans-unit>
        <trans-unit id="46adaa7c-10c2-4b18-8a3e-7d03c6f35fa3" xml:space="preserve">
          <source>The output should resemble the following:</source>
          <target state="new">The output should resemble the following:</target>
        </trans-unit>
        <trans-unit id="bd445168-0182-4fda-a154-e1e5c564b1c2" xml:space="preserve">
          <source>Enter :q to exit the Scala prompt.</source>
          <target state="new">Enter :q to exit the Scala prompt.</target>
        </trans-unit>
        <trans-unit id="dab7f453-2d17-4df0-81b6-2b4c5bc41175" xml:space="preserve">
          <source>Spark SQL allows you to use Spark to run relational queries expressed in Structured Query Language (SQL), HiveQL, or Scala.</source>
          <target state="new">Spark SQL allows you to use Spark to run relational queries expressed in Structured Query Language (SQL), HiveQL, or Scala.</target>
        </trans-unit>
        <trans-unit id="2e7fa525-1a3a-45f0-a34f-29e29a199e0e" xml:space="preserve">
          <source>In this section, we look at using Spark to run a Hive query on a sample Hive table.</source>
          <target state="new">In this section, we look at using Spark to run a Hive query on a sample Hive table.</target>
        </trans-unit>
        <trans-unit id="6af8c722-d94b-4ca5-888f-6afd8ce17028" xml:space="preserve">
          <source>The Hive table used in this section (called <bpt id="fa552b37-78c8-4863-9f1c-40a14b9bc246">&lt;strong&gt;</bpt>hivesampletable<ept id="fa552b37-78c8-4863-9f1c-40a14b9bc246">&lt;/strong&gt;</ept>) is available by default when you provision a cluster.</source>
          <target state="new">The Hive table used in this section (called <bpt id="fa552b37-78c8-4863-9f1c-40a14b9bc246">&lt;strong&gt;</bpt>hivesampletable<ept id="fa552b37-78c8-4863-9f1c-40a14b9bc246">&lt;/strong&gt;</ept>) is available by default when you provision a cluster.</target>
        </trans-unit>
        <trans-unit id="4898c64c-39f0-4251-8e6e-6b2032aedb05" xml:space="preserve">
          <source>Run the following command to start the Spark shell:</source>
          <target state="new">Run the following command to start the Spark shell:</target>
        </trans-unit>
        <trans-unit id="11827972-976a-46d6-aa35-ce510bc1a5ec" xml:space="preserve">
          <source>After the command finishes running, you should get a Scala prompt:</source>
          <target state="new">After the command finishes running, you should get a Scala prompt:</target>
        </trans-unit>
        <trans-unit id="3b52312a-cd23-4851-bda3-f69781860a1a" xml:space="preserve">
          <source>On the Scala prompt, set the Hive context.</source>
          <target state="new">On the Scala prompt, set the Hive context.</target>
        </trans-unit>
        <trans-unit id="6ae8562e-006a-41f9-b9f5-5a88b4be337a" xml:space="preserve">
          <source>This is required to work with Hive queries by using Spark.</source>
          <target state="new">This is required to work with Hive queries by using Spark.</target>
        </trans-unit>
        <trans-unit id="1a0782f2-7708-4bfb-b3e0-87ac55fb4de1" xml:space="preserve">
          <source><bpt id="4753c6ac-e560-432a-b546-1f9543e41f23">&lt;code&gt;</bpt>sc<ept id="4753c6ac-e560-432a-b546-1f9543e41f23">&lt;/code&gt;</ept> in this statement is the default Spark context that is set when you start the Spark shell.</source>
          <target state="new"><bpt id="4753c6ac-e560-432a-b546-1f9543e41f23">&lt;code&gt;</bpt>sc<ept id="4753c6ac-e560-432a-b546-1f9543e41f23">&lt;/code&gt;</ept> in this statement is the default Spark context that is set when you start the Spark shell.</target>
        </trans-unit>
        <trans-unit id="dffa424e-e41d-4ff5-814e-d659c732cff2" xml:space="preserve">
          <source>Run a Hive query by using the Hive context and print the output to the console.</source>
          <target state="new">Run a Hive query by using the Hive context and print the output to the console.</target>
        </trans-unit>
        <trans-unit id="1aaed778-7670-4c30-acc6-06f722e33f41" xml:space="preserve">
          <source>The query retrieves data on devices of a specific make and limits the number of records retrieved to 20.</source>
          <target state="new">The query retrieves data on devices of a specific make and limits the number of records retrieved to 20.</target>
        </trans-unit>
        <trans-unit id="c88f0dca-1469-4608-882c-797994f63003" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="50b21e58-c7a7-4502-a96c-223bc0b4f0a4" xml:space="preserve">
          <source>Enter :q to exit the Scala prompt.</source>
          <target state="new">Enter :q to exit the Scala prompt.</target>
        </trans-unit>
        <trans-unit id="883ed382-c83b-42ab-a186-3600ef453b08" xml:space="preserve">
          <source>In this section, you will create a Scala application that counts the number of lines containing the letters 'a' and 'b' in a sample data file (/example/data/gutenberg/davinci.txt.)</source>
          <target state="new">In this section, you will create a Scala application that counts the number of lines containing the letters 'a' and 'b' in a sample data file (/example/data/gutenberg/davinci.txt.)</target>
        </trans-unit>
        <trans-unit id="1aec4e53-ea26-4c88-a40d-a1c9c2b257c0" xml:space="preserve">
          <source>Use the following commands to install the Scala Build Tool:</source>
          <target state="new">Use the following commands to install the Scala Build Tool:</target>
        </trans-unit>
        <trans-unit id="f4b7fda3-1f1f-4c70-8220-e01e6753a1f4" xml:space="preserve">
          <source>When prompted, select <bpt id="832d5755-b585-4410-9cb9-87bdb1c00beb">&lt;strong&gt;</bpt>Y<ept id="832d5755-b585-4410-9cb9-87bdb1c00beb">&lt;/strong&gt;</ept> to continue.</source>
          <target state="new">When prompted, select <bpt id="832d5755-b585-4410-9cb9-87bdb1c00beb">&lt;strong&gt;</bpt>Y<ept id="832d5755-b585-4410-9cb9-87bdb1c00beb">&lt;/strong&gt;</ept> to continue.</target>
        </trans-unit>
        <trans-unit id="484da9c1-6cb5-4ff8-8e21-b49bb4829fb6" xml:space="preserve">
          <source>Create the directory structure for the Scala project:</source>
          <target state="new">Create the directory structure for the Scala project:</target>
        </trans-unit>
        <trans-unit id="5b273f8e-f755-4138-828e-942ae607f8de" xml:space="preserve">
          <source>Create a new file named <bpt id="626a32d8-f212-464c-8d3f-7c3a2338b37b">&lt;strong&gt;</bpt>simple.sbt<ept id="626a32d8-f212-464c-8d3f-7c3a2338b37b">&lt;/strong&gt;</ept>, which contains the configuration information for this project.</source>
          <target state="new">Create a new file named <bpt id="626a32d8-f212-464c-8d3f-7c3a2338b37b">&lt;strong&gt;</bpt>simple.sbt<ept id="626a32d8-f212-464c-8d3f-7c3a2338b37b">&lt;/strong&gt;</ept>, which contains the configuration information for this project.</target>
        </trans-unit>
        <trans-unit id="5ea55eb4-c732-4e96-94d9-78e62daed115" xml:space="preserve">
          <source>Use the following as the contents of the file:</source>
          <target state="new">Use the following as the contents of the file:</target>
        </trans-unit>
        <trans-unit id="fb6a1a56-9359-49a5-a4b6-faad7244decf" xml:space="preserve">
          <source>Make sure you retain the empty lines between each entry.</source>
          <target state="new">Make sure you retain the empty lines between each entry.</target>
        </trans-unit>
        <trans-unit id="47cc1bb2-1f3f-4994-921e-1ee0c1c4e4c5" xml:space="preserve">
          <source>Use <bpt id="4e03f2d2-6913-4106-b70a-90472b5ab573">&lt;strong&gt;</bpt>Ctrl+X<ept id="4e03f2d2-6913-4106-b70a-90472b5ab573">&lt;/strong&gt;</ept>, then <bpt id="4c8e9d70-f6ad-4e1a-af9c-73e75553f4f6">&lt;strong&gt;</bpt>Y<ept id="4c8e9d70-f6ad-4e1a-af9c-73e75553f4f6">&lt;/strong&gt;</ept> and <bpt id="284f6989-9772-43d0-8554-f2861ff5838f">&lt;strong&gt;</bpt>Enter<ept id="284f6989-9772-43d0-8554-f2861ff5838f">&lt;/strong&gt;</ept> to save the file.</source>
          <target state="new">Use <bpt id="4e03f2d2-6913-4106-b70a-90472b5ab573">&lt;strong&gt;</bpt>Ctrl+X<ept id="4e03f2d2-6913-4106-b70a-90472b5ab573">&lt;/strong&gt;</ept>, then <bpt id="4c8e9d70-f6ad-4e1a-af9c-73e75553f4f6">&lt;strong&gt;</bpt>Y<ept id="4c8e9d70-f6ad-4e1a-af9c-73e75553f4f6">&lt;/strong&gt;</ept> and <bpt id="284f6989-9772-43d0-8554-f2861ff5838f">&lt;strong&gt;</bpt>Enter<ept id="284f6989-9772-43d0-8554-f2861ff5838f">&lt;/strong&gt;</ept> to save the file.</target>
        </trans-unit>
        <trans-unit id="e06484f9-c595-4a6f-bd57-e2b89cad9ec2" xml:space="preserve">
          <source>Use the following command to create a new file named <bpt id="e3078c80-455d-48dd-94fb-da223165a58b">&lt;strong&gt;</bpt>SimpleApp.scala<ept id="e3078c80-455d-48dd-94fb-da223165a58b">&lt;/strong&gt;</ept> in the <bpt id="6247b4d0-0d15-407b-b0a9-c12ebf3589c3">&lt;strong&gt;</bpt>SimpleScalaApp/src/main/scala<ept id="6247b4d0-0d15-407b-b0a9-c12ebf3589c3">&lt;/strong&gt;</ept> directory:</source>
          <target state="new">Use the following command to create a new file named <bpt id="e3078c80-455d-48dd-94fb-da223165a58b">&lt;strong&gt;</bpt>SimpleApp.scala<ept id="e3078c80-455d-48dd-94fb-da223165a58b">&lt;/strong&gt;</ept> in the <bpt id="6247b4d0-0d15-407b-b0a9-c12ebf3589c3">&lt;strong&gt;</bpt>SimpleScalaApp/src/main/scala<ept id="6247b4d0-0d15-407b-b0a9-c12ebf3589c3">&lt;/strong&gt;</ept> directory:</target>
        </trans-unit>
        <trans-unit id="19dee512-3212-41f2-bbe1-49883070fb1a" xml:space="preserve">
          <source>Use the following as the contents of the file:</source>
          <target state="new">Use the following as the contents of the file:</target>
        </trans-unit>
        <trans-unit id="68915e01-d630-4586-98b1-cea4989fc427" xml:space="preserve">
          <source>Use <bpt id="4988bfb1-f482-4311-95bd-7c3493baa752">&lt;strong&gt;</bpt>Ctrl+X<ept id="4988bfb1-f482-4311-95bd-7c3493baa752">&lt;/strong&gt;</ept>, then <bpt id="eb5da9e7-c5a1-4496-8186-537e56ba2fb0">&lt;strong&gt;</bpt>Y<ept id="eb5da9e7-c5a1-4496-8186-537e56ba2fb0">&lt;/strong&gt;</ept>, and <bpt id="8026e213-df12-4eca-90d8-9cd8cb095f1a">&lt;strong&gt;</bpt>Enter<ept id="8026e213-df12-4eca-90d8-9cd8cb095f1a">&lt;/strong&gt;</ept> to save the file.</source>
          <target state="new">Use <bpt id="4988bfb1-f482-4311-95bd-7c3493baa752">&lt;strong&gt;</bpt>Ctrl+X<ept id="4988bfb1-f482-4311-95bd-7c3493baa752">&lt;/strong&gt;</ept>, then <bpt id="eb5da9e7-c5a1-4496-8186-537e56ba2fb0">&lt;strong&gt;</bpt>Y<ept id="eb5da9e7-c5a1-4496-8186-537e56ba2fb0">&lt;/strong&gt;</ept>, and <bpt id="8026e213-df12-4eca-90d8-9cd8cb095f1a">&lt;strong&gt;</bpt>Enter<ept id="8026e213-df12-4eca-90d8-9cd8cb095f1a">&lt;/strong&gt;</ept> to save the file.</target>
        </trans-unit>
        <trans-unit id="1dfe5b57-570d-48be-ab1f-79de72a7f42f" xml:space="preserve">
          <source>From the <bpt id="5885ddf7-9d9d-4ce3-9c1d-d66117ae9ba5">&lt;strong&gt;</bpt>SimpleScalaApp<ept id="5885ddf7-9d9d-4ce3-9c1d-d66117ae9ba5">&lt;/strong&gt;</ept> directory, use the following command to build the application, and store it in a jar file:</source>
          <target state="new">From the <bpt id="5885ddf7-9d9d-4ce3-9c1d-d66117ae9ba5">&lt;strong&gt;</bpt>SimpleScalaApp<ept id="5885ddf7-9d9d-4ce3-9c1d-d66117ae9ba5">&lt;/strong&gt;</ept> directory, use the following command to build the application, and store it in a jar file:</target>
        </trans-unit>
        <trans-unit id="a6ad867f-8c15-45e0-af25-8bbb0aa5d74e" xml:space="preserve">
          <source>Once the application is compiled, you will see a <bpt id="5d13fca9-0287-46ee-b297-9c56fdda9c23">&lt;strong&gt;</bpt>simpleapp_2.10-1.0.jar<ept id="5d13fca9-0287-46ee-b297-9c56fdda9c23">&lt;/strong&gt;</ept> file created in the __SimpleScalaApp/target/scala-2.10** directory.</source>
          <target state="new">Once the application is compiled, you will see a <bpt id="5d13fca9-0287-46ee-b297-9c56fdda9c23">&lt;strong&gt;</bpt>simpleapp_2.10-1.0.jar<ept id="5d13fca9-0287-46ee-b297-9c56fdda9c23">&lt;/strong&gt;</ept> file created in the __SimpleScalaApp/target/scala-2.10** directory.</target>
        </trans-unit>
        <trans-unit id="0f34b9db-0125-49e4-8320-9219092354a1" xml:space="preserve">
          <source>Use the following command to run the SimpleApp.scala program:</source>
          <target state="new">Use the following command to run the SimpleApp.scala program:</target>
        </trans-unit>
        <trans-unit id="8384ce74-c510-42fc-9865-f7b6657b042a" xml:space="preserve">
          <source>When the program finishes running, the output is displayed on the console.</source>
          <target state="new">When the program finishes running, the output is displayed on the console.</target>
        </trans-unit>
        <trans-unit id="9bc89c79-ccc0-4526-be51-05bc2434b9d5" xml:space="preserve">
          <source><bpt id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;linkText&gt;</bpt>Install and use Hue on HDInsight clusters<ept id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;/linkText&gt;</ept><bpt id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;title&gt;</bpt><ept id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;/title&gt;</ept>.</source>
          <target state="new"><bpt id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;linkText&gt;</bpt>Install and use Hue on HDInsight clusters<ept id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;/linkText&gt;</ept><bpt id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;title&gt;</bpt><ept id="5d4bc0f3-441e-4b16-b1e5-d57f449c9375">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="7bdea519-5a4c-4d01-930e-282b9bee9884" xml:space="preserve">
          <source>Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.</source>
          <target state="new">Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="bc5cf3fe-e10e-449c-b511-43c669b5836b" xml:space="preserve">
          <source><bpt id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;linkText&gt;</bpt>Install R on HDInsight clusters[hdinsight-install-r]<ept id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;/linkText&gt;</ept><bpt id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;title&gt;</bpt><ept id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;/title&gt;</ept> provides instructions on how to use cluster customization to install and use R on HDInsight Hadoop clusters.</source>
          <target state="new"><bpt id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;linkText&gt;</bpt>Install R on HDInsight clusters[hdinsight-install-r]<ept id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;/linkText&gt;</ept><bpt id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;title&gt;</bpt><ept id="c500f78d-9679-4aa5-baa0-10b5102eaaca">&lt;/title&gt;</ept> provides instructions on how to use cluster customization to install and use R on HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="6f476060-7e55-45b3-a8b0-e782dbbbefe5" xml:space="preserve">
          <source>R is an open-source language and environment for statistical computing.</source>
          <target state="new">R is an open-source language and environment for statistical computing.</target>
        </trans-unit>
        <trans-unit id="d258aff4-c477-42cc-aeb2-e6fbd45ed96a" xml:space="preserve">
          <source>It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.</source>
          <target state="new">It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.</target>
        </trans-unit>
        <trans-unit id="31fc0be5-ed7b-4fe7-9c29-4d92ae8e1a38" xml:space="preserve">
          <source>It also provides extensive graphical capabilities.</source>
          <target state="new">It also provides extensive graphical capabilities.</target>
        </trans-unit>
        <trans-unit id="6705c518-ece9-4048-a73c-094b4b718239" xml:space="preserve">
          <source><bpt id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;linkText&gt;</bpt>Install Giraph on HDInsight clusters<ept id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;/linkText&gt;</ept><bpt id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;title&gt;</bpt><ept id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;/title&gt;</ept>.</source>
          <target state="new"><bpt id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;linkText&gt;</bpt>Install Giraph on HDInsight clusters<ept id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;/linkText&gt;</ept><bpt id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;title&gt;</bpt><ept id="8031a6bf-6013-4ab2-8e1e-c35ee3b5dd26">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="4a9a23a9-751c-4dec-a047-b52abc85b194" xml:space="preserve">
          <source>Use cluster customization to install Giraph on HDInsight Hadoop clusters.</source>
          <target state="new">Use cluster customization to install Giraph on HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="7b853d1e-828f-474d-9dd8-9528afb1aac9" xml:space="preserve">
          <source>Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.</source>
          <target state="new">Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="96499871-aa36-4afb-aab5-5313e430262f" xml:space="preserve">
          <source><bpt id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;linkText&gt;</bpt>Install Solr on HDInsight clusters<ept id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;/linkText&gt;</ept><bpt id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;title&gt;</bpt><ept id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;/title&gt;</ept>.</source>
          <target state="new"><bpt id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;linkText&gt;</bpt>Install Solr on HDInsight clusters<ept id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;/linkText&gt;</ept><bpt id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;title&gt;</bpt><ept id="3aea3bed-d4ea-473f-a9ae-b091c7b8ccb2">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="24a39709-f350-45b4-9e4e-705bf2b22e6e" xml:space="preserve">
          <source>Use cluster customization to install Solr on HDInsight Hadoop clusters.</source>
          <target state="new">Use cluster customization to install Solr on HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="6bb917b0-f599-4dca-8215-bd7263b2119d" xml:space="preserve">
          <source>Solr allows you to perform powerful search operations on data stored.</source>
          <target state="new">Solr allows you to perform powerful search operations on data stored.</target>
        </trans-unit>
        <trans-unit id="7acfb481-c885-4bc2-b69d-5351c6c9b7d0" xml:space="preserve">
          <source><bpt id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;linkText&gt;</bpt>Install Hue on HDInsight clusters<ept id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;/linkText&gt;</ept><bpt id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;title&gt;</bpt><ept id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;/title&gt;</ept>.</source>
          <target state="new"><bpt id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;linkText&gt;</bpt>Install Hue on HDInsight clusters<ept id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;/linkText&gt;</ept><bpt id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;title&gt;</bpt><ept id="7648a32b-f41d-4e0f-8fa2-582167e31548">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="c5b98738-5ca5-47e8-8fb6-4d53338cbe85" xml:space="preserve">
          <source>Use cluster customization to install Hue on HDInsight Hadoop clusters.</source>
          <target state="new">Use cluster customization to install Hue on HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="0a3b7391-c46a-413b-8880-c85504f2eb52" xml:space="preserve">
          <source>Hue is a set of Web applications used to interact with a Hadoop cluster.</source>
          <target state="new">Hue is a set of Web applications used to interact with a Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="2bc8a05b-764f-4d49-aa23-ded0fa9852a4" xml:space="preserve">
          <source>hdinsight-provision-clusters-linux.md</source>
          <target state="new">hdinsight-provision-clusters-linux.md</target>
        </trans-unit>
        <trans-unit id="8de0cab0-2ba2-4f0b-8a15-fe1ffb61ea5b" xml:space="preserve">
          <source>hdinsight-hadoop-r-scripts-linux.md</source>
          <target state="new">hdinsight-hadoop-r-scripts-linux.md</target>
        </trans-unit>
        <trans-unit id="727e879d-4351-43f4-b4f5-358183bec8e8" xml:space="preserve">
          <source>hdinsight-hadoop-customize-cluster-linux.md</source>
          <target state="new">hdinsight-hadoop-customize-cluster-linux.md</target>
        </trans-unit>
        <trans-unit id="e431ebad-52b1-4ca4-91c1-d876f0912aa6" xml:space="preserve">
          <source>../install-configure-powershell.md</source>
          <target state="new">../install-configure-powershell.md</target>
        </trans-unit>
      </group>
      <group id="aa0acfa7-508c-46f5-95e3-f33231e67258" />
    </body>
  </file>
</xliff>