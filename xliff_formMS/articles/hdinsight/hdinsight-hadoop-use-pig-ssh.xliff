<?xml version="1.0" encoding="utf-8"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-us" target-language="zh-cn" original="foo.file" tool-id="df3dbc47-6ae5-49ac-90c4-e9a347fcfc9d" product-name="foo" product-version="1.0" build-num="1">
    <header>
      <tool tool-id="df3dbc47-6ae5-49ac-90c4-e9a347fcfc9d" tool-name="MarkdownToXliff" tool-version="1.0" tool-company="Microsoft" />
    </header>
    <body>
      <group id="d91a9c10-5a68-4f58-91e6-4072627f9274">
        <trans-unit id="2b7f5f71-bad9-48c2-80fc-b9c8d1e9c8e6" xml:space="preserve">
          <source>Use Hadoop Pig with SSH on an HDInsight cluster | Microsoft Azure</source>
          <target state="new">Use Hadoop Pig with SSH on an HDInsight cluster | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="eed16cbd-b6dc-45b3-bfbf-41b7b25db520" xml:space="preserve">
          <source>Learn how connect to a Linux-based Hadoop cluster with SSH, and then use the Pig command to run Pig Latin statements interactively, or as a batch job.</source>
          <target state="new">Learn how connect to a Linux-based Hadoop cluster with SSH, and then use the Pig command to run Pig Latin statements interactively, or as a batch job.</target>
        </trans-unit>
        <trans-unit id="284e30f6-a139-4b4e-b0d7-859715065393" xml:space="preserve">
          <source><bpt id="ed621c20-128c-434a-b217-c8f7af45e082">&lt;token href="../../includes/hdinsight-selector-use-pig.md"&gt;</bpt><ept id="ed621c20-128c-434a-b217-c8f7af45e082">&lt;/token&gt;</ept></source>
          <target state="new"><bpt id="ed621c20-128c-434a-b217-c8f7af45e082">&lt;token href="../../includes/hdinsight-selector-use-pig.md"&gt;</bpt><ept id="ed621c20-128c-434a-b217-c8f7af45e082">&lt;/token&gt;</ept></target>
        </trans-unit>
        <trans-unit id="d7fa0afb-9835-4a6f-a423-c5b69c01655e" xml:space="preserve">
          <source>In this document you will walk through the process of connecting to a Linux-based Azure HDInsight cluster by using Secure Shell (SSH), then using the Pig command to run Pig Latin statements interactively, or as a batch job.</source>
          <target state="new">In this document you will walk through the process of connecting to a Linux-based Azure HDInsight cluster by using Secure Shell (SSH), then using the Pig command to run Pig Latin statements interactively, or as a batch job.</target>
        </trans-unit>
        <trans-unit id="203957a1-145d-4eff-a739-474daf0bc3ee" xml:space="preserve">
          <source>The Pig Latin programming language allows you to describe transformations that are applied to the input data to produce the desired output.</source>
          <target state="new">The Pig Latin programming language allows you to describe transformations that are applied to the input data to produce the desired output.</target>
        </trans-unit>
        <trans-unit id="a0a7e2a1-caf9-40e2-91d1-19946770fb55" xml:space="preserve">
          <source>If you are already familiar with using Linux-based Hadoop servers, but are new to HDInsight, see <bpt id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;linkText&gt;</bpt>Linux-based HDInsight Tips<ept id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;/linkText&gt;</ept><bpt id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;title&gt;</bpt><ept id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;/title&gt;</ept>.</source>
          <target state="new">If you are already familiar with using Linux-based Hadoop servers, but are new to HDInsight, see <bpt id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;linkText&gt;</bpt>Linux-based HDInsight Tips<ept id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;/linkText&gt;</ept><bpt id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;title&gt;</bpt><ept id="1d4ba974-bd31-422c-9ebe-2a8905a44ee0">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="40c2e9d1-324b-450f-a780-c181deee66de" xml:space="preserve">
          <source>To complete the steps in this article, you will need the following.</source>
          <target state="new">To complete the steps in this article, you will need the following.</target>
        </trans-unit>
        <trans-unit id="543de63d-1acb-4fcc-a1fe-d566ed7ff4e9" xml:space="preserve">
          <source>A Linux-based HDInsight (Hadoop on HDInsight) cluster.</source>
          <target state="new">A Linux-based HDInsight (Hadoop on HDInsight) cluster.</target>
        </trans-unit>
        <trans-unit id="30e25625-5d50-4fd4-b027-436f4f713c04" xml:space="preserve">
          <source>An SSH client.</source>
          <target state="new">An SSH client.</target>
        </trans-unit>
        <trans-unit id="614d6f5c-418c-47e2-a053-cb9749cc95fe" xml:space="preserve">
          <source>Linux, Unix, and Mac OS should come with an SSH client.</source>
          <target state="new">Linux, Unix, and Mac OS should come with an SSH client.</target>
        </trans-unit>
        <trans-unit id="82e7f91d-3683-41b0-90a4-287b3121662a" xml:space="preserve">
          <source>Windows users must download a client, such as <bpt id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;linkText&gt;</bpt>PuTTY<ept id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;/linkText&gt;</ept><bpt id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;title&gt;</bpt><ept id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;/title&gt;</ept>.</source>
          <target state="new">Windows users must download a client, such as <bpt id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;linkText&gt;</bpt>PuTTY<ept id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;/linkText&gt;</ept><bpt id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;title&gt;</bpt><ept id="ea9d03dc-0321-4780-92f0-636d47a87a9f">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="62b22043-15f7-41e2-97ce-53236da94050" xml:space="preserve">
          <source>Connect to the fully qualified domain name (FQDN) of your HDInsight cluster by using the SSH command.</source>
          <target state="new">Connect to the fully qualified domain name (FQDN) of your HDInsight cluster by using the SSH command.</target>
        </trans-unit>
        <trans-unit id="7a6018c0-c5be-42d9-9c03-6e6ebef0bb55" xml:space="preserve">
          <source>The FQDN will be the name you gave the cluster, then <bpt id="e768a6b1-dda6-42ec-9145-ceb4355ae0b7">&lt;strong&gt;</bpt>.azurehdinsight.net<ept id="e768a6b1-dda6-42ec-9145-ceb4355ae0b7">&lt;/strong&gt;</ept>.</source>
          <target state="new">The FQDN will be the name you gave the cluster, then <bpt id="e768a6b1-dda6-42ec-9145-ceb4355ae0b7">&lt;strong&gt;</bpt>.azurehdinsight.net<ept id="e768a6b1-dda6-42ec-9145-ceb4355ae0b7">&lt;/strong&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="ed579ee5-69e8-4500-865c-a3f2294ba3ec" xml:space="preserve">
          <source>For example, the following would connect to a cluster named <bpt id="b493e955-ea76-434d-aa8a-e3230a39e098">&lt;strong&gt;</bpt>myhdinsight<ept id="b493e955-ea76-434d-aa8a-e3230a39e098">&lt;/strong&gt;</ept>.</source>
          <target state="new">For example, the following would connect to a cluster named <bpt id="b493e955-ea76-434d-aa8a-e3230a39e098">&lt;strong&gt;</bpt>myhdinsight<ept id="b493e955-ea76-434d-aa8a-e3230a39e098">&lt;/strong&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="da7c67f3-e822-4a90-9482-ef6a139634c6" xml:space="preserve">
          <source><bpt id="9cdb0ae5-3508-489b-83e6-e48a1111a848">&lt;strong&gt;</bpt>If you provided a certificate key for SSH authentication<ept id="9cdb0ae5-3508-489b-83e6-e48a1111a848">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you may need to specify the location of the private key on your client system.</source>
          <target state="new"><bpt id="9cdb0ae5-3508-489b-83e6-e48a1111a848">&lt;strong&gt;</bpt>If you provided a certificate key for SSH authentication<ept id="9cdb0ae5-3508-489b-83e6-e48a1111a848">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you may need to specify the location of the private key on your client system.</target>
        </trans-unit>
        <trans-unit id="374993d7-22f8-42eb-8ad7-2ae9d39497d9" xml:space="preserve">
          <source><bpt id="ba8c945a-6191-45f5-af68-601ed3693146">&lt;strong&gt;</bpt>If you provided a password for SSH authentication<ept id="ba8c945a-6191-45f5-af68-601ed3693146">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you will need to provide the password when prompted.</source>
          <target state="new"><bpt id="ba8c945a-6191-45f5-af68-601ed3693146">&lt;strong&gt;</bpt>If you provided a password for SSH authentication<ept id="ba8c945a-6191-45f5-af68-601ed3693146">&lt;/strong&gt;</ept> when you created the HDInsight cluster, you will need to provide the password when prompted.</target>
        </trans-unit>
        <trans-unit id="87c59454-a541-4fcd-9ef4-0d127b392c24" xml:space="preserve">
          <source>For more information on using SSH with HDInsight, see <bpt id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix<ept id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;/linkText&gt;</ept><bpt id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;title&gt;</bpt><ept id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;/title&gt;</ept>.</source>
          <target state="new">For more information on using SSH with HDInsight, see <bpt id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix<ept id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;/linkText&gt;</ept><bpt id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;title&gt;</bpt><ept id="4a0b4e59-1423-42e4-9b70-f577b302b5f8">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="8908a96c-6e56-4fc8-a90e-a5da697f98cb" xml:space="preserve">
          <source>Windows does not provide a built-in SSH client.</source>
          <target state="new">Windows does not provide a built-in SSH client.</target>
        </trans-unit>
        <trans-unit id="60cde180-9b8d-44f9-aaaa-8945c55887dd" xml:space="preserve">
          <source>We recommend using <bpt id="92de466c-1a61-426a-9712-63c42795b82f">&lt;strong&gt;</bpt>PuTTY<ept id="92de466c-1a61-426a-9712-63c42795b82f">&lt;/strong&gt;</ept>, which can be downloaded from <bpt id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;linkText&gt;</bpt>http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html<ept id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;/linkText&gt;</ept><bpt id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;title&gt;</bpt><ept id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;/title&gt;</ept>.</source>
          <target state="new">We recommend using <bpt id="92de466c-1a61-426a-9712-63c42795b82f">&lt;strong&gt;</bpt>PuTTY<ept id="92de466c-1a61-426a-9712-63c42795b82f">&lt;/strong&gt;</ept>, which can be downloaded from <bpt id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;linkText&gt;</bpt>http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html<ept id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;/linkText&gt;</ept><bpt id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;title&gt;</bpt><ept id="c17721b5-dd73-4dd1-befd-9e662de3597e">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="7cd821e3-c531-4e5f-8972-c8a3dc8f7e3b" xml:space="preserve">
          <source>For more information on using PuTTY, see <bpt id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows <ept id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;/linkText&gt;</ept><bpt id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;title&gt;</bpt><ept id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;/title&gt;</ept>.</source>
          <target state="new">For more information on using PuTTY, see <bpt id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;linkText&gt;</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows <ept id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;/linkText&gt;</ept><bpt id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;title&gt;</bpt><ept id="00a395a1-67ba-40b2-8d0e-c9faa809bea4">&lt;/title&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="0f755cf3-e4a6-44bc-a582-8d50cede878f" xml:space="preserve">
          <source>Once connected, start the Pig command-line interface (CLI) by using the following command.</source>
          <target state="new">Once connected, start the Pig command-line interface (CLI) by using the following command.</target>
        </trans-unit>
        <trans-unit id="85e20014-7463-421c-83ca-fd8084bf5bb7" xml:space="preserve">
          <source>After a moment, you should see a <bpt id="9485f6ee-9e1b-4396-ab70-c6205d0b3872">&lt;code&gt;</bpt>grunt&gt;<ept id="9485f6ee-9e1b-4396-ab70-c6205d0b3872">&lt;/code&gt;</ept> prompt.</source>
          <target state="new">After a moment, you should see a <bpt id="9485f6ee-9e1b-4396-ab70-c6205d0b3872">&lt;code&gt;</bpt>grunt&gt;<ept id="9485f6ee-9e1b-4396-ab70-c6205d0b3872">&lt;/code&gt;</ept> prompt.</target>
        </trans-unit>
        <trans-unit id="8caca6ef-ce63-463c-b8c5-758f69988368" xml:space="preserve">
          <source>Enter the following statement.</source>
          <target state="new">Enter the following statement.</target>
        </trans-unit>
        <trans-unit id="8fd59089-f6dd-4d8e-a7e0-f20c966853a6" xml:space="preserve">
          <source>This command loads the contents of the sample.log file into LOGS.</source>
          <target state="new">This command loads the contents of the sample.log file into LOGS.</target>
        </trans-unit>
        <trans-unit id="14c08d4f-cff1-4e61-8645-d8f02b082ce7" xml:space="preserve">
          <source>You can view the contents of the file by using the following.</source>
          <target state="new">You can view the contents of the file by using the following.</target>
        </trans-unit>
        <trans-unit id="0ca59ad3-8404-4b46-84ac-37a1500ab016" xml:space="preserve">
          <source>Next, transform the data by applying a regular expression to extract only the logging level from each record by using the following.</source>
          <target state="new">Next, transform the data by applying a regular expression to extract only the logging level from each record by using the following.</target>
        </trans-unit>
        <trans-unit id="a569784b-8be7-4d80-9ab4-1e0a9747f7b0" xml:space="preserve">
          <source>You can use <bpt id="a3c2057e-f0a5-46cd-9c15-41fda5e20beb">&lt;strong&gt;</bpt>DUMP<ept id="a3c2057e-f0a5-46cd-9c15-41fda5e20beb">&lt;/strong&gt;</ept> to view the data after the transformation.</source>
          <target state="new">You can use <bpt id="a3c2057e-f0a5-46cd-9c15-41fda5e20beb">&lt;strong&gt;</bpt>DUMP<ept id="a3c2057e-f0a5-46cd-9c15-41fda5e20beb">&lt;/strong&gt;</ept> to view the data after the transformation.</target>
        </trans-unit>
        <trans-unit id="4d869890-3a8f-40c3-a682-e8f1a8064956" xml:space="preserve">
          <source>In this case, use <bpt id="90cbe5d7-d7e9-4edd-ac86-dcd00f1cb642">&lt;code&gt;</bpt>DUMP LEVELS;<ept id="90cbe5d7-d7e9-4edd-ac86-dcd00f1cb642">&lt;/code&gt;</ept>.</source>
          <target state="new">In this case, use <bpt id="90cbe5d7-d7e9-4edd-ac86-dcd00f1cb642">&lt;code&gt;</bpt>DUMP LEVELS;<ept id="90cbe5d7-d7e9-4edd-ac86-dcd00f1cb642">&lt;/code&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="83c947db-2a5b-48e7-a8ca-92a33de2fb76" xml:space="preserve">
          <source>Continue applying transformations by using the following statements.</source>
          <target state="new">Continue applying transformations by using the following statements.</target>
        </trans-unit>
        <trans-unit id="d10000ae-9d4b-4c09-8fc4-13ba30324eb9" xml:space="preserve">
          <source>Use <bpt id="ce344b3e-88b8-4467-a65b-8884f0e90bb3">&lt;code&gt;</bpt>DUMP<ept id="ce344b3e-88b8-4467-a65b-8884f0e90bb3">&lt;/code&gt;</ept> to view the result of the transformation after each step.</source>
          <target state="new">Use <bpt id="ce344b3e-88b8-4467-a65b-8884f0e90bb3">&lt;code&gt;</bpt>DUMP<ept id="ce344b3e-88b8-4467-a65b-8884f0e90bb3">&lt;/code&gt;</ept> to view the result of the transformation after each step.</target>
        </trans-unit>
        <trans-unit id="317f3486-62bb-4024-8121-5522f1916084" xml:space="preserve">
          <source>Statement</source>
          <target state="new">Statement</target>
        </trans-unit>
        <trans-unit id="f31f951e-132d-41d5-a93b-096fdf006d75" xml:space="preserve">
          <source>What it does</source>
          <target state="new">What it does</target>
        </trans-unit>
        <trans-unit id="20766c42-1ca0-460e-aeca-19db3d1e2181" xml:space="preserve">
          <source>FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;</source>
          <target state="new">FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;</target>
        </trans-unit>
        <trans-unit id="a0b7b297-a596-45b1-956b-1b08874d77a7" xml:space="preserve">
          <source>Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.</source>
          <target state="new">Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.</target>
        </trans-unit>
        <trans-unit id="403a11ac-7533-4cc1-b71b-0957f51ac40c" xml:space="preserve">
          <source>GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;</source>
          <target state="new">GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;</target>
        </trans-unit>
        <trans-unit id="b7636808-0e22-4304-a874-718a70db6bd8" xml:space="preserve">
          <source>Groups the rows by log level and stores the results into GROUPEDLEVELS.</source>
          <target state="new">Groups the rows by log level and stores the results into GROUPEDLEVELS.</target>
        </trans-unit>
        <trans-unit id="cbfb34d2-3dba-4446-aed2-a491ac528820" xml:space="preserve">
          <source>FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;</source>
          <target state="new">FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;</target>
        </trans-unit>
        <trans-unit id="268cf9f3-05ff-47ae-b67e-4f5a1a5aec73" xml:space="preserve">
          <source>Creates a new set of data that contains each unique log level value and how many times it occurs. This is stored into FREQUENCIES.</source>
          <target state="new">Creates a new set of data that contains each unique log level value and how many times it occurs. This is stored into FREQUENCIES.</target>
        </trans-unit>
        <trans-unit id="949521e8-c32b-4181-b9a0-162297967cf3" xml:space="preserve">
          <source>RESULT = order FREQUENCIES by COUNT desc;</source>
          <target state="new">RESULT = order FREQUENCIES by COUNT desc;</target>
        </trans-unit>
        <trans-unit id="7b1a0345-7ee3-45a9-81bc-448e916bd45b" xml:space="preserve">
          <source>Orders the log levels by count (descending) and stores into RESULT.</source>
          <target state="new">Orders the log levels by count (descending) and stores into RESULT.</target>
        </trans-unit>
        <trans-unit id="0c4edd8a-25dc-47ee-9b14-e6a4b93d17ad" xml:space="preserve">
          <source>You can also save the results of a transformation by using the <bpt id="5b7dd8df-dbf6-41c3-a2f6-a93370e898b9">&lt;code&gt;</bpt>STORE<ept id="5b7dd8df-dbf6-41c3-a2f6-a93370e898b9">&lt;/code&gt;</ept> statement.</source>
          <target state="new">You can also save the results of a transformation by using the <bpt id="5b7dd8df-dbf6-41c3-a2f6-a93370e898b9">&lt;code&gt;</bpt>STORE<ept id="5b7dd8df-dbf6-41c3-a2f6-a93370e898b9">&lt;/code&gt;</ept> statement.</target>
        </trans-unit>
        <trans-unit id="903ed7ba-4189-406e-a186-0e2ed1e5dae0" xml:space="preserve">
          <source>For example, the following saves the <bpt id="1aa5c27f-8c05-40c1-b3cd-40e96d2237fd">&lt;code&gt;</bpt>RESULT<ept id="1aa5c27f-8c05-40c1-b3cd-40e96d2237fd">&lt;/code&gt;</ept> to the <bpt id="f43947ff-13ba-478a-9a74-1e15c248a4fa">&lt;strong&gt;</bpt>/example/data/pigout<ept id="f43947ff-13ba-478a-9a74-1e15c248a4fa">&lt;/strong&gt;</ept> directory on the default storage container for your cluster.</source>
          <target state="new">For example, the following saves the <bpt id="1aa5c27f-8c05-40c1-b3cd-40e96d2237fd">&lt;code&gt;</bpt>RESULT<ept id="1aa5c27f-8c05-40c1-b3cd-40e96d2237fd">&lt;/code&gt;</ept> to the <bpt id="f43947ff-13ba-478a-9a74-1e15c248a4fa">&lt;strong&gt;</bpt>/example/data/pigout<ept id="f43947ff-13ba-478a-9a74-1e15c248a4fa">&lt;/strong&gt;</ept> directory on the default storage container for your cluster.</target>
        </trans-unit>
        <trans-unit id="9d5e5c5c-8b9f-4ab1-b72b-339645ac603f" xml:space="preserve">
          <source>The data is stored in the specified directory in files named <bpt id="626d6b48-997c-4e2e-81e1-001e8b4327ee">&lt;strong&gt;</bpt>part-nnnnn<ept id="626d6b48-997c-4e2e-81e1-001e8b4327ee">&lt;/strong&gt;</ept>.</source>
          <target state="new">The data is stored in the specified directory in files named <bpt id="626d6b48-997c-4e2e-81e1-001e8b4327ee">&lt;strong&gt;</bpt>part-nnnnn<ept id="626d6b48-997c-4e2e-81e1-001e8b4327ee">&lt;/strong&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="86ddaeb6-e7f7-4cd0-ad1a-e07dbe4ce8fb" xml:space="preserve">
          <source>If the directory already exists, you will receive an error.</source>
          <target state="new">If the directory already exists, you will receive an error.</target>
        </trans-unit>
        <trans-unit id="3886f161-7336-4715-a77d-aefcabffcb93" xml:space="preserve">
          <source>To exit the grunt prompt, enter the following statement.</source>
          <target state="new">To exit the grunt prompt, enter the following statement.</target>
        </trans-unit>
        <trans-unit id="1afd4df9-fa38-4390-aed7-585b833b0f2a" xml:space="preserve">
          <source>You can also use the Pig command to run Pig Latin contained in a file.</source>
          <target state="new">You can also use the Pig command to run Pig Latin contained in a file.</target>
        </trans-unit>
        <trans-unit id="470a2fcc-05c3-4806-aa42-67857f10d004" xml:space="preserve">
          <source>After exiting the grunt prompt, use the following command to pipe STDIN into a file named <bpt id="4e25effa-e711-41f4-945e-6f5fc3ed32e8">&lt;strong&gt;</bpt>pigbatch.pig<ept id="4e25effa-e711-41f4-945e-6f5fc3ed32e8">&lt;/strong&gt;</ept>.</source>
          <target state="new">After exiting the grunt prompt, use the following command to pipe STDIN into a file named <bpt id="4e25effa-e711-41f4-945e-6f5fc3ed32e8">&lt;strong&gt;</bpt>pigbatch.pig<ept id="4e25effa-e711-41f4-945e-6f5fc3ed32e8">&lt;/strong&gt;</ept>.</target>
        </trans-unit>
        <trans-unit id="c7e719f5-9418-4f17-9180-0980e2b82372" xml:space="preserve">
          <source>This file will be created in the home directory for the account you are logged in to for the SSH session.</source>
          <target state="new">This file will be created in the home directory for the account you are logged in to for the SSH session.</target>
        </trans-unit>
        <trans-unit id="9d562492-fb02-43f6-8f40-cbd92b3e106f" xml:space="preserve">
          <source>Type or paste the following lines, and then use Ctrl+D when finished.</source>
          <target state="new">Type or paste the following lines, and then use Ctrl+D when finished.</target>
        </trans-unit>
        <trans-unit id="6ac1e4e2-c4c0-4584-adb8-215d0d079223" xml:space="preserve">
          <source>Use the following to run the <bpt id="2df769ad-0426-47c1-b4b4-05c592f12037">&lt;strong&gt;</bpt>pigbatch.pig<ept id="2df769ad-0426-47c1-b4b4-05c592f12037">&lt;/strong&gt;</ept> file by using the Pig command.</source>
          <target state="new">Use the following to run the <bpt id="2df769ad-0426-47c1-b4b4-05c592f12037">&lt;strong&gt;</bpt>pigbatch.pig<ept id="2df769ad-0426-47c1-b4b4-05c592f12037">&lt;/strong&gt;</ept> file by using the Pig command.</target>
        </trans-unit>
        <trans-unit id="92d7e800-fe0c-441a-b5db-bc062ed6ec0f" xml:space="preserve">
          <source>Once the batch job finishes, you should see the following output, which should be the same as when you used <bpt id="a6886cab-45ba-4b33-bd3f-19b0270acd33">&lt;code&gt;</bpt>DUMP RESULT;<ept id="a6886cab-45ba-4b33-bd3f-19b0270acd33">&lt;/code&gt;</ept> in the previous steps.</source>
          <target state="new">Once the batch job finishes, you should see the following output, which should be the same as when you used <bpt id="a6886cab-45ba-4b33-bd3f-19b0270acd33">&lt;code&gt;</bpt>DUMP RESULT;<ept id="a6886cab-45ba-4b33-bd3f-19b0270acd33">&lt;/code&gt;</ept> in the previous steps.</target>
        </trans-unit>
        <trans-unit id="ce5a56c2-6b6a-4b7c-a2f2-220fe20aa382" xml:space="preserve">
          <source>As you can see, the Pig command allows you to interactively run MapReduce operations by using Pig Latin, as well as run statements stored in a batch file.</source>
          <target state="new">As you can see, the Pig command allows you to interactively run MapReduce operations by using Pig Latin, as well as run statements stored in a batch file.</target>
        </trans-unit>
        <trans-unit id="0bb2fc70-6ea9-48fd-bb70-a2da20200ebc" xml:space="preserve">
          <source>For general information on Pig in HDInsight.</source>
          <target state="new">For general information on Pig in HDInsight.</target>
        </trans-unit>
        <trans-unit id="ad789a21-e81d-4b5e-81f2-371a698537ab" xml:space="preserve">
          <source><bpt id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;/linkText&gt;</ept><bpt id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;title&gt;</bpt><ept id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;linkText&gt;</bpt>Use Pig with Hadoop on HDInsight<ept id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;/linkText&gt;</ept><bpt id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;title&gt;</bpt><ept id="1e731ba6-e395-4378-a53b-888fc9836752">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="70b9a24b-680b-4da8-b859-b4d7c112a877" xml:space="preserve">
          <source>For information on other ways you can work with Hadoop on HDInsight.</source>
          <target state="new">For information on other ways you can work with Hadoop on HDInsight.</target>
        </trans-unit>
        <trans-unit id="d21053bf-f6ca-4bdb-ac92-479eae4e276e" xml:space="preserve">
          <source><bpt id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;/linkText&gt;</ept><bpt id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;title&gt;</bpt><ept id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;linkText&gt;</bpt>Use Hive with Hadoop on HDInsight<ept id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;/linkText&gt;</ept><bpt id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;title&gt;</bpt><ept id="93a3127d-f941-4ee0-964f-27cbb67c6f21">&lt;/title&gt;</ept></target>
        </trans-unit>
        <trans-unit id="6dbe2162-0c55-4336-8b5d-ab230f7ab1e8" xml:space="preserve">
          <source><bpt id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;linkText&gt;</bpt>Use MapReduce with Hadoop on HDInsight<ept id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;/linkText&gt;</ept><bpt id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;title&gt;</bpt><ept id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;/title&gt;</ept></source>
          <target state="new"><bpt id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;linkText&gt;</bpt>Use MapReduce with Hadoop on HDInsight<ept id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;/linkText&gt;</ept><bpt id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;title&gt;</bpt><ept id="542f8bb4-7c17-4826-80dd-7ed23cf950d2">&lt;/title&gt;</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>